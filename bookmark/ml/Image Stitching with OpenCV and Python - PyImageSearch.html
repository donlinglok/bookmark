<!DOCTYPE html>
<!-- saved from url=(0076)https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/ -->
<html lang="en-US" class="js"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script class="w-json-ld" type="application/ld+json" id="w-json-ldwistia_43">{"@context":"http://schema.org/","@id":"https://fast.wistia.net/embed/iframe/kno0cmko2z","@type":"VideoObject","duration":"PT3M52S","name":"Pyimagesearch_Sales_page w/out Autoplay","thumbnailUrl":"https://embed-ssl.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.jpg?image_crop_resized=640x360","contentUrl":"https://embed-fastly.wistia.com/deliveries/2003a737de7da1bcd5c4d283caa5eefae8c9cbea.m3u8","embedUrl":"https://fast.wistia.net/embed/iframe/kno0cmko2z","uploadDate":"2021-02-19","description":"a PyImageSearch University Opt-in Pitch [v2] video","potentialAction":{"@type":"SeekToAction","target":"https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/?wtime={seek_to_second_number}","startOffset-input":"required name=seek_to_second_number"}}</script><script class="w-json-ld" type="application/ld+json" id="w-json-ldwistia_107">{"@context":"http://schema.org/","@id":"https://fast.wistia.net/embed/iframe/8ggk996ods","@type":"VideoObject","duration":"PT1M34S","name":"PyUniOptinPitch","thumbnailUrl":"https://embed-ssl.wistia.com/deliveries/b8e0c620b2c8f8986aa80fabf27c8de4.jpg?image_crop_resized=640x360","contentUrl":"https://embedwistia-a.akamaihd.net/deliveries/6eb159c40755e5ed484552ce51441db934ff5c1e.m3u8","embedUrl":"https://fast.wistia.net/embed/iframe/8ggk996ods?wseektoaction=true","uploadDate":"2021-03-05","description":"a PyImageSearch University Opt-in Pitch [v2] video","potentialAction":{"@type":"SeekToAction","target":"https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/?wtime={seek_to_second_number}","startOffset-input":"required name=seek_to_second_number"}}</script><script type="text/javascript" async="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/saved_resource"></script><script async="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/fbevents.js.download"></script><script type="text/javascript" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/visit"></script>

<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1">

	<!-- This site is optimized with the Yoast SEO plugin v19.6.1 - https://yoast.com/wordpress/plugins/seo/ -->
	<title>Image Stitching with OpenCV and Python - PyImageSearch</title><style id="avlabs-lazy-load-bg">.pyi-page-hero .pyi-hero-right .pyi-page-hero .pyi-hero-left .nav-primary .is-topics .has-icon.has-icon--pi a::before, .nav-primary .is-topics .has-icon.has-icon--opencv a::before, .nav-primary .is-topics .has-icon.has-icon--object-tracking a::before, .nav-primary .is-topics .has-icon.has-icon--object-detection a::before, .nav-primary .is-topics .has-icon.has-icon--ocr a::before, .nav-primary .is-topics .has-icon.has-icon--medical a::before, .nav-primary .is-topics .has-icon.has-icon--ml a::before, .nav-primary .is-topics .has-icon.has-icon--keras a::before, .nav-primary .is-topics .has-icon.has-icon--interviews a::before, .nav-primary .is-topics .has-icon.has-icon--image a::before, .nav-primary .is-topics .has-icon.has-icon--face a::before, .nav-primary .is-topics .has-icon.has-icon--iot a::before, .nav-primary .is-topics .has-icon.has-icon--dlib a::before, .nav-primary .is-topics .has-icon.has-icon--deep-learning a::before{
background: none ;
}</style><style id="avlabs-custom-critical-css-before-rocket">:root{--wp-admin-theme-color:#007cba;--wp-admin-theme-color-darker-10:#006ba1;--wp-admin-theme-color-darker-20:#005a87}.enlighter-t-pyis-enlighter-theme .enlighter-codegroup-wrapper .enlighter-raw{background-color:#fff;font-size:12px;color:#000;line-height:16px}.enlighter-t-pyis-enlighter-theme .enlighter-codegroup-wrapper .enlighter-toolbar .enlighter-btn{border-radius:0}.enlighter-t-pyis-enlighter-theme .enlighter-codegroup-wrapper .enlighter-toolbar{display:none!important}.enlighter-t-pyis-enlighter-theme .enlighter-codegroup-wrapper .enlighter-toolbar .enlighter-btn{background-color:#fff;color:#717171;font-size:12px;padding:0;border:1px solid #e0e0e0;margin:0 0 0 8px;text-decoration:none;width:23px;height:23px;background-position:0 0;background-size:contain}.foundation-mq{font-family:"small=0em&medium=40em&large=64em&xlarge=75em&xxlarge=90em"}.sticky-container{position:relative}.sticky{position:relative;z-index:0;-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0)}.sticky.is-anchored{position:relative;right:auto;left:auto}#pyis-cta-modal-sticky-bar{margin:1.25rem 0}#pyis-cta-modal-sticky-bar .grid-container{padding-right:.625rem;padding-left:.625rem;max-width:75rem;margin-left:auto;margin-right:auto}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-container{padding-right:.9375rem;padding-left:.9375rem}}#pyis-cta-modal-sticky-bar .grid-x{display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-flow:row wrap;-ms-flex-flow:row wrap;flex-flow:row wrap}#pyis-cta-modal-sticky-bar .cell{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;min-height:0;min-width:0;width:100%}#pyis-cta-modal-sticky-bar .grid-margin-x{margin-left:-.625rem;margin-right:-.625rem}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-margin-x{margin-left:-.9375rem;margin-right:-.9375rem}}#pyis-cta-modal-sticky-bar .grid-margin-x>.cell{width:calc(100% - 1.25rem);margin-left:.625rem;margin-right:.625rem}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-margin-x>.cell{width:calc(100% - 1.875rem);margin-left:.9375rem;margin-right:.9375rem}}#pyis-cta-modal-sticky-bar .text-center{text-align:center}#pyis-cta-modal-sticky-bar .sticky{background-color:#051e50;color:#fefefe;padding:1.625rem 1rem 1.25rem 1.625rem}#pyis-cta-modal-sticky-bar .sticky a{background:0 0;outline:0;font-size:1.2rem;padding:0;border-bottom:none;color:#fefefe;text-decoration:underline;position:relative}#pyis-cta-modal-sticky-bar .sticky a:before{position:absolute;top:-.5625rem;left:-3.75rem;display:block;width:2.5rem;height:2.5rem;content:'';background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/source_code_mini_image.png);background-size:contain}#pyis-cta-modal .modal-content{margin-top:1.5rem}#pyis-cta-modal .optin-modal-content .pyuni-logo{padding-bottom:20px;max-width:400px}#pyis-cta-modal .optin-modal-content h3{margin-bottom:20px;font-size:24px}#pyis-cta-modal .optin-modal-content .is-style-list-checks li{font-weight:400}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-display:swap;font-style:normal;font-weight:700}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/4c4052/00000000000000003b9b3069/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff2"),url(https://use.typekit.net/af/4c4052/00000000000000003b9b3069/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff"),url(https://use.typekit.net/af/4c4052/00000000000000003b9b3069/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("opentype");font-display:swap;font-style:italic;font-weight:700}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff2"),url(https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff"),url(https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("opentype");font-display:swap;font-style:normal;font-weight:600}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-display:swap;font-style:normal;font-weight:400}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/5c70f2/00000000000000003b9b3063/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff2"),url(https://use.typekit.net/af/5c70f2/00000000000000003b9b3063/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff"),url(https://use.typekit.net/af/5c70f2/00000000000000003b9b3063/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("opentype");font-display:swap;font-style:italic;font-weight:400}button,input{overflow:visible}html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{margin:.67em 0;font-size:2em}code,pre{font-family:monospace;font-size:1em}a{background-color:transparent}strong{font-weight:bolder}img{border-style:none}button,input,textarea{margin:0;font-family:inherit;font-size:100%;line-height:1.15}button{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=submit]::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}[type=submit]:-moz-focusring,button:-moz-focusring{outline:ButtonText dotted 1px}textarea{overflow:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}html{box-sizing:border-box}*,:after{box-sizing:inherit}.entry-content::before,.entry::before,.nav-primary::before,.nav-secondary::before,.site-container::before,.site-header::before,.site-inner::before,.widget::before,.wrap::before{display:table;content:" "}.entry-content::after,.entry::after,.nav-primary::after,.nav-secondary::after,.site-container::after,.site-header::after,.site-inner::after,.widget::after,.wrap::after{display:table;clear:both;content:""}html,input[type=search]{box-sizing:border-box}*,:after,:before{box-sizing:inherit}html{overflow-y:scroll;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}body{margin:0;font-family:proxima-nova,sans-serif;font-weight:400;line-height:1.472;color:#051e50;font-size:17px}@media (min-width:640px){body{line-height:1.52}}@media (min-width:880px){body{line-height:1.568}}@media (min-width:1200px){body{line-height:1.6}}@media (min-width:640px){body{font-size:19px}}@media (min-width:880px){body{font-size:20px}}body a{font-weight:700;color:#169fe6;text-decoration:none}.entry-content a{border-bottom:1px solid #169fe6}:focus{outline:0}ul{padding:0;margin:0}li{list-style-type:none}em{font-style:italic}cite{font-style:normal}iframe,img{max-width:100%}img{display:block;height:auto}p{padding:0;margin:0 0 24px}@media (min-width:640px){p{margin:0 0 32px}}h1,h2,h3,h4{margin:0 0 30px;font-family:proxima-nova,sans-serif;font-weight:700}h4 a{color:#169fe6}h1{line-height:1.06;letter-spacing:-.5px;font-size:40px}@media (min-width:640px){h1{font-size:48px}}@media (min-width:880px){h1{font-size:54px}}@media (min-width:1200px){h1{font-size:62px}}@media (min-width:880px){h1{letter-spacing:-1.5px}}@media (min-width:1200px){h1{letter-spacing:-2.5px}}h2{line-height:1.5;letter-spacing:-.5px;font-size:28px}@media (min-width:640px){h2{font-size:32px}}@media (min-width:880px){h2{font-size:36px}}@media (min-width:1200px){h2{font-size:40px}}@media (min-width:880px){h2{letter-spacing:-1px}}h3{line-height:1.25;font-size:26px}@media (min-width:640px){h3{font-size:28px}}@media (min-width:880px){h3{font-size:30px}}@media (min-width:1200px){h3{font-size:32px}}h4{line-height:1.25;font-size:20px}@media (min-width:640px){h4{font-size:22px}}@media (min-width:880px){h4{font-size:22px}}@media (min-width:1200px){h4{font-size:24px}}.site-container{overflow-x:hidden;word-wrap:break-word}.site-inner{padding:24px 0;margin:0 auto;clear:both}@media (min-width:640px){.site-inner{padding:30px 0}}@media (min-width:880px){.site-inner{padding:48px 0}}@media (min-width:1200px){.site-inner{padding:60px 0}}.wrap{width:auto;max-width:100%;margin:0 16px}.wrap::before{display:table;content:" "}.wrap::after{display:table;clear:both;content:""}@media (min-width:640px){.wrap{margin:0 24px}}@media (min-width:880px){.wrap{margin:0 50px}}@media (min-width:1200px){body .wrap{max-width:1110px;margin:0 auto}}@media (min-width:920px){.site-header{width:100%;padding:20px 0 10px}}@media (max-width:920px){.site-header>.wrap{margin:0 10px}}.title-area{position:relative;z-index:99999;float:left;padding:14px 0}@media (min-width:880px){.title-area{padding:8px 0}}.site-title{margin-bottom:0;font-weight:900;line-height:1;text-indent:-9999px;text-transform:uppercase;letter-spacing:2px;font-size:24px}@media (min-width:640px){.site-title{font-size:24px}}@media (min-width:880px){.site-title{font-size:30px}}@media (min-width:1200px){.site-title{font-size:30px}}.site-title a{display:block;width:140px;height:30px;background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/logo-mobile.png) no-repeat center center;background-size:contain}@media (min-width:400px){.site-title a{width:173px;height:36px}}@media (min-width:920px){.site-title a{width:220px;height:47px;margin-top:21px}}@media (min-width:1058px){.site-title a{width:348px;height:64px;margin-top:0;background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/logo.png) no-repeat center center;background-size:contain}}.site-title a{color:#484848;text-decoration:none}.site-description{position:absolute!important;width:1px;height:1px;overflow:hidden;clip:rect(0,0,0,0);word-wrap:normal!important;border:0}.content{max-width:100%;margin:0 auto}@media (min-width:880px){.content{float:left;width:72%;max-width:730px}}.sidebar{max-width:730px;margin:0 auto}@media (min-width:880px){.sidebar{float:right;width:25%}}.sidebar{font-size:16px;line-height:1.5}.sidebar p{margin-bottom:20px}.sidebar__block-title{font-size:20px;line-height:28px}.sidebar__block-content{margin-top:10px;margin-bottom:10px;font-size:14px;line-height:24px}.sidebar .widget{padding:24px;margin-bottom:10px;background-color:#f4f6fa}.sidebar__block{display:flex;flex-direction:column;align-items:center;justify-content:center;text-align:center}.sidebar__block h4{padding:0;margin:0}.sidebar__block h4 a{font-weight:700;color:#051e50;text-decoration:none}.sidebar__block img{margin-bottom:22px;box-shadow:0 15px 30px rgba(0,0,0,.08),0 10px 15px rgba(0,0,0,.12)}.sidebar__block a img{margin-bottom:0}.sidebar__block>:first-child{margin-bottom:20px}.entry-content>*{max-width:100%;margin:16px 0}@media (min-width:880px){.entry-content>*{margin:22px 0}}@media (min-width:1200px){.entry-content>*{margin:24px 0}}.entry-content>:first-child{margin-top:0}.entry-content>:last-child{margin-bottom:0}.pyi-page-hero{position:relative;padding:20px 0 50px}@media (min-width:880px){.pyi-page-hero{padding:60px 0 80px}}.pyi-page-hero::after{position:absolute;bottom:0;width:100%;height:100px;content:'';background-image:url(https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/wave.png?lossy=1&strip=1&webp=1);background-repeat:repeat-x;background-position:top center;background-size:cover}.single-post .pyi-page-hero::after{display:none;content:none}.pyi-page-hero>.wrap{position:relative}.pyi-page-hero .pyi-hero-left{position:absolute;top:20px;left:-290px;z-index:-1;width:250px;height:250px;background-image:url(https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/hero_bg_left.png?lossy=1&strip=1&webp=1);background-repeat:no-repeat;background-position:top center;background-size:contain}.pyi-page-hero .pyi-hero-right{position:absolute;top:-80px;right:-200px;z-index:-1;z-index:-1;width:400px;height:500px;background-image:url(https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/hero_bg_right.png?lossy=1&strip=1&webp=1);background-repeat:no-repeat;background-position:top center;background-size:contain}@media (max-width:879px){.pyi-page-hero .pyi-hero-right{display:none}}.pyi-page-hero .entry-title{max-width:730px}@media (min-width:640px){.footer-cta{display:flex;align-items:center}}.footer-cta input{width:100%;margin-bottom:5px;line-height:1.5;text-align:center;border:2px #6dc713 solid}@media (min-width:640px){.footer-cta input{width:52%;margin-bottom:0;line-height:1.15;text-align:left}}.footer-cta button{width:100%;padding:16px 14px 14px;font-weight:600;line-height:30px;color:#fff;text-align:center;text-transform:uppercase;letter-spacing:1.5px;background-color:#6dc713;border:none;font-size:16px}@media (min-width:640px){.footer-cta button{width:48%}}@media (min-width:1023px){.footer-cta button{padding:17px 14px 16px}}@media (min-width:640px){.footer-cta button{font-size:18px}}@media (min-width:880px){.footer-cta button{font-size:16px}}@media (min-width:1200px){.footer-cta button{font-size:16px}}::-moz-placeholder{color:#4d5a75;opacity:1}::-webkit-input-placeholder{color:#4d5a75}input,textarea{width:100%;padding:20px 24px 16px;font-weight:400;color:#051e50;background-color:#fff;border:2px solid #f4f6fa;font-size:16px}@media (min-width:640px){input,textarea{font-size:18px}}@media (min-width:880px){input,textarea{font-size:20px}}@media (min-width:1200px){input,textarea{font-size:20px}}input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-results-button{display:none}.search-form{position:relative;max-width:400px;overflow:hidden;border:1px solid #f4f6fa}.search-form .search-field{padding-right:32px;border:none}.search-form .search-submit{position:absolute;top:51%;right:32px;width:24px;min-width:0;height:24px;padding:0;margin:0;margin-top:-12px;text-align:center;background:0 0;border:none}.search-form .search-submit svg{fill:#169fe6}.nav-primary ul{width:100%;margin:0;clear:both;line-height:1}.nav-primary .menu-item{position:relative;float:left;list-style:none}.nav-primary .menu-item a{position:relative;display:block;font-weight:600;line-height:1;color:#051e50;text-decoration:none;border:none;font-size:18px}@media (min-width:640px){.nav-primary .menu-item a{font-size:18px}}@media (min-width:880px){.nav-primary .menu-item a{font-size:14px}}@media (min-width:1200px){.nav-primary .menu-item a{font-size:16px}}@media (max-width:920px){.nav-primary{position:absolute;right:10px;left:10px;z-index:999999;display:none;width:calc(100% - 20px);height:100%;padding:0;clear:both;background:#f4f6fa}.nav-primary .menu-primary{background-color:#051e50}}@media (min-width:921px){.nav-primary{float:right;width:auto}.nav-primary .menu>.menu-item.menu-item-has-children>a{padding-right:26px}.nav-primary .menu>.menu-item>a{padding:24px 12px;border-bottom:2px solid transparent}.nav-primary .menu>.menu-item>a span{padding-bottom:10px;border-bottom:2px solid transparent}.nav-primary .submenu-expand{position:absolute;top:50%;right:8px;margin-top:-5px;line-height:0}.nav-primary .submenu-expand svg{width:10px;height:10px}.nav-primary .sub-menu{position:absolute;left:-9999px;z-index:99;width:180px;background:#fff;box-shadow:0 15px 30px rgba(0,0,0,.08),0 10px 15px rgba(0,0,0,.12);opacity:0}.nav-primary .sub-menu .menu-item{float:none}.nav-primary .sub-menu .menu-item>a{padding:18px 16px 14px 16px;font-size:14px;border-bottom:1px solid #eceff5}}@media (min-width:1200px){.nav-primary .menu>.menu-item>a{padding:24px 16px}}.main-nav-wrap{display:block;float:right;width:auto}@media (min-width:920px){.main-nav-wrap{display:flex}}.nav-primary .is-topics>.sub-menu{width:auto;margin:0 32px 0 42px}@media (min-width:920px){.nav-primary .is-topics>.sub-menu{width:335px;margin-left:16px}}.nav-primary .is-topics .has-icon a{position:relative;padding-left:0}@media (min-width:920px){.nav-primary .is-topics .has-icon a{padding-left:42px}}.nav-primary .is-topics .has-icon a::before{position:absolute;top:13px;left:0;width:16px;height:16px;content:'';filter:brightness(0) invert(1)}@media (min-width:920px){.nav-primary .is-topics .has-icon a::before{top:16px;left:12px;width:16px;height:16px;filter:grayscale(1)}}.nav-primary .is-topics .has-icon.has-icon--deep-learning a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-deeplearning.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--dlib a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-dlib.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--iot a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-iot.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--face a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-face.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--image a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-image.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--interviews a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-interviews.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--keras a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-keras.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--ml a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-ml.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--medical a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-medical.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--ocr a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-ocr.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--object-detection a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-object_detection.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--object-tracking a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-object_tracking.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--opencv a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-opencv.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--pi a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-pi.png) no-repeat center center;background-size:contain}.nav-secondary{display:none;float:right;margin-top:10px}@media (min-width:920px){.nav-secondary{display:block}}.nav-secondary .wrap{margin:0}.nav-secondary ul{width:100%;margin:0;clear:both;line-height:1}.nav-secondary .menu-item{position:relative;float:left;margin-left:28px;list-style:none}@media (min-width:1200px){.nav-secondary .menu-item{margin-left:36px}}.nav-secondary .menu-item a{position:relative;display:block;font-size:16px;font-weight:400;color:#4d5a75;text-decoration:none;border:none;font-size:14px}@media (min-width:640px){.nav-secondary .menu-item a{font-size:14px}}@media (min-width:880px){.nav-secondary .menu-item a{font-size:15px 16px}}.nav-mobile{float:right;width:auto}@media (min-width:921px){.nav-mobile{display:none}}.mobile-menu-toggle{display:block;width:100%;padding:12px 20px 10px;margin-top:14px;font-size:13px;font-weight:700;text-transform:uppercase;letter-spacing:1px;background-color:#eceff5;border:none}.mobile-menu-toggle svg{margin:-2px 10px 0 0;fill:#051e50}.mobile-menu-toggle svg{vertical-align:middle}.mobile-menu-toggle .menu-close,.mobile-menu-toggle .mobile-menu-close{display:none}.header-search{position:relative;display:block;float:right;width:auto;margin:0 auto}@media (max-width:919px){.header-search ::-moz-placeholder{color:#4d5a75;opacity:1}.header-search ::-webkit-input-placeholder{color:#4d5a75}}.header-search input{margin-bottom:0}.header-search ::-moz-placeholder{color:#4d5a75;opacity:1}.header-search ::-webkit-input-placeholder{color:#4d5a75}.header-search .search-form{position:relative;z-index:99999;display:none;display:none;width:100%;margin:0 auto}.header-search .search-submit svg{fill:#169fe6}@media (min-width:920px){.header-search .search-submit svg{fill:#169fe6}}.header-search .mobile-search-toggle{display:block;padding:8px 11px 8px;margin:14px 0 0 4px;background-color:#169fe6;border:none;opacity:1}@media (min-width:920px){.header-search .mobile-search-toggle{position:relative;display:block;float:right;padding:11px 14px 7px;margin:6px -6px 0 16px;background-color:#169fe6}}@media (min-width:1200px){.header-search .mobile-search-toggle{padding:10px 19px 5px 17px;margin:12px 0 0 16px}}.header-search .mobile-search-toggle svg{fill:#fff;width:14px;height:14px;margin-top:calc((14px - 14px)/ 2)}@media (min-width:920px){.header-search .mobile-search-toggle svg{fill:#fff;width:16px;height:16px;margin-top:calc((16px - 16px)/ 2)}}.header-search .mobile-search-toggle .search-close{display:none}.nav-primary .mobile-only{display:block}@media (min-width:920px){.nav-primary .mobile-only{display:none}}.entry-content code{background-color:#f5f5f5}blockquote{font-style:italic;text-align:left;background:0 0}blockquote p{font-weight:400;line-height:1.5;color:#051e50}blockquote cite{display:block;margin-top:20px;font-weight:700;color:#4d5a75;font-size:16px}@media (min-width:640px){blockquote cite{font-size:18px}}blockquote cite .cite-title{display:block;font-weight:400}blockquote p:last-of-type{margin-bottom:0}blockquote::before{position:relative;top:-37px;left:-51px;display:block;height:0;font-size:90px;color:#169fe6;content:'\201C'}@media (min-width:640px){blockquote::before{top:-48px;left:-61px;font-size:110px}}@media (min-width:880px){blockquote::before{top:-48px;left:-55px;font-size:110px}}@media (min-width:1200px){blockquote::before{top:-58px;left:-71px;font-size:120px}}p.entry-meta{margin-bottom:0;font-size:14px}@media (min-width:640px){p.entry-meta{font-size:15px}}@media (min-width:880px){p.entry-meta{font-size:16px}}@media (min-width:1200px){p.entry-meta{font-size:16px}}.entry-categories{display:block}.widget{margin-bottom:60px}.widget a{font-weight:400;color:#4d5a75;text-decoration:underline}.modal{position:relative;z-index:2;box-sizing:border-box;display:none;width:90%;max-width:500px;padding:15px 30px;text-align:left;vertical-align:middle;background:#fff;border-radius:8px;box-shadow:0 0 10px #000;-webkit-border-radius:8px;-moz-border-radius:8px;-o-border-radius:8px;-ms-border-radius:8px;-webkit-box-shadow:0 0 10px #000;-moz-box-shadow:0 0 10px #000;-o-box-shadow:0 0 10px #000;-ms-box-shadow:0 0 10px #000}.modal a.close-modal{position:absolute;top:-12.5px;right:-12.5px;display:block;width:30px;height:30px;text-indent:-9999px;background-repeat:no-repeat;background-position:center center;background-size:contain}.front-page-modal.modal{width:96%;max-width:1110px;padding:20px 20px;border-radius:0}@media (min-width:640px){.front-page-modal.modal{padding:40px 40px}}@media (min-width:880px){.front-page-modal.modal{padding:50px 60px}}@media (min-width:1200px){.front-page-modal.modal{padding:60px 80px}}.front-page-modal.modal p{margin-bottom:24px;font-size:16px}@media (min-width:640px){.front-page-modal.modal p{font-size:18px}}@media (min-width:880px){.front-page-modal.modal p{font-size:18px}}.front-page-modal.modal .front-modal-top{text-align:center}.front-page-modal.modal .front-modal-top h3{margin-bottom:20px;line-height:1.4;font-size:24px}@media (min-width:640px){.front-page-modal.modal .front-modal-top h3{font-size:28px}}@media (min-width:880px){.front-page-modal.modal .front-modal-top h3{font-size:32px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-top h3{font-size:40px}}@media (min-width:880px){.front-page-modal.modal .front-modal-top h3{margin-bottom:40px}}.front-page-modal.modal .front-modal-action{max-width:730px;margin:20px auto}@media (min-width:880px){.front-page-modal.modal .front-modal-action{margin:40px auto}}.front-page-modal.modal .front-modal-action .footer-cta{display:block}@media (min-width:880px){.front-page-modal.modal .front-modal-action .footer-cta{display:flex}}@media (max-width:879px){.front-page-modal.modal .front-modal-action .footer-cta button,.front-page-modal.modal .front-modal-action .footer-cta input{width:100%;margin-bottom:4px;text-align:center}}.front-page-modal.modal .front-modal-video{display:grid;margin:30px auto 30px;grid-gap:30px;grid-template-columns:1fr}@media (min-width:880px){.front-page-modal.modal .front-modal-video{max-width:920px;margin:50px auto 60px;grid-template-columns:1fr 1fr;grid-gap:50px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-video{margin:60px auto 80px;grid-gap:80px}}.front-page-modal.modal .front-modal-testimonial{padding:24px 30px;margin:0 -20px -24px -20px;background-color:#f4f6fa}@media (min-width:640px){.front-page-modal.modal .front-modal-testimonial{padding:40px 50px;margin:0 -40px -40px -40px}}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial{padding:50px 60px;margin:0 -60px -50px -60px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-testimonial{padding:66px 80px;margin:0 -80px -60px -80px}}.front-page-modal.modal .front-modal-testimonial blockquote{max-width:730px;margin:0 auto 0 40px}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial blockquote{margin:0 auto}}.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:16px}@media (min-width:640px){.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:18px}}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:18px}}.front-page-modal.modal .front-modal-testimonial blockquote cite{margin-top:30px}.front-page-modal ul.is-style-list-checks li{position:relative;padding-left:40px;margin-bottom:15px;font-size:18px;font-weight:600;list-style-type:none}.front-page-modal ul.is-style-list-checks li::before{position:absolute;top:4px;left:0;width:20px;height:20px;content:'';background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/checks_blue.png) no-repeat center center;background-size:contain}.front-page-modal a.close-modal{background-color:#000}.single-post .pyi-page-hero .entry-meta{font-style:italic;color:#4d5a75}.single-post .pyi-page-hero .entry-meta .entry-author,.single-post .pyi-page-hero .entry-meta .entry-time{font-style:normal;font-weight:600}.single-post .pyi-page-hero .entry-meta .entry-categories{font-style:normal}.single-post .pyi-page-hero{padding-bottom:0}.single-post .pyi-page-hero .entry-title{max-width:730px;margin-bottom:20px}.single-post .entry-categories{margin-bottom:20px}.single-post .entry-categories a{display:inline-block;padding:6px 8px;margin-bottom:4px;font-size:13px;line-height:1;color:#4d5a75;text-transform:uppercase;letter-spacing:1px;background-color:#f4f6fa}@media (min-width:880px){.single-post .entry-categories a{margin-bottom:0}}.single-post .site-inner{padding-top:30px}.screen-reader-shortcut,.screen-reader-text{position:absolute!important;width:1px;height:1px;overflow:hidden;clip:rect(0,0,0,0);word-wrap:normal!important;border:0}.genesis-skip-link{margin:0}.genesis-skip-link li{width:0;height:0;list-style:none}.grecaptcha-badge{display:none!important}.enlighter-default .enlighter-raw{display:none;min-width:100%;line-height:inherit;font-size:1em;font-family:inherit;margin:0;padding:0;white-space:pre-wrap;word-wrap:break-word;border:none;box-shadow:none}.enlighter-default .enlighter-btn{display:inline-block;margin:0 5px 0 5px;padding:3px 5px 3px 5px;border:solid 1px #333;background-color:#f0f0f0;font-family:inherit}.enlighter-default .enlighter-toolbar .enlighter-btn-raw{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3C!DOCTYPE%20svg%20PUBLIC%20%22-%2F%2FW3C%2F%2FDTD%20SVG%201.1%2F%2FEN%22%20%22http%3A%2F%2Fwww.w3.org%2FGraphics%2FSVG%2F1.1%2FDTD%2Fsvg11.dtd%22%3E%0D%0A%3Csvg%20version%3D%221.1%22%20id%3D%22Ebene_2%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20x%3D%220px%22%20y%3D%220px%22%0D%0A%09%20width%3D%2246px%22%20height%3D%2246px%22%20viewBox%3D%220%200%2046%2046%22%20enable-background%3D%22new%200%200%2046%2046%22%20xml%3Aspace%3D%22preserve%22%3E%0D%0A%3Cg%3E%0D%0A%09%3Cpath%20d%3D%22M19.436%2C36.875L6.568%2C25.002v-3.863L19.436%2C9.267v5.041l-9.583%2C8.668v0.188l9.583%2C8.669V36.875z%22%2F%3E%0D%0A%09%3Cpath%20d%3D%22M26.343%2C36.875v-5.041l9.583-8.669v-0.188l-9.583-8.668V9.267l12.868%2C11.872v3.863L26.343%2C36.875z%22%2F%3E%0D%0A%3C%2Fg%3E%0D%0A%3C%2Fsvg%3E%0D%0A)}.enlighter-default .enlighter-toolbar .enlighter-btn-copy{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3C!DOCTYPE%20svg%20PUBLIC%20%22-%2F%2FW3C%2F%2FDTD%20SVG%201.1%2F%2FEN%22%20%22http%3A%2F%2Fwww.w3.org%2FGraphics%2FSVG%2F1.1%2FDTD%2Fsvg11.dtd%22%3E%0D%0A%3Csvg%20version%3D%221.1%22%20id%3D%22Ebene_2%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20x%3D%220px%22%20y%3D%220px%22%0D%0A%09%20width%3D%2246px%22%20height%3D%2246px%22%20viewBox%3D%220%200%2046%2046%22%20enable-background%3D%22new%200%200%2046%2046%22%20xml%3Aspace%3D%22preserve%22%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%2253.75%22%20y1%3D%2239.353%22%20x2%3D%2286.375%22%20y2%3D%2239.353%22%2F%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%2251.711%22%20y1%3D%2230.534%22%20x2%3D%2284.336%22%20y2%3D%2230.534%22%2F%3E%0D%0A%3Crect%20x%3D%228.932%22%20y%3D%227.334%22%20fill%3D%22%23FFFFFF%22%20stroke%3D%22%23000000%22%20stroke-width%3D%223%22%20stroke-miterlimit%3D%2210%22%20width%3D%2221.097%22%20height%3D%2224.952%22%2F%3E%0D%0A%3Crect%20x%3D%2218.942%22%20y%3D%2215.424%22%20fill%3D%22%23FFFFFF%22%20stroke%3D%22%23000000%22%20stroke-width%3D%223%22%20stroke-miterlimit%3D%2210%22%20width%3D%2221.096%22%20height%3D%2224.953%22%2F%3E%0D%0A%3C%2Fsvg%3E%0D%0A)}.enlighter-default .enlighter-toolbar .enlighter-btn-window{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3C!DOCTYPE%20svg%20PUBLIC%20%22-%2F%2FW3C%2F%2FDTD%20SVG%201.1%2F%2FEN%22%20%22http%3A%2F%2Fwww.w3.org%2FGraphics%2FSVG%2F1.1%2FDTD%2Fsvg11.dtd%22%3E%0D%0A%3Csvg%20version%3D%221.1%22%20id%3D%22Ebene_2%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20x%3D%220px%22%20y%3D%220px%22%0D%0A%09%20width%3D%2246px%22%20height%3D%2246px%22%20viewBox%3D%220%200%2046%2046%22%20enable-background%3D%22new%200%200%2046%2046%22%20xml%3Aspace%3D%22preserve%22%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%227.125%22%20y1%3D%229.25%22%20x2%3D%2239.75%22%20y2%3D%229.25%22%2F%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%227.125%22%20y1%3D%2218.167%22%20x2%3D%2239.75%22%20y2%3D%2218.167%22%2F%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%227.125%22%20y1%3D%2227.083%22%20x2%3D%2239.75%22%20y2%3D%2227.083%22%2F%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%227.125%22%20y1%3D%2236%22%20x2%3D%2229.809%22%20y2%3D%2236%22%2F%3E%0D%0A%3C%2Fsvg%3E%0D%0A)}.enlighter-default .enlighter-toolbar .enlighter-btn-website{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3C!DOCTYPE%20svg%20PUBLIC%20%22-%2F%2FW3C%2F%2FDTD%20SVG%201.1%2F%2FEN%22%20%22http%3A%2F%2Fwww.w3.org%2FGraphics%2FSVG%2F1.1%2FDTD%2Fsvg11.dtd%22%3E%0D%0A%3Csvg%20version%3D%221.1%22%20id%3D%22E%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20x%3D%220px%22%20y%3D%220px%22%0D%0A%09%20width%3D%2246px%22%20height%3D%2246px%22%20viewBox%3D%220%200%2046%2046%22%20enable-background%3D%22new%200%200%2046%2046%22%20xml%3Aspace%3D%22preserve%22%3E%0D%0A%3Cg%3E%0D%0A%09%3Cpath%20fill%3D%22%23202F65%22%20d%3D%22M32.48%2C25.614H19.64l-4.933%2C9.826l17.746%2C0.037l-6.173%2C5.358L8.167%2C40.912L16.29%2C6.055h22.974l-5.734%2C5.354%0D%0A%09%09l-13.306-0.027l0.672%2C8.797h12.841L32.48%2C25.614z%22%2F%3E%0D%0A%3C%2Fg%3E%0D%0A%3C%2Fsvg%3E%0D%0A)}.enlighter-origin{display:none!important}.enlighter-toolbar{display:none;position:absolute;right:10px;top:10px;z-index:10}.enlighter-toolbar-bottom{top:unset;bottom:0}html body{opacity:1!important}@font-face{font-family:proxima-nova;src:url("https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3") format("woff2");font-display:block;font-style:normal;font-weight:400}@font-face{font-family:proxima-nova;src:url("https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3") format("woff2");font-display:block;font-style:normal;font-weight:600}@font-face{font-family:proxima-nova;src:url("https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3") format("woff2");font-display:block;font-style:normal;font-weight:700}@font-face{font-family:'Bree Serif';font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/breeserif/v10/4UaHrEJCrhhnVA3DgluA96rp5w.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;src:url(https://fonts.gstatic.com/s/opensans/v20/mem5YaGs126MiZpBA-UN_r8OUuhp.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/opensans/v20/mem8YaGs126MiZpBA-UFVZ0b.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/opensans/v20/mem5YaGs126MiZpBA-UN7rgOUuhp.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:Muli;font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/muli/v22/7Auwp_0qiz-afTLGLQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:Roboto;font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmWUlfBBc4.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:Roboto;font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fBBc4.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:Roboto;font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu4mxK.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}.nav-mobile{float:right;width:auto}</style><style id="avlabs-rocket-critical-css">:root{--wp-admin-theme-color:#007cba;--wp-admin-theme-color-darker-10:#006ba1;--wp-admin-theme-color-darker-20:#005a87}.sticky{position:relative;z-index:0;-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0)}.sticky.is-anchored{position:relative;right:auto;left:auto}#pyis-cta-modal-sticky-bar{margin:1.25rem 0}#pyis-cta-modal-sticky-bar .grid-container{padding-right:.625rem;padding-left:.625rem;max-width:75rem;margin-left:auto;margin-right:auto}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-container{padding-right:.9375rem;padding-left:.9375rem}}#pyis-cta-modal-sticky-bar .grid-x{display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-flow:row wrap;-ms-flex-flow:row wrap;flex-flow:row wrap}#pyis-cta-modal-sticky-bar .cell{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;min-height:0;min-width:0;width:100%}#pyis-cta-modal-sticky-bar .grid-margin-x{margin-left:-.625rem;margin-right:-.625rem}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-margin-x{margin-left:-.9375rem;margin-right:-.9375rem}}#pyis-cta-modal-sticky-bar .grid-margin-x>.cell{width:calc(100% - 1.25rem);margin-left:.625rem;margin-right:.625rem}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-margin-x>.cell{width:calc(100% - 1.875rem);margin-left:.9375rem;margin-right:.9375rem}}#pyis-cta-modal-sticky-bar .text-center{text-align:center}#pyis-cta-modal-sticky-bar .sticky{background-color:#051e50;color:#fefefe;padding:1.625rem 1rem 1.25rem 1.625rem}#pyis-cta-modal-sticky-bar .sticky a{background:0 0;outline:0;font-size:1.2rem;padding:0;border-bottom:none;color:#fefefe;text-decoration:underline;position:relative}#pyis-cta-modal-sticky-bar .sticky a:before{position:absolute;top:-.5625rem;left:-3.75rem;display:block;width:2.5rem;height:2.5rem;content:'';background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/source_code_mini_image.png);background-size:contain}#pyis-cta-modal .modal-content{margin-top:1.5rem}#pyis-cta-modal .optin-modal-content .pyuni-logo{padding-bottom:20px;max-width:400px}#pyis-cta-modal .optin-modal-content h3{margin-bottom:20px;font-size:24px}#pyis-cta-modal .optin-modal-content .is-style-list-checks li{font-weight:400}button,input{overflow:visible}html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{margin:0.67em 0;font-size:2em}a{background-color:transparent}strong{font-weight:bolder}img{border-style:none}button,input{margin:0;font-family:inherit;font-size:100%;line-height:1.15}button{text-transform:none}[type='submit'],button{-webkit-appearance:button}[type='submit']::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}[type='submit']:-moz-focusring,button:-moz-focusring{outline:ButtonText dotted 1px}[type='search']{outline-offset:-2px;-webkit-appearance:textfield}[type='search']::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}html{box-sizing:border-box}*,*,*:after{box-sizing:inherit}.entry::before,.entry-content::before,.nav-primary::before,.nav-secondary::before,.site-container::before,.site-header::before,.site-inner::before,.widget::before,.wrap::before{display:table;content:" "}.entry::after,.entry-content::after,.nav-primary::after,.nav-secondary::after,.site-container::after,.site-header::after,.site-inner::after,.widget::after,.wrap::after{display:table;clear:both;content:""}html,input[type='search']{box-sizing:border-box}*,*:before,*:after{box-sizing:inherit}html{overflow-y:scroll;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}body{margin:0;font-family:proxima-nova,sans-serif;font-weight:400;line-height:1.472;color:#051e50;font-size:17px}@media (min-width:640px){body{line-height:1.52}}@media (min-width:880px){body{line-height:1.568}}@media (min-width:1200px){body{line-height:1.6}}@media (min-width:640px){body{font-size:19px}}@media (min-width:880px){body{font-size:20px}}a{font-weight:700;color:#169fe6;text-decoration:none}.entry-content a{border-bottom:1px solid #169fe6}:focus{outline:none}ul{padding:0;margin:0}li{list-style-type:none}em{font-style:italic}cite{font-style:normal}img{max-width:100%}img{display:block;height:auto}p{padding:0;margin:0 0 24px}@media (min-width:640px){p{margin:0 0 32px}}h1,h2,h3,h4{margin:0 0 30px;font-family:proxima-nova,sans-serif;font-weight:700}h4 a{color:#169fe6}h1{line-height:1.06;letter-spacing:-0.5px;font-size:40px}@media (min-width:640px){h1{font-size:48px}}@media (min-width:880px){h1{font-size:54px}}@media (min-width:1200px){h1{font-size:62px}}@media (min-width:880px){h1{letter-spacing:-1.5px}}@media (min-width:1200px){h1{letter-spacing:-2.5px}}h2{line-height:1.5;letter-spacing:-0.5px;font-size:28px}@media (min-width:640px){h2{font-size:32px}}@media (min-width:880px){h2{font-size:36px}}@media (min-width:1200px){h2{font-size:40px}}@media (min-width:880px){h2{letter-spacing:-1px}}h3{line-height:1.25;font-size:26px}@media (min-width:640px){h3{font-size:28px}}@media (min-width:880px){h3{font-size:30px}}@media (min-width:1200px){h3{font-size:32px}}h4{line-height:1.25;font-size:20px}@media (min-width:640px){h4{font-size:22px}}@media (min-width:880px){h4{font-size:22px}}@media (min-width:1200px){h4{font-size:24px}}.site-container{overflow-x:hidden;word-wrap:break-word}.site-inner{padding:24px 0;margin:0 auto;clear:both}@media (min-width:640px){.site-inner{padding:30px 0}}@media (min-width:880px){.site-inner{padding:48px 0}}@media (min-width:1200px){.site-inner{padding:60px 0}}.wrap{width:auto;max-width:100%;margin:0 16px}.wrap::before{display:table;content:" "}.wrap::after{display:table;clear:both;content:""}@media (min-width:640px){.wrap{margin:0 24px}}@media (min-width:880px){.wrap{margin:0 50px}}@media (min-width:1200px){.wrap{max-width:1110px;margin:0 auto}}@media (min-width:920px){.site-header{width:100%;padding:20px 0 10px}}@media (max-width:920px){.site-header>.wrap{margin:0 10px}}.title-area{position:relative;z-index:99999;float:left;padding:14px 0}@media (min-width:880px){.title-area{padding:8px 0}}.site-title{margin-bottom:0;font-weight:900;line-height:1;text-indent:-9999px;text-transform:uppercase;letter-spacing:2px;font-size:24px}@media (min-width:640px){.site-title{font-size:24px}}@media (min-width:880px){.site-title{font-size:30px}}@media (min-width:1200px){.site-title{font-size:30px}}.site-title a{display:block;width:140px;height:30px;background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/logo-mobile.png) no-repeat center center;background-size:contain}@media (min-width:400px){.site-title a{width:173px;height:36px}}@media (min-width:920px){.site-title a{width:220px;height:47px;margin-top:21px}}@media (min-width:1058px){.site-title a{width:348px;height:64px;margin-top:0;background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/logo.png) no-repeat center center;background-size:contain}}.site-title a{color:#484848;text-decoration:none}.site-description{position:absolute!important;width:1px;height:1px;overflow:hidden;clip:rect(0,0,0,0);word-wrap:normal!important;border:0}.content{max-width:100%;margin:0 auto}@media (min-width:880px){.content{float:left;width:72%;max-width:730px}}.sidebar{max-width:730px;margin:0 auto}@media (min-width:880px){.sidebar{float:right;width:25%}}.sidebar{font-size:16px;line-height:1.5}.sidebar p{margin-bottom:20px}.sidebar__block-title{font-size:20px;line-height:28px}.sidebar__block-content{margin-top:10px;margin-bottom:10px;font-size:14px;line-height:24px}.sidebar .widget{padding:24px;margin-bottom:10px;background-color:#f4f6fa}.sidebar__block{display:flex;flex-direction:column;align-items:center;justify-content:center;text-align:center}.sidebar__block h4{padding:0;margin:0}.sidebar__block h4 a{font-weight:700;color:#051e50;text-decoration:none}.sidebar__block img{margin-bottom:22px;box-shadow:0 15px 30px rgba(0,0,0,0.08),0 10px 15px rgba(0,0,0,0.12)}.sidebar__block a img{margin-bottom:0}.sidebar__block>:first-child{margin-bottom:20px}.entry-content>*{max-width:100%;margin:16px 0}@media (min-width:880px){.entry-content>*{margin:22px 0}}@media (min-width:1200px){.entry-content>*{margin:24px 0}}.entry-content>*:first-child{margin-top:0}.pyi-page-hero{position:relative;padding:20px 0 50px}@media (min-width:880px){.pyi-page-hero{padding:60px 0 80px}}.pyi-page-hero::after{position:absolute;bottom:0;width:100%;height:100px;content:'';background-image:url(https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/wave.png?lossy=1&strip=1&webp=1);background-repeat:repeat-x;background-position:top center;background-size:cover}.single-post .pyi-page-hero::after{display:none;content:none}.pyi-page-hero>.wrap{position:relative}.pyi-page-hero .pyi-hero-left{position:absolute;top:20px;left:-290px;z-index:-1;width:250px;height:250px;background-image:url(https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/hero_bg_left.png?lossy=1&strip=1&webp=1);background-repeat:no-repeat;background-position:top center;background-size:contain}.pyi-page-hero .pyi-hero-right{position:absolute;top:-80px;right:-200px;z-index:-1;z-index:-1;width:400px;height:500px;background-image:url(https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/hero_bg_right.png?lossy=1&strip=1&webp=1);background-repeat:no-repeat;background-position:top center;background-size:contain}@media (max-width:879px){.pyi-page-hero .pyi-hero-right{display:none}}.pyi-page-hero .entry-title{max-width:730px}@media (min-width:640px){.footer-cta{display:flex;align-items:center}}.footer-cta input{width:100%;margin-bottom:5px;line-height:1.5;text-align:center;border:2px #6dc713 solid}@media (min-width:640px){.footer-cta input{width:52%;margin-bottom:0;line-height:1.15;text-align:left}}.footer-cta button{width:100%;padding:16px 14px 14px;font-weight:600;line-height:30px;color:#fff;text-align:center;text-transform:uppercase;letter-spacing:1.5px;background-color:#6dc713;border:none;font-size:16px}@media (min-width:640px){.footer-cta button{width:48%}}@media (min-width:1023px){.footer-cta button{padding:17px 14px 16px}}@media (min-width:640px){.footer-cta button{font-size:18px}}@media (min-width:880px){.footer-cta button{font-size:16px}}@media (min-width:1200px){.footer-cta button{font-size:16px}}::-moz-placeholder{color:#4d5a75;opacity:1}::-webkit-input-placeholder{color:#4d5a75}input{width:100%;padding:20px 24px 16px;font-weight:400;color:#051e50;background-color:#fff;border:2px solid #f4f6fa;font-size:16px}@media (min-width:640px){input{font-size:18px}}@media (min-width:880px){input{font-size:20px}}@media (min-width:1200px){input{font-size:20px}}input[type='search']::-webkit-search-cancel-button,input[type='search']::-webkit-search-results-button{display:none}.search-form{position:relative;max-width:400px;overflow:hidden;border:1px solid #f4f6fa}.search-form .search-field{padding-right:32px;border:none}.search-form .search-submit{position:absolute;top:51%;right:32px;width:24px;min-width:0;height:24px;padding:0;margin:0;margin-top:-12px;text-align:center;background:transparent;border:none}.search-form .search-submit svg{fill:#169fe6}.nav-primary ul{width:100%;margin:0;clear:both;line-height:1}.nav-primary .menu-item{position:relative;float:left;list-style:none}.nav-primary .menu-item a{position:relative;display:block;font-weight:600;line-height:1;color:#051e50;text-decoration:none;border:none;font-size:18px}@media (min-width:640px){.nav-primary .menu-item a{font-size:18px}}@media (min-width:880px){.nav-primary .menu-item a{font-size:14px}}@media (min-width:1200px){.nav-primary .menu-item a{font-size:16px}}@media (max-width:920px){.nav-primary{position:absolute;right:10px;left:10px;z-index:999999;display:none;width:calc(100% - 20px);height:100%;padding:0;clear:both;background:#f4f6fa}.nav-primary .menu-primary{background-color:#051e50}}@media (min-width:921px){.nav-primary{float:right;width:auto}.nav-primary .menu>.menu-item.menu-item-has-children>a{padding-right:26px}.nav-primary .menu>.menu-item>a{padding:24px 12px;border-bottom:2px solid transparent}.nav-primary .menu>.menu-item>a span{padding-bottom:10px;border-bottom:2px solid transparent}.nav-primary .submenu-expand{position:absolute;top:50%;right:8px;margin-top:-5px;line-height:0}.nav-primary .submenu-expand svg{width:10px;height:10px}.nav-primary .sub-menu{position:absolute;left:-9999px;z-index:99;width:180px;background:#fff;box-shadow:0 15px 30px rgba(0,0,0,0.08),0 10px 15px rgba(0,0,0,0.12);opacity:0}.nav-primary .sub-menu .menu-item{float:none}.nav-primary .sub-menu .menu-item>a{padding:18px 16px 14px 16px;font-size:14px;border-bottom:1px solid #eceff5}}@media (min-width:1200px){.nav-primary .menu>.menu-item>a{padding:24px 16px}}.main-nav-wrap{display:block;float:right;width:auto}@media (min-width:920px){.main-nav-wrap{display:flex}}.nav-primary .is-topics>.sub-menu{width:auto;margin:0 32px 0 42px}@media (min-width:920px){.nav-primary .is-topics>.sub-menu{width:335px;margin-left:16px}}.nav-primary .is-topics .has-icon a{position:relative;padding-left:0px}@media (min-width:920px){.nav-primary .is-topics .has-icon a{padding-left:42px}}.nav-primary .is-topics .has-icon a::before{position:absolute;top:13px;left:0;width:16px;height:16px;content:'';filter:brightness(0) invert(1)}@media (min-width:920px){.nav-primary .is-topics .has-icon a::before{top:16px;left:12px;width:16px;height:16px;filter:grayscale(1)}}.nav-primary .is-topics .has-icon.has-icon--deep-learning a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-deeplearning.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--dlib a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-dlib.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--iot a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-iot.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--face a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-face.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--image a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-image.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--interviews a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-interviews.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--keras a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-keras.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--ml a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-ml.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--medical a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-medical.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--ocr a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-ocr.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--object-detection a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-object_detection.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--object-tracking a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-object_tracking.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--opencv a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-opencv.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--pi a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-pi.png) no-repeat center center;background-size:contain}.nav-secondary{display:none;float:right;margin-top:10px}@media (min-width:920px){.nav-secondary{display:block}}.nav-secondary .wrap{margin:0}.nav-secondary ul{width:100%;margin:0;clear:both;line-height:1}.nav-secondary .menu-item{position:relative;float:left;margin-left:28px;list-style:none}@media (min-width:1200px){.nav-secondary .menu-item{margin-left:36px}}.nav-secondary .menu-item a{position:relative;display:block;font-size:16px;font-weight:400;color:#4d5a75;text-decoration:none;border:none;font-size:14px}@media (min-width:640px){.nav-secondary .menu-item a{font-size:14px}}@media (min-width:880px){.nav-secondary .menu-item a{font-size:15px 16px}}.nav-mobile{float:right;width:auto}@media (min-width:921px){.nav-mobile{display:none}}.mobile-menu-toggle{display:block;width:100%;padding:12px 20px 10px;margin-top:14px;font-size:13px;font-weight:700;text-transform:uppercase;letter-spacing:1px;background-color:#eceff5;border:none}.mobile-menu-toggle svg{margin:-2px 10px 0 0;fill:#051e50}.mobile-menu-toggle svg{vertical-align:middle}.mobile-menu-toggle .menu-close,.mobile-menu-toggle .mobile-menu-close{display:none}.header-search{position:relative;display:block;float:right;width:auto;margin:0 auto}@media (max-width:919px){.header-search ::-moz-placeholder{color:#4d5a75;opacity:1}.header-search ::-webkit-input-placeholder{color:#4d5a75}}.header-search input{margin-bottom:0}.header-search ::-moz-placeholder{color:#4d5a75;opacity:1}.header-search ::-webkit-input-placeholder{color:#4d5a75}.header-search .search-form{position:relative;z-index:99999;display:none;display:none;width:100%;margin:0 auto}.header-search .search-submit svg{fill:#169fe6}@media (min-width:920px){.header-search .search-submit svg{fill:#169fe6}}.header-search .mobile-search-toggle{display:block;padding:8px 11px 8px;margin:14px 0 0 4px;background-color:#169fe6;border:none;opacity:1}@media (min-width:920px){.header-search .mobile-search-toggle{position:relative;display:block;float:right;padding:11px 14px 7px;margin:6px -6px 0 16px;background-color:#169fe6}}@media (min-width:1200px){.header-search .mobile-search-toggle{padding:10px 19px 5px 17px;margin:12px 0 0 16px}}.header-search .mobile-search-toggle svg{fill:#fff;width:14px;height:14px;margin-top:calc((14px - 14px) / 2)}@media (min-width:920px){.header-search .mobile-search-toggle svg{fill:#fff;width:16px;height:16px;margin-top:calc((16px - 16px) / 2)}}.header-search .mobile-search-toggle .search-close{display:none}.nav-primary .mobile-only{display:block}@media (min-width:920px){.nav-primary .mobile-only{display:none}}blockquote{font-style:italic;text-align:left;background:transparent}blockquote p{font-weight:400;line-height:1.5;color:#051e50}blockquote cite{display:block;margin-top:20px;font-weight:700;color:#4d5a75;font-size:16px}@media (min-width:640px){blockquote cite{font-size:18px}}blockquote cite .cite-title{display:block;font-weight:400}blockquote p:last-of-type{margin-bottom:0}blockquote::before{position:relative;top:-37px;left:-51px;display:block;height:0;font-size:90px;color:#169fe6;content:'\201C'}@media (min-width:640px){blockquote::before{top:-48px;left:-61px;font-size:110px}}@media (min-width:880px){blockquote::before{top:-48px;left:-55px;font-size:110px}}@media (min-width:1200px){blockquote::before{top:-58px;left:-71px;font-size:120px}}p.entry-meta{margin-bottom:0;font-size:14px}@media (min-width:640px){p.entry-meta{font-size:15px}}@media (min-width:880px){p.entry-meta{font-size:16px}}@media (min-width:1200px){p.entry-meta{font-size:16px}}.entry-categories{display:block}.widget{margin-bottom:60px}.widget a{font-weight:400;color:#4d5a75;text-decoration:underline}.modal{position:relative;z-index:2;box-sizing:border-box;display:none;width:90%;max-width:500px;padding:15px 30px;text-align:left;vertical-align:middle;background:#fff;border-radius:8px;box-shadow:0 0 10px #000;-webkit-border-radius:8px;-moz-border-radius:8px;-o-border-radius:8px;-ms-border-radius:8px;-webkit-box-shadow:0 0 10px #000;-moz-box-shadow:0 0 10px #000;-o-box-shadow:0 0 10px #000;-ms-box-shadow:0 0 10px #000}.modal a.close-modal{position:absolute;top:-12.5px;right:-12.5px;display:block;width:30px;height:30px;text-indent:-9999px;background-repeat:no-repeat;background-position:center center;background-size:contain}.front-page-modal.modal{width:96%;max-width:1110px;padding:20px 20px;border-radius:0}@media (min-width:640px){.front-page-modal.modal{padding:40px 40px}}@media (min-width:880px){.front-page-modal.modal{padding:50px 60px}}@media (min-width:1200px){.front-page-modal.modal{padding:60px 80px}}.front-page-modal.modal p{margin-bottom:24px;font-size:16px}@media (min-width:640px){.front-page-modal.modal p{font-size:18px}}@media (min-width:880px){.front-page-modal.modal p{font-size:18px}}.front-page-modal.modal .front-modal-top{text-align:center}.front-page-modal.modal .front-modal-top h3{margin-bottom:20px;line-height:1.4;font-size:24px}@media (min-width:640px){.front-page-modal.modal .front-modal-top h3{font-size:28px}}@media (min-width:880px){.front-page-modal.modal .front-modal-top h3{font-size:32px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-top h3{font-size:40px}}@media (min-width:880px){.front-page-modal.modal .front-modal-top h3{margin-bottom:40px}}.front-page-modal.modal .front-modal-action{max-width:730px;margin:20px auto}@media (min-width:880px){.front-page-modal.modal .front-modal-action{margin:40px auto}}.front-page-modal.modal .front-modal-action .footer-cta{display:block}@media (min-width:880px){.front-page-modal.modal .front-modal-action .footer-cta{display:flex}}@media (max-width:879px){.front-page-modal.modal .front-modal-action .footer-cta input,.front-page-modal.modal .front-modal-action .footer-cta button{width:100%;margin-bottom:4px;text-align:center}}.front-page-modal.modal .front-modal-video{display:grid;margin:30px auto 30px;grid-gap:30px;grid-template-columns:1fr}@media (min-width:880px){.front-page-modal.modal .front-modal-video{max-width:920px;margin:50px auto 60px;grid-template-columns:1fr 1fr;grid-gap:50px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-video{margin:60px auto 80px;grid-gap:80px}}.front-page-modal.modal .front-modal-testimonial{padding:24px 30px;margin:0 -20px -24px -20px;background-color:#f4f6fa}@media (min-width:640px){.front-page-modal.modal .front-modal-testimonial{padding:40px 50px;margin:0 -40px -40px -40px}}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial{padding:50px 60px;margin:0 -60px -50px -60px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-testimonial{padding:66px 80px;margin:0 -80px -60px -80px}}.front-page-modal.modal .front-modal-testimonial blockquote{max-width:730px;margin:0 auto 0 40px}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial blockquote{margin:0 auto}}.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:16px}@media (min-width:640px){.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:18px}}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:18px}}.front-page-modal.modal .front-modal-testimonial blockquote cite{margin-top:30px}.front-page-modal ul.is-style-list-checks li{position:relative;padding-left:40px;margin-bottom:15px;font-size:18px;font-weight:600;list-style-type:none}.front-page-modal ul.is-style-list-checks li::before{position:absolute;top:4px;left:0;width:20px;height:20px;content:'';background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/checks_blue.png) no-repeat center center;background-size:contain}.front-page-modal a.close-modal{background-color:#000}.single-post .pyi-page-hero .entry-meta{font-style:italic;color:#4d5a75}.single-post .pyi-page-hero .entry-meta .entry-author,.single-post .pyi-page-hero .entry-meta .entry-time{font-style:normal;font-weight:600}.single-post .pyi-page-hero .entry-meta .entry-categories{font-style:normal}.single-post .pyi-page-hero{padding-bottom:0}.single-post .pyi-page-hero .entry-title{max-width:730px;margin-bottom:20px}.single-post .entry-categories{margin-bottom:20px}.single-post .entry-categories a{display:inline-block;padding:6px 8px;margin-bottom:4px;font-size:13px;line-height:1;color:#4d5a75;text-transform:uppercase;letter-spacing:1px;background-color:#f4f6fa}@media (min-width:880px){.single-post .entry-categories a{margin-bottom:0}}.single-post .site-inner{padding-top:30px}.screen-reader-shortcut,.screen-reader-text{position:absolute!important;width:1px;height:1px;overflow:hidden;clip:rect(0,0,0,0);word-wrap:normal!important;border:0}.genesis-skip-link{margin:0}.genesis-skip-link li{width:0;height:0;list-style:none}</style><link rel="stylesheet" href="./Image Stitching with OpenCV and Python - PyImageSearch_files/eef0bf32586d57e4ed24eb224ecbaf2f.css" media="all" type="text/css"><style id="avlabs-custom-critical-css-after-rocket">.aligncenter,img.centered{display:block;margin:0 auto}#loader-wrapper{display:none}.pyi-top-bar{position:sticky;top:0;z-index:999999;width:100%;padding:16px 0 14px;font-weight:600;color:#fff;text-align:center;background-color:#051e50;font-size:14px}

#release_bar {
    height: 69px;
}

</style>
	<meta name="description" content="In this tutorial you will learn how to perform multiple image stitching using Python, OpenCV, and the cv2.createSticher and cv2.Stitcher_create functions.">
	<link rel="canonical" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/">
	<meta property="og:locale" content="en_US">
	<meta property="og:type" content="article">
	<meta property="og:title" content="Image Stitching with OpenCV and Python - PyImageSearch">
	<meta property="og:description" content="In this tutorial you will learn how to perform multiple image stitching using Python, OpenCV, and the cv2.createSticher and cv2.Stitcher_create functions.">
	<meta property="og:url" content="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/">
	<meta property="og:site_name" content="PyImageSearch">
	<meta property="article:published_time" content="2018-12-17T15:00:43+00:00">
	<meta property="article:modified_time" content="2021-04-17T18:09:40+00:00">
	<meta property="og:image" content="https://pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg">
	<meta property="og:image:width" content="600">
	<meta property="og:image:height" content="378">
	<meta property="og:image:type" content="image/jpeg">
	<meta name="author" content="Adrian Rosebrock">
	<meta name="twitter:label1" content="Written by">
	<meta name="twitter:data1" content="Adrian Rosebrock">
	<meta name="twitter:label2" content="Est. reading time">
	<meta name="twitter:data2" content="20 minutes">
	<script type="text/javascript" async="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/4768429.js.download"></script><script type="text/javascript" async="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/1871593262.js.download"></script><script type="text/javascript" async="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/recaptcha__en.js.download" crossorigin="anonymous" integrity="sha384-ALtiHf0DOZRoBKnCKTk/SlH3koiTb5V8tXxijiVbKfgMusXfsD91H2zPixteloxy"></script><script type="application/ld+json" class="yoast-schema-graph">{"@context":"https://schema.org","@graph":[{"@type":"WebPage","@id":"https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/","url":"https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/","name":"Image Stitching with OpenCV and Python - PyImageSearch","isPartOf":{"@id":"https://pyimagesearch.com/#website"},"primaryImageOfPage":{"@id":"https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#primaryimage"},"image":{"@id":"https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#primaryimage"},"thumbnailUrl":"https://pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg","datePublished":"2018-12-17T15:00:43+00:00","dateModified":"2021-04-17T18:09:40+00:00","author":{"@id":"https://pyimagesearch.com/#/schema/person/5901b399e2f20b986362a00636181cca"},"description":"In this tutorial you will learn how to perform multiple image stitching using Python, OpenCV, and the cv2.createSticher and cv2.Stitcher_create functions.","breadcrumb":{"@id":"https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/"]}]},{"@type":"ImageObject","inLanguage":"en-US","@id":"https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#primaryimage","url":"https://pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg","contentUrl":"https://pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg","width":600,"height":378},{"@type":"BreadcrumbList","@id":"https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://pyimagesearch.com/"},{"@type":"ListItem","position":2,"name":"Blog","item":"https://pyimagesearch.com/blog/"},{"@type":"ListItem","position":3,"name":"Image Stitching with OpenCV and Python"}]},{"@type":"WebSite","@id":"https://pyimagesearch.com/#website","url":"https://pyimagesearch.com/","name":"PyImageSearch","description":"You can master Computer Vision, Deep Learning, and OpenCV - PyImageSearch","potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://pyimagesearch.com/?s={search_term_string}"},"query-input":"required name=search_term_string"}],"inLanguage":"en-US"},{"@type":"Person","@id":"https://pyimagesearch.com/#/schema/person/5901b399e2f20b986362a00636181cca","name":"Adrian Rosebrock","image":{"@type":"ImageObject","inLanguage":"en-US","@id":"https://pyimagesearch.com/#/schema/person/image/","url":"https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g","contentUrl":"https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g","caption":"Adrian Rosebrock"},"description":"Hi there, I’m Adrian Rosebrock, PhD. All too often I see developers, students, and researchers wasting their time, studying the wrong things, and generally struggling to get started with Computer Vision, Deep Learning, and OpenCV. I created this website to show you what I believe is the best possible way to get your start.","url":"https://pyimagesearch.com/author/adrian/"}]}</script>
	<!-- / Yoast SEO plugin. -->


<link rel="dns-prefetch" href="https://pyimagesearch.com/">
<link rel="dns-prefetch" href="https://www.google.com/">
<link rel="dns-prefetch" href="https://a.omappapi.com/">
<link rel="dns-prefetch" href="https://use.typekit.net/">
<link rel="dns-prefetch" href="https://929687.smushcdn.com/">

<link rel="alternate" type="application/rss+xml" title="PyImageSearch » Feed" href="https://pyimagesearch.com/feed/">
<link rel="alternate" type="application/rss+xml" title="PyImageSearch » Comments Feed" href="https://pyimagesearch.com/comments/feed/">
<link rel="alternate" type="application/rss+xml" title="PyImageSearch » Image Stitching with OpenCV and Python Comments Feed" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/feed/">

<style id="global-styles-inline-css" type="text/css">
body{--wp--preset--color--black: #051e50;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--color--green: #6dc713;--wp--preset--color--blue: #169fe6;--wp--preset--color--dark-blue: #051e50;--wp--preset--color--dark-grey: #4d5a75;--wp--preset--color--grey: #eceff5;--wp--preset--color--light-grey: #f4f6fa;--wp--preset--color--blue-soft: #F4F6FA;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--duotone--dark-grayscale: url('#wp-duotone-dark-grayscale');--wp--preset--duotone--grayscale: url('#wp-duotone-grayscale');--wp--preset--duotone--purple-yellow: url('#wp-duotone-purple-yellow');--wp--preset--duotone--blue-red: url('#wp-duotone-blue-red');--wp--preset--duotone--midnight: url('#wp-duotone-midnight');--wp--preset--duotone--magenta-yellow: url('#wp-duotone-magenta-yellow');--wp--preset--duotone--purple-green: url('#wp-duotone-purple-green');--wp--preset--duotone--blue-orange: url('#wp-duotone-blue-orange');--wp--preset--font-size--small: 16px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 24px;--wp--preset--font-size--x-large: 42px;--wp--preset--font-size--regular: 20px;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
</style>









<style id="rocket-lazyload-inline-css" type="text/css">
.rll-youtube-player{position:relative;padding-bottom:56.23%;height:0;overflow:hidden;max-width:100%;}.rll-youtube-player:focus-within{outline: 2px solid currentColor;outline-offset: 5px;}.rll-youtube-player iframe{position:absolute;top:0;left:0;width:100%;height:100%;z-index:100;background:0 0}.rll-youtube-player img{bottom:0;display:block;left:0;margin:auto;max-width:100%;width:100%;position:absolute;right:0;top:0;border:none;height:auto;-webkit-transition:.4s all;-moz-transition:.4s all;transition:.4s all}.rll-youtube-player img:hover{-webkit-filter:brightness(75%)}.rll-youtube-player .play{height:100%;width:100%;left:0;top:0;position:absolute;background:url(https://pyimagesearch.com/wp-content/plugins/wp-rocket/assets/img/youtube.png) no-repeat center;background-color: transparent !important;cursor:pointer;border:none;}.wp-embed-responsive .wp-has-aspect-ratio .rll-youtube-player{position:absolute;padding-bottom:0;width:100%;height:100%;top:0;bottom:0;left:0;right:0}
</style>






<link rel="https://api.w.org/" href="https://pyimagesearch.com/wp-json/"><link rel="alternate" type="application/json" href="https://pyimagesearch.com/wp-json/wp/v2/posts/9285"><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://pyimagesearch.com/xmlrpc.php?rsd">
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://pyimagesearch.com/wp-includes/wlwmanifest.xml"> 
<meta name="generator" content="WordPress 6.0.3">
<link rel="shortlink" href="https://pyimagesearch.com/?p=9285">
<link rel="alternate" type="application/json+oembed" href="https://pyimagesearch.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fpyimagesearch.com%2F2018%2F12%2F17%2Fimage-stitching-with-opencv-and-python%2F">
<link rel="alternate" type="text/xml+oembed" href="https://pyimagesearch.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fpyimagesearch.com%2F2018%2F12%2F17%2Fimage-stitching-with-opencv-and-python%2F&amp;format=xml">
    
    

<link rel="preload" as="font" href="https://pyimagesearch.com/wp-content/plugins/ultimate-faqs/assets/fonts/ewd-toggle-icon.woff2" crossorigin=""><link rel="pingback" href="https://pyimagesearch.com/xmlrpc.php">
<style type="text/css">
/* <![CDATA[ */
img.latex { vertical-align: middle; border: none; }
/* ]]> */
</style>
		<style type="text/css" id="wp-custom-css">
			.grecaptcha-badge {  
    display: none !important;
}

img.latex {
	margin: 0!important;
	display: inline!important;
}

.entry-content > .aligncenter {
	margin-left: auto;
	margin-right: auto;
} 

.page-template-page_success_stories .success-story-all .success-story-item {
	break-inside: avoid;
	float: none;
}
.site-title a {
    width: 160px;
	height: 50px;align-content}
@media (min-width: 1058px){
.site-title a {
	width: 300px;
  height: 90px;
}}		</style>
		<noscript><style id="rocket-lazyload-nojs-css">.rll-youtube-player, [data-lazy-src]{display:none !important;}</style></noscript><script>
/*! loadCSS rel=preload polyfill. [c]2017 Filament Group, Inc. MIT License */
(function(w){"use strict";if(!w.loadCSS){w.loadCSS=function(){}}
var rp=loadCSS.relpreload={};rp.support=(function(){var ret;try{ret=w.document.createElement("link").relList.supports("preload")}catch(e){ret=!1}
return function(){return ret}})();rp.bindMediaToggle=function(link){var finalMedia=link.media||"all";function enableStylesheet(){link.media=finalMedia}
if(link.addEventListener){link.addEventListener("load",enableStylesheet)}else if(link.attachEvent){link.attachEvent("onload",enableStylesheet)}
setTimeout(function(){link.rel="stylesheet";link.media="only x"});setTimeout(enableStylesheet,3000)};rp.poly=function(){if(rp.support()){return}
var links=w.document.getElementsByTagName("link");for(var i=0;i<links.length;i++){var link=links[i];if(link.rel==="preload"&&link.getAttribute("as")==="style"&&!link.getAttribute("data-loadcss")){link.setAttribute("data-loadcss",!0);rp.bindMediaToggle(link)}}};if(!rp.support()){rp.poly();var run=w.setInterval(rp.poly,500);if(w.addEventListener){w.addEventListener("load",function(){rp.poly();w.clearInterval(run)})}else if(w.attachEvent){w.attachEvent("onload",function(){rp.poly();w.clearInterval(run)})}}
if(typeof exports!=="undefined"){exports.loadCSS=loadCSS}
else{w.loadCSS=loadCSS}}(typeof global!=="undefined"?global:this))
</script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/j.php" type="text/javascript"></script><style>@import url(https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&family=Plus+Jakarta+Sans:wght@300;400;500;600;700;800&display=swap);</style><style>.MuiTooltip-popper{z-index:10000000 !important}
</style><style>@font-face {
	font-family: "wticons";
	src: url("data:font/woff2;charset=utf-8;base64,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") format("woff2");
}

.wticons {
	line-height: 1;
}

.wticons:before {
	font-family: wticons !important;
	font-style: normal;
	font-weight: normal !important;
	vertical-align: top;
}

.wticon-account:before {
	content: "\f101";
}
.wticon-add:before {
	content: "\f102";
}
.wticon-cardResizeDrag:before {
	content: "\f103";
}
.wticon-casual:before {
	content: "\f104";
}
.wticon-check:before {
	content: "\f105";
}
.wticon-checkSmall:before {
	content: "\f106";
}
.wticon-chevron:before {
	content: "\f107";
}
.wticon-copy:before {
	content: "\f108";
}
.wticon-copySmall:before {
	content: "\f109";
}
.wticon-dismiss:before {
	content: "\f10a";
}
.wticon-downChevron:before {
	content: "\f10b";
}
.wticon-error:before {
	content: "\f10c";
}
.wticon-expand:before {
	content: "\f10d";
}
.wticon-feedback:before {
	content: "\f10e";
}
.wticon-filledDownArrow:before {
	content: "\f10f";
}
.wticon-find:before {
	content: "\f110";
}
.wticon-formal:before {
	content: "\f111";
}
.wticon-gift:before {
	content: "\f112";
}
.wticon-grayLogo:before {
	content: "\f113";
}
.wticon-ignore:before {
	content: "\f114";
}
.wticon-info:before {
	content: "\f115";
}
.wticon-leftChevron:before {
	content: "\f116";
}
.wticon-logo:before {
	content: "\f117";
}
.wticon-love:before {
	content: "\f118";
}
.wticon-noRecommendations:before {
	content: "\f119";
}
.wticon-paragraphRewrite:before {
	content: "\f11a";
}
.wticon-paste:before {
	content: "\f11b";
}
.wticon-pin:before {
	content: "\f11c";
}
.wticon-premium:before {
	content: "\f11d";
}
.wticon-premiumDetail:before {
	content: "\f11e";
}
.wticon-premiumFull:before {
	content: "\f11f";
}
.wticon-recommendationLight:before {
	content: "\f120";
}
.wticon-recommendationLightCard:before {
	content: "\f121";
}
.wticon-recommendationLightNoSuggestions:before {
	content: "\f122";
}
.wticon-refine:before {
	content: "\f123";
}
.wticon-rewrite:before {
	content: "\f124";
}
.wticon-rightChevron:before {
	content: "\f125";
}
.wticon-rocket:before {
	content: "\f126";
}
.wticon-sentenceExamples:before {
	content: "\f127";
}
.wticon-settings:before {
	content: "\f128";
}
.wticon-shorten:before {
	content: "\f129";
}
.wticon-tutorial:before {
	content: "\f12a";
}
.wticon-unlock:before {
	content: "\f12b";
}
.wticon-warn:before {
	content: "\f12c";
}
.wticon-WordtuneButton:before {
	content: "\f12d";
}
.wticon-x:before {
	content: "\f12e";
}

/*# sourceMappingURL=data:application/json;base64,{"version":3,"sources":["webpack://src/shared/Icons.font.js"],"names":[],"mappings":"AAAA;CACC,sBAAsB;CACtB,63SAA63S;AAC93S;;AAEA;CACC,cAAc;AACf;;AAEA;CACC,+BAA+B;CAC/B,kBAAkB;CAClB,8BAA8B;CAC9B,mBAAmB;AACpB;;AAEA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB","sourcesContent":["@font-face {\n\tfont-family: \"wticons\";\n\tsrc: url(\"data:font/woff2;charset=utf-8;base64,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\") format(\"woff2\");\n}\n\n.wticons {\n\tline-height: 1;\n}\n\n.wticons:before {\n\tfont-family: wticons !important;\n\tfont-style: normal;\n\tfont-weight: normal !important;\n\tvertical-align: top;\n}\n\n.wticon-account:before {\n\tcontent: \"\\f101\";\n}\n.wticon-add:before {\n\tcontent: \"\\f102\";\n}\n.wticon-cardResizeDrag:before {\n\tcontent: \"\\f103\";\n}\n.wticon-casual:before {\n\tcontent: \"\\f104\";\n}\n.wticon-check:before {\n\tcontent: \"\\f105\";\n}\n.wticon-checkSmall:before {\n\tcontent: \"\\f106\";\n}\n.wticon-chevron:before {\n\tcontent: \"\\f107\";\n}\n.wticon-copy:before {\n\tcontent: \"\\f108\";\n}\n.wticon-copySmall:before {\n\tcontent: \"\\f109\";\n}\n.wticon-dismiss:before {\n\tcontent: \"\\f10a\";\n}\n.wticon-downChevron:before {\n\tcontent: \"\\f10b\";\n}\n.wticon-error:before {\n\tcontent: \"\\f10c\";\n}\n.wticon-expand:before {\n\tcontent: \"\\f10d\";\n}\n.wticon-feedback:before {\n\tcontent: \"\\f10e\";\n}\n.wticon-filledDownArrow:before {\n\tcontent: \"\\f10f\";\n}\n.wticon-find:before {\n\tcontent: \"\\f110\";\n}\n.wticon-formal:before {\n\tcontent: \"\\f111\";\n}\n.wticon-gift:before {\n\tcontent: \"\\f112\";\n}\n.wticon-grayLogo:before {\n\tcontent: \"\\f113\";\n}\n.wticon-ignore:before {\n\tcontent: \"\\f114\";\n}\n.wticon-info:before {\n\tcontent: \"\\f115\";\n}\n.wticon-leftChevron:before {\n\tcontent: \"\\f116\";\n}\n.wticon-logo:before {\n\tcontent: \"\\f117\";\n}\n.wticon-love:before {\n\tcontent: \"\\f118\";\n}\n.wticon-noRecommendations:before {\n\tcontent: \"\\f119\";\n}\n.wticon-paragraphRewrite:before {\n\tcontent: \"\\f11a\";\n}\n.wticon-paste:before {\n\tcontent: \"\\f11b\";\n}\n.wticon-pin:before {\n\tcontent: \"\\f11c\";\n}\n.wticon-premium:before {\n\tcontent: \"\\f11d\";\n}\n.wticon-premiumDetail:before {\n\tcontent: \"\\f11e\";\n}\n.wticon-premiumFull:before {\n\tcontent: \"\\f11f\";\n}\n.wticon-recommendationLight:before {\n\tcontent: \"\\f120\";\n}\n.wticon-recommendationLightCard:before {\n\tcontent: \"\\f121\";\n}\n.wticon-recommendationLightNoSuggestions:before {\n\tcontent: \"\\f122\";\n}\n.wticon-refine:before {\n\tcontent: \"\\f123\";\n}\n.wticon-rewrite:before {\n\tcontent: \"\\f124\";\n}\n.wticon-rightChevron:before {\n\tcontent: \"\\f125\";\n}\n.wticon-rocket:before {\n\tcontent: \"\\f126\";\n}\n.wticon-sentenceExamples:before {\n\tcontent: \"\\f127\";\n}\n.wticon-settings:before {\n\tcontent: \"\\f128\";\n}\n.wticon-shorten:before {\n\tcontent: \"\\f129\";\n}\n.wticon-tutorial:before {\n\tcontent: \"\\f12a\";\n}\n.wticon-unlock:before {\n\tcontent: \"\\f12b\";\n}\n.wticon-warn:before {\n\tcontent: \"\\f12c\";\n}\n.wticon-WordtuneButton:before {\n\tcontent: \"\\f12d\";\n}\n.wticon-x:before {\n\tcontent: \"\\f12e\";\n}\n"],"sourceRoot":""} */</style><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/jquery.js.download"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/f67da8ef1bb72583a9be2d03590e071d_avlabs_primary_script.js.download"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/avlabs-mobile-menu.js.download"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/avlabs-preloader.js.download"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/stickykit.min.js.download"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/kno0cmko2z.jsonp"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/8ggk996ods.jsonp"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/api.js.download"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/js"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/enlighterjs.min.js.download"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/ede493e5bb638499b98e1abc76c95105.js.download"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/skip-links.min.js.download"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/modal-min.js.download"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/avlabs-lazy-load.js.download"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/jquery.flexslider.min.js.download"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/global-min.js.download"></script><script src="./Image Stitching with OpenCV and Python - PyImageSearch_files/lazyload.min.js.download"></script><script type="text/javascript" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/api.min.js.download" async="" data-user="18464" data-campaign="vksgrjuaic5dopynajjn"></script><meta class="foundation-mq"><script type="text/javascript" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/api.min.js.download" async="" id="omapi-script"></script><style data-jss="" data-meta="MuiSnackbar">
.MuiSnackbar-root {
  left: 8px;
  right: 8px;
  display: flex;
  z-index: 1400;
  position: fixed;
  align-items: center;
  justify-content: center;
}
.MuiSnackbar-anchorOriginTopCenter {
  top: 8px;
}
@media (min-width:600px) {
  .MuiSnackbar-anchorOriginTopCenter {
    top: 24px;
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginBottomCenter {
  bottom: 8px;
}
@media (min-width:600px) {
  .MuiSnackbar-anchorOriginBottomCenter {
    left: 50%;
    right: auto;
    bottom: 24px;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginTopRight {
  top: 8px;
  justify-content: flex-end;
}
@media (min-width:600px) {
  .MuiSnackbar-anchorOriginTopRight {
    top: 24px;
    left: auto;
    right: 24px;
  }
}
.MuiSnackbar-anchorOriginBottomRight {
  bottom: 8px;
  justify-content: flex-end;
}
@media (min-width:600px) {
  .MuiSnackbar-anchorOriginBottomRight {
    left: auto;
    right: 24px;
    bottom: 24px;
  }
}
.MuiSnackbar-anchorOriginTopLeft {
  top: 8px;
  justify-content: flex-start;
}
@media (min-width:600px) {
  .MuiSnackbar-anchorOriginTopLeft {
    top: 24px;
    left: 24px;
    right: auto;
  }
}
.MuiSnackbar-anchorOriginBottomLeft {
  bottom: 8px;
  justify-content: flex-start;
}
@media (min-width:600px) {
  .MuiSnackbar-anchorOriginBottomLeft {
    left: 24px;
    right: auto;
    bottom: 24px;
  }
}
</style><style data-emotion="css" data-s=""></style><style type="text/css">.rm-c,.rm-c a,.rm-c abbr,.rm-c acronym,.rm-c address,.rm-c applet,.rm-c area,.rm-c article,.rm-c aside,.rm-c audio,.rm-c b,.rm-c big,.rm-c blockquote,.rm-c button,.rm-c canvas,.rm-c caption,.rm-c cite,.rm-c code,.rm-c col,.rm-c colgroup,.rm-c datalist,.rm-c dd,.rm-c del,.rm-c dfn,.rm-c div,.rm-c dl,.rm-c dt,.rm-c em,.rm-c fieldset,.rm-c figcaption,.rm-c figure,.rm-c footer,.rm-c form,.rm-c h1,.rm-c h2,.rm-c h3,.rm-c h4,.rm-c h5,.rm-c h6,.rm-c header,.rm-c hr,.rm-c i,.rm-c iframe,.rm-c img,.rm-c input,.rm-c ins,.rm-c kbd,.rm-c label,.rm-c legend,.rm-c li,.rm-c main,.rm-c map,.rm-c mark,.rm-c menu,.rm-c meta,.rm-c nav,.rm-c object,.rm-c ol,.rm-c optgroup,.rm-c option,.rm-c output,.rm-c p,.rm-c pre,.rm-c progress,.rm-c q,.rm-c samp,.rm-c section,.rm-c select,.rm-c small,.rm-c span,.rm-c strike,.rm-c strong,.rm-c sub,.rm-c summary,.rm-c sup,.rm-c svg,.rm-c table,.rm-c tbody,.rm-c td,.rm-c textarea,.rm-c tfoot,.rm-c th,.rm-c thead,.rm-c time,.rm-c tr,.rm-c tt,.rm-c ul,.rm-c var,.rm-c video{background-attachment:scroll!important;background-color:transparent!important;background-image:none!important;background-position:0 0!important;background-repeat:repeat!important;border-color:#000!important;border:medium none currentColor!important;bottom:auto!important;clear:none!important;clip:auto!important;color:inherit!important;counter-increment:none!important;counter-reset:none!important;cursor:auto!important;direction:inherit!important;display:inline!important;float:none!important;font-family:inherit!important;font-size:inherit!important;font-style:inherit!important;font-variant:normal!important;font-weight:inherit!important;height:auto!important;left:auto!important;letter-spacing:normal!important;line-height:inherit!important;list-style-type:inherit!important;list-style-position:outside!important;list-style-image:none!important;margin:0!important;max-height:none!important;max-width:none!important;min-height:0!important;min-width:0!important;opacity:1;outline:medium none invert!important;overflow:visible!important;padding:0!important;position:static!important;quotes:"" ""!important;right:auto!important;table-layout:auto!important;text-align:inherit!important;text-decoration:inherit!important;text-indent:0!important;text-transform:none!important;top:auto!important;unicode-bidi:normal!important;vertical-align:baseline!important;visibility:inherit!important;white-space:normal!important;width:auto!important;word-spacing:normal!important;z-index:auto!important;-webkit-background-origin:padding-box!important;background-origin:padding-box!important;-webkit-background-clip:border-box!important;background-clip:border-box!important;-webkit-background-size:auto!important;-moz-background-size:auto!important;background-size:auto!important;-webkit-border-image:none!important;-moz-border-image:none!important;-o-border-image:none!important;border-image:none!important;-webkit-border-radius:0!important;-moz-border-radius:0!important;border-radius:0!important;-webkit-box-shadow:none!important;box-shadow:none!important;-webkit-box-sizing:content-box!important;-moz-box-sizing:content-box!important;box-sizing:content-box!important;-webkit-column-count:auto!important;-moz-column-count:auto!important;column-count:auto!important;-webkit-column-gap:normal!important;-moz-column-gap:normal!important;column-gap:normal!important;-webkit-column-rule:medium none #000!important;-moz-column-rule:medium none #000!important;column-rule:medium none #000!important;-webkit-column-span:1!important;-moz-column-span:1!important;column-span:1!important;-webkit-column-width:auto!important;-moz-column-width:auto!important;column-width:auto!important;font-feature-settings:normal!important;overflow-x:visible!important;overflow-y:visible!important;-webkit-hyphens:manual!important;-moz-hyphens:manual!important;hyphens:manual!important;-webkit-perspective:none!important;-moz-perspective:none!important;-ms-perspective:none!important;-o-perspective:none!important;perspective:none!important;-webkit-perspective-origin:50% 50%!important;-moz-perspective-origin:50% 50%!important;-ms-perspective-origin:50% 50%!important;-o-perspective-origin:50% 50%!important;perspective-origin:50% 50%!important;-webkit-backface-visibility:visible!important;-moz-backface-visibility:visible!important;-ms-backface-visibility:visible!important;-o-backface-visibility:visible!important;backface-visibility:visible!important;text-shadow:none!important;-webkit-transition:all 0s ease 0s!important;transition:all 0s ease 0s!important;-webkit-transform:none!important;-moz-transform:none!important;-ms-transform:none!important;-o-transform:none!important;transform:none!important;-webkit-transform-origin:50% 50%!important;-moz-transform-origin:50% 50%!important;-ms-transform-origin:50% 50%!important;-o-transform-origin:50% 50%!important;transform-origin:50% 50%!important;-webkit-transform-style:flat!important;-moz-transform-style:flat!important;-ms-transform-style:flat!important;-o-transform-style:flat!important;transform-style:flat!important;word-break:normal!important}.rm-c,.rm-c address,.rm-c article,.rm-c audio,.rm-c blockquote,.rm-c caption,.rm-c colgroup,.rm-c dd,.rm-c dialog,.rm-c div,.rm-c dl,.rm-c dt,.rm-c fieldset,.rm-c figure,.rm-c footer,.rm-c form,.rm-c h1,.rm-c h2,.rm-c h3,.rm-c h4,.rm-c h5,.rm-c h6,.rm-c header,.rm-c hgroup,.rm-c hr,.rm-c main,.rm-c menu,.rm-c nav,.rm-c ol,.rm-c option,.rm-c p,.rm-c pre,.rm-c progress,.rm-c section,.rm-c summary,.rm-c ul,.rm-c video{display:block!important}.rm-c h1,.rm-c h2,.rm-c h3,.rm-c h4,.rm-c h5,.rm-c h6{font-weight:700!important}.rm-c h1{font-size:2em!important;padding:.67em 0!important}.rm-c h2{font-size:1.5em!important}.rm-c h2,.rm-c h3{padding:.83em 0!important}.rm-c h3{font-size:1.17em!important}.rm-c h4{font-size:1em!important}.rm-c h5{font-size:.83em!important}.rm-c p{margin:1em 0!important}.rm-c table{display:table!important}.rm-c thead{display:table-header-group!important}.rm-c tbody{display:table-row-group!important}.rm-c tfoot{display:table-footer-group!important}.rm-c tr{display:table-row!important}.rm-c td,.rm-c th{display:table-cell!important;padding:2px!important}.rm-c ol,.rm-c ul{margin:1em 0!important}.rm-c ol li,.rm-c ol ol li,.rm-c ol ol ol li,.rm-c ol ol ul li,.rm-c ol ul ul li,.rm-c ul li,.rm-c ul ol ol li,.rm-c ul ul li,.rm-c ul ul ol li,.rm-c ul ul ul li{list-style-position:inside!important;margin-top:.08em!important}.rm-c ol ol,.rm-c ol ol ol,.rm-c ol ol ul,.rm-c ol ul,.rm-c ol ul ul,.rm-c ul ol,.rm-c ul ol ol,.rm-c ul ul,.rm-c ul ul ol,.rm-c ul ul ul{padding-left:40px!important;margin:0!important}.rm-c nav ol,.rm-c nav ul{list-style-type:none!important}.rm-c menu,.rm-c ul{list-style-type:disc!important}.rm-c ol{list-style-type:decimal!important}.rm-c menu menu,.rm-c menu ul,.rm-c ol menu,.rm-c ol ul,.rm-c ul menu,.rm-c ul ul{list-style-type:circle!important}.rm-c menu menu menu,.rm-c menu menu ul,.rm-c menu ol menu,.rm-c menu ol ul,.rm-c menu ul menu,.rm-c menu ul ul,.rm-c ol menu menu,.rm-c ol menu ul,.rm-c ol ol menu,.rm-c ol ol ul,.rm-c ol ul menu,.rm-c ol ul ul,.rm-c ul menu menu,.rm-c ul menu ul,.rm-c ul ol menu,.rm-c ul ol ul,.rm-c ul ul menu,.rm-c ul ul ul{list-style-type:square!important}.rm-c li{display:list-item!important;min-height:auto!important;min-width:auto!important;padding-left:20px!important}.rm-c strong{font-weight:700!important}.rm-c em{font-style:italic!important}.rm-c code,.rm-c kbd,.rm-c pre,.rm-c samp{font-family:monospace!important}.rm-c a,.rm-c a *,.rm-c button,.rm-c button *,.rm-c input[type=button],.rm-c input[type=checkbox],.rm-c input[type=radio],.rm-c input[type=submit],.rm-c select{cursor:pointer!important}.rm-c button,.rm-c input[type=submit]{font-family:inherit!important;outline:initial!important}.rm-c input[type=hidden]{display:none!important}.rm-c textarea{-webkit-appearance:textarea!important;background:#fff!important;padding:2px!important;margin-left:4px!important;word-wrap:break-word!important;white-space:pre-wrap!important;font-size:11px!important;font-family:inherit!important;line-height:13px!important;resize:both!important}.rm-c input,.rm-c select,.rm-c textarea{border:1px solid #ccc!important}.rm-c select{font-size:11px!important;font-family:inherit!important;display:inline-block}.rm-c input:focus,.rm-c textarea:focus{outline:5px auto -webkit-focus-ring-color!important;outline:initial!important}.rm-c input[type=email],.rm-c input[type=text]{background:#fff!important;padding:1px!important;font-family:inherit!important;font-size:small!important}.rm-c input[type=checkbox],.rm-c input[type=radio]{border:1px solid #2b2b2b!important;border-radius:4px!important;outline:initial!important}.rm-c input[type=radio]{margin:2px 2px 3px!important}.rm-c abbr[title],.rm-c acronym[title],.rm-c dfn[title]{cursor:help!important;border-bottom-width:1px!important;border-bottom-style:dotted!important}.rm-c ins{background-color:#ff9!important;color:#000!important}.rm-c del{text-decoration:line-through!important}.rm-c blockquote,.rm-c q{quotes:none!important}.rm-c blockquote:after,.rm-c blockquote:before,.rm-c li:after,.rm-c li:before,.rm-c q:after,.rm-c q:before{content:""!important}.rm-c input,.rm-c select{vertical-align:middle!important}.rm-c table{border-collapse:collapse!important;border-spacing:0!important}.rm-c hr{display:block!important;height:1px!important;border:0!important;border-top:1px solid #ccc!important;margin:1em 0!important}.rm-c [dir=rtl]{direction:rtl!important}.rm-c mark{background-color:#ff9!important;color:#000!important;font-style:italic!important;font-weight:700!important}.rm-c menu{padding-left:40px!important;padding-top:8px!important}.rm-c [hidden],.rm-c template{display:none!important}.rm-c abbr[title]{border-bottom:1px dotted!important}.rm-c sub,.rm-c sup{font-size:75%!important;line-height:0!important;position:relative!important;vertical-align:baseline!important}.rm-c sup{top:-.5em!important}.rm-c sub{bottom:-.25em!important}.rm-c img{border:0!important}.rm-c figure{margin:0!important}.rm-c textarea{overflow:auto!important;vertical-align:top!important}.rm-c{font-size:medium!important;line-height:1!important;text-align:left!important;text-align:start!important;color:#000!important;font-style:normal!important;font-weight:400!important;text-decoration:none!important;list-style-type:disc!important}.rm-c pre{white-space:pre!important}</style><style type="text/css">.rm-animated{animation-duration:1s;animation-fill-mode:both}.rm-animated.infinite{animation-iteration-count:infinite}.rm-animated.delay-1s{animation-delay:1s}.rm-animated.delay-2s{animation-delay:2s}.rm-animated.delay-3s{animation-delay:3s}.rm-animated.delay-4s{animation-delay:4s}.rm-animated.delay-5s{animation-delay:5s}.rm-animated.fast{animation-duration:.8s}.rm-animated.faster{animation-duration:.5s}.rm-animated.slow{animation-duration:2s}.rm-animated.slower{animation-duration:3s}@media (prefers-reduced-motion),(print){.rm-animated{animation:unset!important;transition:none!important}}@keyframes rm-tada{0%{transform:scaleX(1)}2%,4%{transform:scale3d(.9,.9,.9) rotate(-3deg)}6%,10%,14%,18%{transform:scale3d(1.1,1.1,1.1) rotate(3deg)}8%,12%,16%{transform:scale3d(1.1,1.1,1.1) rotate(-3deg)}20%{transform:scaleX(1)}}.rm-tada{animation-duration:5s;animation-name:rm-tada}</style><style>.rmtempinvisible { visibility: visible !important; }</style></head>
<body data-rsssl="1" class="post-template-default single single-post postid-9285 single-format-standard wp-embed-responsive header-full-width content-sidebar genesis-breadcrumbs-hidden genesis-footer-widgets-visible" data-new-gr-c-s-check-loaded="14.1085.0" data-gr-ext-installed=""><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-dark-grayscale"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0 0.49803921568627"></fefuncr><fefuncg type="table" tableValues="0 0.49803921568627"></fefuncg><fefuncb type="table" tableValues="0 0.49803921568627"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-grayscale"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0 1"></fefuncr><fefuncg type="table" tableValues="0 1"></fefuncg><fefuncb type="table" tableValues="0 1"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-purple-yellow"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0.54901960784314 0.98823529411765"></fefuncr><fefuncg type="table" tableValues="0 1"></fefuncg><fefuncb type="table" tableValues="0.71764705882353 0.25490196078431"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-blue-red"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0 1"></fefuncr><fefuncg type="table" tableValues="0 0.27843137254902"></fefuncg><fefuncb type="table" tableValues="0.5921568627451 0.27843137254902"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-midnight"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0 0"></fefuncr><fefuncg type="table" tableValues="0 0.64705882352941"></fefuncg><fefuncb type="table" tableValues="0 1"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-magenta-yellow"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0.78039215686275 1"></fefuncr><fefuncg type="table" tableValues="0 0.94901960784314"></fefuncg><fefuncb type="table" tableValues="0.35294117647059 0.47058823529412"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-purple-green"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0.65098039215686 0.40392156862745"></fefuncr><fefuncg type="table" tableValues="0 1"></fefuncg><fefuncb type="table" tableValues="0.44705882352941 0.4"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-blue-orange"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0.098039215686275 1"></fefuncr><fefuncg type="table" tableValues="0 0.66274509803922"></fefuncg><fefuncb type="table" tableValues="0.84705882352941 0.41960784313725"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><div class="site-container"><ul class="genesis-skip-link"><li><a href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#genesis-nav-primary" class="screen-reader-shortcut"> Skip to primary navigation</a></li><li><a href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#genesis-content" class="screen-reader-shortcut"> Skip to main content</a></li><li><a href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#genesis-sidebar-primary" class="screen-reader-shortcut"> Skip to primary sidebar</a></li><li><a href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#genesis-footer-widgets" class="screen-reader-shortcut"> Skip to footer</a></li></ul><header class="site-header"><div class="wrap"><div class="title-area"><p class="site-title"><a href="https://pyimagesearch.com/">PyImageSearch</a></p><p class="site-description">You can master Computer Vision, Deep Learning, and OpenCV - PyImageSearch</p></div><nav class="nav-secondary" aria-label="Secondary"><div class="wrap"><ul id="menu-header-secondary" class="menu genesis-nav-menu menu-secondary"><li id="menu-item-29226" class="menu-item"><a href="https://pyimagesearch.com/consulting-2/"><span>Consulting</span></a></li>
<li id="menu-item-15978" class="menu-item"><a href="https://pyimagesearch.com/opencv-tutorials-resources-guides/"><span>OpenCV Install Guides</span></a></li>
<li id="menu-item-12816" class="menu-item"><a href="https://pyimagesearch.com/about/"><span>About</span></a></li>
<li id="menu-item-12817" class="menu-item"><a href="https://pyimagesearch.com/faqs/"><span>FAQ</span></a></li>
<li id="menu-item-12818" class="menu-item"><a href="https://pyimagesearch.com/contact/"><span>Contact</span></a></li>
<li id="menu-item-31245" class="menu-item"><a href="https://pyimagesearch.com/consult-adrian/"><span>Coaching</span></a></li>
</ul></div></nav><div class="main-nav-wrap"><nav class="nav-primary" aria-label="Main" id="genesis-nav-primary"><ul id="menu-main-menu" class="menu genesis-nav-menu menu-primary"><li id="menu-item-11459" class="menu-item"><a href="https://pyimagesearch.com/start-here/"><span>Get Started</span></a></li>
<li id="menu-item-10696" class="is-topics menu-item menu-item-has-children"><a href="https://pyimagesearch.com/topics/"><span>Topics</span></a><span class="submenu-expand" tabindex="-1"><svg class="svg-icon" width="16" height="16" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M151.5 347.8L3.5 201c-4.7-4.7-4.7-12.3 0-17l19.8-19.8c4.7-4.7 12.3-4.7 17 0L160 282.7l119.7-118.5c4.7-4.7 12.3-4.7 17 0l19.8 19.8c4.7 4.7 4.7 12.3 0 17l-148 146.8c-4.7 4.7-12.3 4.7-17 0z"></path></svg></span>
<ul class="sub-menu">
	<li id="menu-item-10698" class="has-icon has-icon--deep-learning menu-item"><a href="https://pyimagesearch.com/category/deep-learning/"><span>Deep Learning</span></a></li>
	<li id="menu-item-10699" class="has-icon has-icon--dlib menu-item"><a href="https://pyimagesearch.com/category/dlib/"><span>Dlib Library</span></a></li>
	<li id="menu-item-10700" class="has-icon has-icon--iot menu-item"><a href="https://pyimagesearch.com/category/embedded/"><span>Embedded/IoT and Computer Vision</span></a></li>
	<li id="menu-item-10701" class="has-icon has-icon--face menu-item"><a href="https://pyimagesearch.com/category/faces/"><span>Face Applications</span></a></li>
	<li id="menu-item-10702" class="has-icon has-icon--image menu-item"><a href="https://pyimagesearch.com/category/image-processing/"><span>Image Processing</span></a></li>
	<li id="menu-item-10703" class="has-icon has-icon--interviews menu-item"><a href="https://pyimagesearch.com/category/interviews/"><span>Interviews</span></a></li>
	<li id="menu-item-10704" class="has-icon has-icon--keras menu-item"><a href="https://pyimagesearch.com/category/keras-and-tensorflow/"><span>Keras and TensorFlow</span></a></li>
	<li id="menu-item-10705" class="has-icon has-icon--ml menu-item"><a href="https://pyimagesearch.com/category/machine-learning/"><span>Machine Learning and Computer Vision</span></a></li>
	<li id="menu-item-10706" class="has-icon has-icon--medical menu-item"><a href="https://pyimagesearch.com/category/medical/"><span>Medical Computer Vision</span></a></li>
	<li id="menu-item-10707" class="has-icon has-icon--ocr menu-item"><a href="https://pyimagesearch.com/category/optical-character-recognition-ocr/"><span>Optical Character Recognition (OCR)</span></a></li>
	<li id="menu-item-10708" class="has-icon has-icon--object-detection menu-item"><a href="https://pyimagesearch.com/category/object-detection/"><span>Object Detection</span></a></li>
	<li id="menu-item-10709" class="has-icon has-icon--object-tracking menu-item"><a href="https://pyimagesearch.com/category/object-tracking/"><span>Object Tracking</span></a></li>
	<li id="menu-item-10711" class="has-icon has-icon--opencv menu-item"><a href="https://pyimagesearch.com/category/opencv/"><span>OpenCV Tutorials</span></a></li>
	<li id="menu-item-10710" class="has-icon has-icon--pi menu-item"><a href="https://pyimagesearch.com/category/raspberry-pi/"><span>Raspberry Pi</span></a></li>
</ul>
</li>
<li id="menu-item-12831" class="menu-item"><a href="https://pyimagesearch.com/books-and-courses/"><span>Books and Courses</span></a></li>
<li id="menu-item-15979" class="menu-item"><a href="https://pyimagesearch.com/pyimagesearch-reviews-testimonials/"><span>Student Success Stories</span></a></li>
<li id="menu-item-12845" class="menu-item current_page_parent"><a href="https://pyimagesearch.com/blog/"><span>Blog</span></a></li>
<li id="menu-item-29296" class="mobile-only menu-item"><a href="https://pyimagesearch.com/consulting-2/"><span>Consulting</span></a></li>
<li id="menu-item-2619" class="mobile-only menu-item"><a href="https://pyimagesearch.com/about/"><span>About</span></a></li>
<li id="menu-item-10258" class="mobile-only menu-item"><a href="https://pyimagesearch.com/faqs/"><span>FAQ</span></a></li>
<li id="menu-item-6744" class="mobile-only menu-item"><a href="https://pyimagesearch.com/contact/"><span>Contact</span></a></li>
</ul></nav><div class="header-search"><button class="mobile-search-toggle"><svg class="svg-icon search-icon" width="28" height="28" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M508.5 468.9L387.1 347.5c-2.3-2.3-5.3-3.5-8.5-3.5h-13.2c31.5-36.5 50.6-84 50.6-136C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c52 0 99.5-19.1 136-50.6v13.2c0 3.2 1.3 6.2 3.5 8.5l121.4 121.4c4.7 4.7 12.3 4.7 17 0l22.6-22.6c4.7-4.7 4.7-12.3 0-17zM208 368c-88.4 0-160-71.6-160-160S119.6 48 208 48s160 71.6 160 160-71.6 160-160 160z"></path></svg><svg class="svg-icon search-close" width="28" height="28" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M207.6 256l107.72-107.72c6.23-6.23 6.23-16.34 0-22.58l-25.03-25.03c-6.23-6.23-16.34-6.23-22.58 0L160 208.4 52.28 100.68c-6.23-6.23-16.34-6.23-22.58 0L4.68 125.7c-6.23 6.23-6.23 16.34 0 22.58L112.4 256 4.68 363.72c-6.23 6.23-6.23 16.34 0 22.58l25.03 25.03c6.23 6.23 16.34 6.23 22.58 0L160 303.6l107.72 107.72c6.23 6.23 16.34 6.23 22.58 0l25.03-25.03c6.23-6.23 6.23-16.34 0-22.58L207.6 256z"></path></svg><span class="screen-reader-text">Search</span></button>
<form role="search" method="get" class="search-form" action="https://pyimagesearch.com/">
	<label>
		<span class="screen-reader-text">Search...</span>
		<input type="search" class="search-field" placeholder="Search articles..." value="" name="s" title="Search for">
	</label>
	<button type="submit" class="search-submit"><svg class="svg-icon search" width="20" height="20" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M508.5 468.9L387.1 347.5c-2.3-2.3-5.3-3.5-8.5-3.5h-13.2c31.5-36.5 50.6-84 50.6-136C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c52 0 99.5-19.1 136-50.6v13.2c0 3.2 1.3 6.2 3.5 8.5l121.4 121.4c4.7 4.7 12.3 4.7 17 0l22.6-22.6c4.7-4.7 4.7-12.3 0-17zM208 368c-88.4 0-160-71.6-160-160S119.6 48 208 48s160 71.6 160 160-71.6 160-160 160z"></path></svg><span class="screen-reader-text">Submit</span></button>
</form>
</div><nav class="nav-mobile"><button class="mobile-menu-toggle"><span class="mobile-menu-open"><svg class="svg-icon menu-open" width="13" height="13" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg>Menu</span><span class="mobile-menu-close"><svg class="svg-icon menu-close" width="13" height="13" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M207.6 256l107.72-107.72c6.23-6.23 6.23-16.34 0-22.58l-25.03-25.03c-6.23-6.23-16.34-6.23-22.58 0L160 208.4 52.28 100.68c-6.23-6.23-16.34-6.23-22.58 0L4.68 125.7c-6.23 6.23-6.23 16.34 0 22.58L112.4 256 4.68 363.72c-6.23 6.23-6.23 16.34 0 22.58l25.03 25.03c6.23 6.23 16.34 6.23 22.58 0L160 303.6l107.72 107.72c6.23 6.23 16.34 6.23 22.58 0l25.03-25.03c6.23-6.23 6.23-16.34 0-22.58L207.6 256z"></path></svg>Close</span><span class="screen-reader-text">Menu</span></button></nav></div></div></header><div class="pyi-page-hero"><div class="wrap"><p class="entry-meta"><span class="entry-categories"><a href="https://pyimagesearch.com/category/image-descriptors/" rel="category tag">Image Descriptors</a> <a href="https://pyimagesearch.com/category/tutorials/" rel="category tag">Tutorials</a></span></p><header class="entry-header"><h1 class="entry-title">Image Stitching with OpenCV and Python</h1>
</header><p class="entry-meta">by <span class="entry-author"><a href="https://pyimagesearch.com/author/adrian/" class="entry-author-link" rel="author"><span class="entry-author-name">Adrian Rosebrock</span></a></span> on <time class="entry-time">December 17, 2018</time></p><div class="pyi-hero-left"></div><div class="pyi-hero-right"></div></div></div><div class="site-inner"><div class="wrap"><div class="content-sidebar-wrap"><main class="content" id="genesis-content"><article class="post-9285 post type-post status-publish format-standard has-post-thumbnail category-image-descriptors category-tutorials tag-image-descriptors tag-image-stitching tag-keypoint-detection tag-keypoint-matching tag-panorama tag-ransac entry" aria-label="Image Stitching with OpenCV and Python"><div class="entry-content">
<div id="pyis-cta-modal-sticky-top-anchor"></div>

<div id="pyis-cta-modal-sticky-bar" data-sticky-container="" class="sticky-container" style="height: 75.175px;">

	<div class="sticky is-at-top is-stuck" data-sticky="wtb22y-sticky" data-top-anchor="pyis-cta-modal-sticky-top-anchor:top" data-btm-anchor="pyis-cta-modal-sticky-bottom-anchor:bottom" data-margin-top="0" data-sticky-on="small" data-resize="tiw4eg-sticky" data-mutate="tiw4eg-sticky" style="max-width: 702.4px; margin-top: 0em; bottom: auto; top: 0px;" data-events="mutate">

		<div class="grid-container">
			<div class="grid-x grid-margin-x">
				<div class="cell text-center">
		
					<a href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" class="pyis-cta-modal-open-modal">
						
						Click here to download the source code to this post						
					</a>

				</div>
			</div>
		</div>
		
	</div>

</div><p><a href="https://pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg"><img class="aligncenter size-full wp-image-9290 entered lazyloaded" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/image_stitching_opencv_header.jpg" alt="" width="600" height="378" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?size=126x79&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header-300x189.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?size=378x238&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?size=504x318&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" data-lazy-sizes="(max-width: 600px) 100vw, 600px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" sizes="(max-width: 600px) 100vw, 600px" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?size=126x79&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header-300x189.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?size=378x238&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?size=504x318&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?lossy=1&amp;strip=1&amp;webp=1 600w"><noscript><img class="aligncenter size-full wp-image-9290" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?lossy=1&strip=1&webp=1" alt="" width="600" height="378" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?size=126x79&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header-300x189.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?size=378x238&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?size=504x318&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_header.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" sizes="(max-width: 600px) 100vw, 600px" /></noscript></a></p>
<p>In this tutorial, you will learn how to perform image stitching using Python, OpenCV, and the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.createStitcher</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.createStitcher</code>  and <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.Stitcher_create</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.Stitcher_create</code>  functions. Using today’s code you’ll be able to stitch <em>multiple</em> images together, creating a panorama of stitched images.</p>
<p>Just under two years ago I published two guides on image stitching and panorama construction:</p>
<ol>
<li><a href="https://pyimagesearch.com/2016/01/11/opencv-panorama-stitching/" target="_blank" rel="noopener noreferrer">Fundamentals of image stitching</a></li>
<li><a href="https://pyimagesearch.com/2016/01/25/real-time-panorama-and-image-stitching-with-opencv/" target="_blank" rel="noopener noreferrer">Real-time panorama and image stitching</a></li>
</ol>
<p>Both of these tutorials covered the fundamentals of the typical image stitching algorithm, which, at a bare minimum, require four key steps:</p>
<ol>
<li>Detecting keypoints (DoG, Harris, etc.) and extracting local invariant descriptors (SIFT, SURF, etc.) from two input images</li>
<li>Matching the descriptors between the images</li>
<li>Using the RANSAC algorithm to estimate a homography matrix using our matched feature vectors</li>
<li>Applying a warping transformation using the homography matrix obtained from Step #3</li>
</ol>
<p><strong>However, the biggest problem with my original implementations is that they were not capable of handling more than two input images.</strong></p>
<p>In today’s tutorial, we’ll be revisiting image stitching with OpenCV, including how to stitch more than two images together into a panoramic image.</p>
<p><strong>To learn how to stitch images with OpenCV and Python, <em>just keep reading!</em></strong></p>
<div id="pyi-source-code-block" class="source-code-wrap"><div class="gpd-source-code">
    <div class="gpd-source-code-content">
        <img src="./Image Stitching with OpenCV and Python - PyImageSearch_files/source-code-icon.png" alt="" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/source-code-icon.png?lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" class="entered lazyloaded"><noscript><img src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/source-code-icon.png?lossy=1&strip=1&webp=1" alt=""></noscript>
        <h4>Looking for the source code to this post?</h4>
                    <a href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" class="pyis-cta-modal-open-modal">Jump Right To The Downloads Section <svg class="svg-icon arrow-right" width="12" height="12" aria-hidden="true" role="img" focusable="false" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.8125 0.1875C6.875 0.125 6.96875 0.09375 7.09375 0.09375C7.1875 0.09375 7.28125 0.125 7.34375 0.1875L13.875 6.75C13.9375 6.8125 14 6.90625 14 7C14 7.125 13.9375 7.1875 13.875 7.25L7.34375 13.8125C7.28125 13.875 7.1875 13.9062 7.09375 13.9062C6.96875 13.9062 6.875 13.875 6.8125 13.8125L6.1875 13.1875C6.125 13.125 6.09375 13.0625 6.09375 12.9375C6.09375 12.8438 6.125 12.75 6.1875 12.6562L11.0312 7.8125H0.375C0.25 7.8125 0.15625 7.78125 0.09375 7.71875C0.03125 7.65625 0 7.5625 0 7.4375V6.5625C0 6.46875 0.03125 6.375 0.09375 6.3125C0.15625 6.25 0.25 6.1875 0.375 6.1875H11.0312L6.1875 1.34375C6.125 1.28125 6.09375 1.1875 6.09375 1.0625C6.09375 0.96875 6.125 0.875 6.1875 0.8125L6.8125 0.1875Z" fill="#169FE6"></path></svg></a>
            </div>
</div>
</div>
<h2>Image Stitching with OpenCV and Python</h2>
<p>In the first part of today’s tutorial, we’ll briefly review OpenCV’s image stitching algorithm that is baked into the OpenCV library itself via <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.createStitcher</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.createStitcher</code>  and <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.Stitcher_create</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.Stitcher_create</code>  functions.</p>
<p>From there we’ll review our project structure and implement a Python script that can be used for image stitching.</p>
<p>We’ll review the results of this first script, note its limitations, and then implement a second Python script that can be used for more aesthetically pleasing image stitching results.</p>
<p>Finally, we’ll review the results of our second script and again note any limitations or drawbacks.</p>
<h3>OpenCV’s image stitching algorithm</h3>
<figure id="attachment_9291" aria-describedby="caption-attachment-9291" style="width: 600px" class="wp-caption aligncenter"><a href="https://pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png"><img class="wp-image-9291 size-full entered lazyloaded" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/image_stitching_opencv_pipeline.png" alt="" width="600" height="401" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?size=126x84&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline-300x201.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?size=378x253&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?size=504x337&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?lossy=1&amp;strip=1&amp;webp=1 600w" data-lazy-sizes="(max-width: 600px) 100vw, 600px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" sizes="(max-width: 600px) 100vw, 600px" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?size=126x84&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline-300x201.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?size=378x253&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?size=504x337&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?lossy=1&amp;strip=1&amp;webp=1 600w"><noscript><img class="wp-image-9291 size-full" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?lossy=1&strip=1&webp=1" alt="" width="600" height="401" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?size=126x84&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline-300x201.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?size=378x253&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?size=504x337&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_pipeline.png?lossy=1&amp;strip=1&amp;webp=1 600w" sizes="(max-width: 600px) 100vw, 600px" /></noscript></a><figcaption id="caption-attachment-9291" class="wp-caption-text"><strong>Figure 1:</strong> The stitching module pipeline implemented in the Stitcher class (<a href="https://docs.opencv.org/3.4/d1/d46/group__stitching.html" target="_blank" rel="noopener noreferrer">source</a>).</figcaption></figure>
<p>The algorithm we’ll be using here today is similar to the method proposed by Brown and Lowe in their 2007 paper, <a href="http://matthewalunbrown.com/papers/ijcv2007.pdf" target="_blank" rel="noopener noreferrer"><em>Automatic Panoramic Image Stitching with Invariant Features</em></a>.</p>
<p>Unlike previous image stitching algorithms which are sensitive to the ordering of input images, <strong>the Brown and Lowe method is more robust,</strong> making it <em>insensitive</em> to:</p>
<ul>
<li>Ordering of images</li>
<li>Orientation of images</li>
<li>Illumination changes</li>
<li>Noisy images that are not actually part of the panorama</li>
</ul>
<p>Furthermore, their image stitching method is capable of producing more aesthetically pleasing output panorama images through the use of gain compensation and image blending.</p>
<p>A complete, detailed review of the algorithm is outside the scope of this post, so if you’re interested in learning more, please refer to the <a href="http://matthewalunbrown.com/papers/ijcv2007.pdf" target="_blank" rel="noopener noreferrer">original publication</a>.</p>
<h3>Project structure</h3>
<p>Let’s see how this project is organized with the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">tree</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">tree</code>  command:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-text">$ tree --dirsfirst</span></div></div><div class=""><div><span class="enlighter-text">.</span></div></div><div class=""><div><span class="enlighter-text">├── images</span></div></div><div class=""><div><span class="enlighter-text">│   └── scottsdale</span></div></div><div class=""><div><span class="enlighter-text">│       ├── IMG_1786-2.jpg</span></div></div><div class=""><div><span class="enlighter-text">│       ├── IMG_1787-2.jpg</span></div></div><div class=""><div><span class="enlighter-text">│       └── IMG_1788-2.jpg</span></div></div><div class=""><div><span class="enlighter-text">├── image_stitching.py</span></div></div><div class=""><div><span class="enlighter-text">├── image_stitching_simple.py</span></div></div><div class=""><div><span class="enlighter-text">└── output.png</span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-n1">2</span><span class="enlighter-text"> directories, </span><span class="enlighter-n1">6</span><span class="enlighter-text"> files</span></div></div></div><div class="enlighter-raw">$ tree --dirsfirst
.
├── images
│   └── scottsdale
│       ├── IMG_1786-2.jpg
│       ├── IMG_1787-2.jpg
│       └── IMG_1788-2.jpg
├── image_stitching.py
├── image_stitching_simple.py
└── output.png

2 directories, 6 files</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="5">$ tree --dirsfirst
.
├── images
│&nbsp;&nbsp; └── scottsdale
│&nbsp;&nbsp;     ├── IMG_1786-2.jpg
│&nbsp;&nbsp;     ├── IMG_1787-2.jpg
│&nbsp;&nbsp;     └── IMG_1788-2.jpg
├── image_stitching.py
├── image_stitching_simple.py
└── output.png

2 directories, 6 files
</pre>


<p>The input images go in the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">images/</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">images/</code>  folder. I opted to make a subfolder for my <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">scottsdale/</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">scottsdale/</code>  set of images in case I wanted to add additional subfolders here later.</p>
<p>Today we’ll be reviewing two Python scripts:</p>
<ul>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">image_stitching_simple.py</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">image_stitching_simple.py</code> : Our simple version of image stitching can be completed in less than 50 lines of Python code!</li>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">image_stitching.py</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">image_stitching.py</code> : This script includes my hack to extract an ROI of the stitched image for an aesthetically pleasing result.</li>
</ul>
<p>The last file, <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">output.png</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">output.png</code> , is the name of the resulting stitched image. Using command line arguments, you can easily change the filename + path of the output image.</p>
<h3>The cv2.createStitcher and cv2.Stitcher_create functions</h3>
<figure id="attachment_9292" aria-describedby="caption-attachment-9292" style="width: 600px" class="wp-caption aligncenter"><a href="https://pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_signature.png"><img class="size-full wp-image-9292 entered lazyloaded" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/image_stitching_opencv_signature.png" alt="" width="600" height="343" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?size=126x72&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature-300x172.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?size=378x216&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?size=504x288&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?lossy=1&amp;strip=1&amp;webp=1 600w" data-lazy-sizes="(max-width: 600px) 100vw, 600px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" sizes="(max-width: 600px) 100vw, 600px" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?size=126x72&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature-300x172.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?size=378x216&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?size=504x288&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?lossy=1&amp;strip=1&amp;webp=1 600w"><noscript><img class="size-full wp-image-9292" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?lossy=1&strip=1&webp=1" alt="" width="600" height="343" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?size=126x72&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature-300x172.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?size=378x216&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?size=504x288&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_signature.png?lossy=1&amp;strip=1&amp;webp=1 600w" sizes="(max-width: 600px) 100vw, 600px" /></noscript></a><figcaption id="caption-attachment-9292" class="wp-caption-text"><strong>Figure 2:</strong> The constructor signature for creating a Stitcher class object with OpenCV.</figcaption></figure>
<p>OpenCV has already implemented a method similar to Brown and Lowe’s paper via the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.createStitcher</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.createStitcher</code>  (OpenCV 3.x) and <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.Stitcher_create</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.Stitcher_create</code>  (OpenCV 4) functions.</p>
<p>Assuming you have <a href="https://pyimagesearch.com/opencv-tutorials-resources-guides/" target="_blank" rel="noopener noreferrer">OpenCV properly configured and installed</a> you’ll be able to investigate the function signature of <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.createStitcher</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.createStitcher</code>  for OpenCV 3.x:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-m0">createStitcher</span><span class="enlighter-g1">(</span><span class="enlighter-text">...</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">    </span><span class="enlighter-m0">createStitcher</span><span class="enlighter-g1">([</span><span class="enlighter-text">, try_use_gpu</span><span class="enlighter-g1">])</span><span class="enlighter-text"> -</span><span class="enlighter-g1">&gt;</span><span class="enlighter-text"> retval</span></div></div></div><div class="enlighter-raw">createStitcher(...)
    createStitcher([, try_use_gpu]) -&gt; retval</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="14">createStitcher(...)
    createStitcher([, try_use_gpu]) -&gt; retval
</pre>


<p>Notice how this function has only a single parameter, <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">try_gpu</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">try_gpu</code>  which can be used to improve your the throughout of your image stitching pipeline. OpenCV’s GPU support is <em>limited</em> and I’ve never been able to get this parameter to work so I recommend always leaving it as <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-e0">False</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">False</code> .</p>
<p>The <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.Stitcher_create</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.Stitcher_create</code>  function for OpenCV 4 has a similar signature:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-m0">Stitcher_create</span><span class="enlighter-g1">(</span><span class="enlighter-text">...</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">    </span><span class="enlighter-m0">Stitcher_create</span><span class="enlighter-g1">([</span><span class="enlighter-text">, mode</span><span class="enlighter-g1">])</span><span class="enlighter-text"> -</span><span class="enlighter-g1">&gt;</span><span class="enlighter-text"> retval</span></div></div><div class=""><div><span class="enlighter-text">    .   @brief Creates a Stitcher configured </span><span class="enlighter-k1">in</span><span class="enlighter-text"> one </span><span class="enlighter-k1">of</span><span class="enlighter-text"> the stitching</span></div></div><div class=""><div><span class="enlighter-text">    .	modes.</span></div></div><div class=""><div><span class="enlighter-text">    .   </span></div></div><div class=""><div><span class="enlighter-text">    .   @param mode Scenario </span><span class="enlighter-k1">for</span><span class="enlighter-text"> stitcher operation. </span><span class="enlighter-k1">This</span><span class="enlighter-text"> is usually</span></div></div><div class=""><div><span class="enlighter-text">    .	determined by source </span><span class="enlighter-k1">of</span><span class="enlighter-text"> images to stitch and their transformation.</span></div></div><div class=""><div><span class="enlighter-text">    .	Default parameters will be chosen </span><span class="enlighter-k1">for</span><span class="enlighter-text"> operation </span><span class="enlighter-k1">in</span><span class="enlighter-text"> given scenario.</span></div></div><div class=""><div><span class="enlighter-text">    .   @</span><span class="enlighter-k1">return</span><span class="enlighter-text"> Stitcher </span><span class="enlighter-k1">class</span><span class="enlighter-text"> instance.</span></div></div></div><div class="enlighter-raw">Stitcher_create(...)
    Stitcher_create([, mode]) -&gt; retval
    .   @brief Creates a Stitcher configured in one of the stitching
    .	modes.
    .   
    .   @param mode Scenario for stitcher operation. This is usually
    .	determined by source of images to stitch and their transformation.
    .	Default parameters will be chosen for operation in given scenario.
    .   @return Stitcher class instance.</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="18">Stitcher_create(...)
    Stitcher_create([, mode]) -&gt; retval
    .   @brief Creates a Stitcher configured in one of the stitching
    .	modes.
    .   
    .   @param mode Scenario for stitcher operation. This is usually
    .	determined by source of images to stitch and their transformation.
    .	Default parameters will be chosen for operation in given scenario.
    .   @return Stitcher class instance.
</pre>


<p>To perform the actual image stitching we’ll need to call the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">.stitch</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">.stitch</code>  method:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-text">OpenCV </span><span class="enlighter-n0">3.</span><span class="enlighter-m3">x</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-m0">stitch</span><span class="enlighter-g1">(</span><span class="enlighter-text">...</span><span class="enlighter-g1">)</span><span class="enlighter-text"> method </span><span class="enlighter-k1">of</span><span class="enlighter-text"> cv2.</span><span class="enlighter-m3">Stitcher</span><span class="enlighter-text"> instance</span></div></div><div class=""><div><span class="enlighter-text">    </span><span class="enlighter-m0">stitch</span><span class="enlighter-g1">(</span><span class="enlighter-text">images</span><span class="enlighter-g1">[</span><span class="enlighter-text">, pano</span><span class="enlighter-g1">])</span><span class="enlighter-text"> -</span><span class="enlighter-g1">&gt;</span><span class="enlighter-text"> retval, pano</span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">OpenCV </span><span class="enlighter-n0">4.</span><span class="enlighter-m3">x</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-m0">stitch</span><span class="enlighter-g1">(</span><span class="enlighter-text">...</span><span class="enlighter-g1">)</span><span class="enlighter-text"> method </span><span class="enlighter-k1">of</span><span class="enlighter-text"> cv2.</span><span class="enlighter-m3">Stitcher</span><span class="enlighter-text"> instance</span></div></div><div class=""><div><span class="enlighter-text">    </span><span class="enlighter-m0">stitch</span><span class="enlighter-g1">(</span><span class="enlighter-text">images, masks</span><span class="enlighter-g1">[</span><span class="enlighter-text">, pano</span><span class="enlighter-g1">])</span><span class="enlighter-text"> -</span><span class="enlighter-g1">&gt;</span><span class="enlighter-text"> retval, pano</span></div></div><div class=""><div><span class="enlighter-text">    .   @brief These functions </span><span class="enlighter-k1">try</span><span class="enlighter-text"> to stitch the given images.</span></div></div><div class=""><div><span class="enlighter-text">    .   </span></div></div><div class=""><div><span class="enlighter-text">    .   @param images Input images.</span></div></div><div class=""><div><span class="enlighter-text">    .   @param masks Masks </span><span class="enlighter-k1">for</span><span class="enlighter-text"> each input image specifying where to</span></div></div><div class=""><div><span class="enlighter-text">    .	look </span><span class="enlighter-k1">for</span><span class="enlighter-text"> </span><span class="enlighter-m0">keypoints</span><span class="enlighter-text"> </span><span class="enlighter-g1">(</span><span class="enlighter-text">optional</span><span class="enlighter-g1">)</span><span class="enlighter-text">.</span></div></div><div class=""><div><span class="enlighter-text">    .   @param pano Final pano.</span></div></div><div class=""><div><span class="enlighter-text">    .   @</span><span class="enlighter-k1">return</span><span class="enlighter-text"> Status code.</span></div></div></div><div class="enlighter-raw">OpenCV 3.x:
stitch(...) method of cv2.Stitcher instance
    stitch(images[, pano]) -&gt; retval, pano

OpenCV 4.x:
stitch(...) method of cv2.Stitcher instance
    stitch(images, masks[, pano]) -&gt; retval, pano
    .   @brief These functions try to stitch the given images.
    .   
    .   @param images Input images.
    .   @param masks Masks for each input image specifying where to
    .	look for keypoints (optional).
    .   @param pano Final pano.
    .   @return Status code.</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="20">OpenCV 3.x:
stitch(...) method of cv2.Stitcher instance
    stitch(images[, pano]) -&gt; retval, pano

OpenCV 4.x:
stitch(...) method of cv2.Stitcher instance
    stitch(images, masks[, pano]) -&gt; retval, pano
    .   @brief These functions try to stitch the given images.
    .   
    .   @param images Input images.
    .   @param masks Masks for each input image specifying where to
    .	look for keypoints (optional).
    .   @param pano Final pano.
    .   @return Status code.

</pre>


<p>This method accepts a list of input <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">images</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">images</code> , and then attempts to stitch them into a panorama, returning the output panorama image to the calling function.</p>
<p>The <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">status</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">status</code>  variable indicates whether or not the image stitching was a success and can be one of four variables:</p>
<ul>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">OK = </span><span class="enlighter-n1">0</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">OK = 0</code> : The image stitching was a success.</li>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">ERR_NEED_MORE_IMGS = </span><span class="enlighter-n1">1</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">ERR_NEED_MORE_IMGS = 1</code> : In the event you receive this status code, you will need more input images to construct your panorama. Typically this error occurs if there are not enough keypoints detected in your input images.</li>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">ERR_HOMOGRAPHY_EST_FAIL = </span><span class="enlighter-n1">2</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">ERR_HOMOGRAPHY_EST_FAIL = 2</code> : This error occurs when the RANSAC homography estimation fails. Again, you may need more images or your images don’t have enough distinguishing, unique texture/objects for keypoints to be accurately matched.</li>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">ERR_CAMERA_PARAMS_ADJUST_FAIL = </span><span class="enlighter-n1">3</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">ERR_CAMERA_PARAMS_ADJUST_FAIL = 3</code> : I have never encountered this error before so I don’t have much knowledge about it, but the gist is that it is related to failing to properly estimate camera intrinsics/extrinsics from the input images. If you encounter this error you may need to refer to the OpenCV documentation or even dive into the OpenCV C++ code.</li>
</ul>
<p>Now that we’ve reviewed the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.createStitcher</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.createStitcher</code> , <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.Stitcher_create</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.Stitcher_create</code> , and <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">.stitch</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">.stitch</code>  methods, let’s move on to actually implementing image stitching with OpenCV and Python.</p>
<h3>Implementing image stitching with Python</h3>
<p>Let’s go ahead and get started implementing our image stitching algorithm!</p>
<p>Open up the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">image_stitching_simple.py</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">image_stitching_simple.py</code>  file and insert the following code:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-c0"># import the necessary packages</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">from </span><span class="enlighter-k10">imutils</span><span class="enlighter-k0"> import</span><span class="enlighter-text"> paths</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> numpy </span><span class="enlighter-k0">as</span><span class="enlighter-text"> np</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> argparse</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> imutils</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> cv2</span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># construct the argument parser and parse the arguments</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap = argparse.</span><span class="enlighter-m1">ArgumentParser</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap.</span><span class="enlighter-m1">add_argument</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"-i"</span><span class="enlighter-text">, </span><span class="enlighter-s0">"--images"</span><span class="enlighter-text">, type=str, required=</span><span class="enlighter-e0">True</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">	help=</span><span class="enlighter-s0">"path to input directory of images to stitch"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap.</span><span class="enlighter-m1">add_argument</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"-o"</span><span class="enlighter-text">, </span><span class="enlighter-s0">"--output"</span><span class="enlighter-text">, type=str, required=</span><span class="enlighter-e0">True</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">	help=</span><span class="enlighter-s0">"path to the output image"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">args = </span><span class="enlighter-m0">vars</span><span class="enlighter-g1">(</span><span class="enlighter-text">ap.</span><span class="enlighter-m1">parse_args</span><span class="enlighter-g1">())</span></div></div></div><div class="enlighter-raw"># import the necessary packages
from imutils import paths
import numpy as np
import argparse
import imutils
import cv2

# construct the argument parser and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--images", type=str, required=True,
	help="path to input directory of images to stitch")
ap.add_argument("-o", "--output", type=str, required=True,
	help="path to the output image")
args = vars(ap.parse_args())</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="31"># import the necessary packages
from imutils import paths
import numpy as np
import argparse
import imutils
import cv2

# construct the argument parser and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--images", type=str, required=True,
	help="path to input directory of images to stitch")
ap.add_argument("-o", "--output", type=str, required=True,
	help="path to the output image")
args = vars(ap.parse_args())
</pre>


<p>Our required packages are imported on <strong>Lines 2-6</strong>. Notably, we’ll be using OpenCV and <a href="https://github.com/jrosebr1/imutils" target="_blank" rel="noopener noreferrer">imutils</a>. If you haven’t already, go ahead and install them:</p>
<ul>
<li>To install OpenCV, just follow one of my <a href="https://pyimagesearch.com/opencv-tutorials-resources-guides/" target="_blank" rel="noopener noreferrer">OpenCV installation guides</a>.</li>
<li>The imutils package can be installed/updated with pip: <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">pip install --upgrade imutils</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">pip install --upgrade imutils</code> . Be sure to upgrade it as new features are often added.</li>
</ul>
<p>From there we’ll parse two command line arguments on <strong>Lines 9-14</strong>:</p>
<ul>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">--images</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">--images</code> : The path to the directory of input images to stitch.</li>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">--output</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">--output</code> : The path to the output image where the result will be saved.</li>
</ul>
<p>If you aren’t familiar with the concepts of <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">argparse</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">argparse</code>  and command line arguments then read <a href="https://pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/" target="_blank" rel="noopener noreferrer">this blog post</a>.</p>
<p>Let’s load our input images:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 15"><div class=""><div><span class="enlighter-c0"># grab the paths to the input images and initialize our images list</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-m0">print</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"[INFO] loading images..."</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">imagePaths = </span><span class="enlighter-m0">sorted</span><span class="enlighter-g1">(</span><span class="enlighter-m0">list</span><span class="enlighter-g1">(</span><span class="enlighter-text">paths.</span><span class="enlighter-m1">list_images</span><span class="enlighter-g1">(</span><span class="enlighter-text">args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"images"</span><span class="enlighter-g1">])))</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">images = </span><span class="enlighter-g1">[]</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># loop over the image paths, load each one, and add them to our</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># images to stitch list</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k1">for</span><span class="enlighter-text"> imagePath </span><span class="enlighter-k0">in</span><span class="enlighter-text"> imagePaths:</span></div></div><div class=""><div><span class="enlighter-text">	image = cv2.</span><span class="enlighter-m1">imread</span><span class="enlighter-g1">(</span><span class="enlighter-text">imagePath</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	images.</span><span class="enlighter-m1">append</span><span class="enlighter-g1">(</span><span class="enlighter-text">image</span><span class="enlighter-g1">)</span></div></div></div><div class="enlighter-raw"># grab the paths to the input images and initialize our images list
print("[INFO] loading images...")
imagePaths = sorted(list(paths.list_images(args["images"])))
images = []

# loop over the image paths, load each one, and add them to our
# images to stitch list
for imagePath in imagePaths:
	image = cv2.imread(imagePath)
	images.append(image)</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="16" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="36"># grab the paths to the input images and initialize our images list
print("[INFO] loading images...")
imagePaths = sorted(list(paths.list_images(args["images"])))
images = []

# loop over the image paths, load each one, and add them to our
# images to stitch list
for imagePath in imagePaths:
	image = cv2.imread(imagePath)
	images.append(image)
</pre>


<p>Here we grab our <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">imagePaths</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">imagePaths</code>  (<strong>Line 18</strong>).</p>
<p>Then for each <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">imagePath</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">imagePath</code> , we’ll load the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">image</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">image</code>  and add it to the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">images</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">images</code>  list (<strong>Lines 19-25</strong>).</p>
<p>Now that the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">images</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">images</code>  are in memory, let’s go ahead and stitch them together into a panorama using OpenCV’s built-in capability:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 26"><div class=""><div><span class="enlighter-c0"># initialize OpenCV's image stitcher object and then perform the image</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># stitching</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-m0">print</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"[INFO] stitching images..."</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">stitcher = cv2.</span><span class="enlighter-m1">createStitcher</span><span class="enlighter-g1">()</span><span class="enlighter-text"> </span><span class="enlighter-k1">if</span><span class="enlighter-text"> imutils.</span><span class="enlighter-m1">is_cv3</span><span class="enlighter-g1">()</span><span class="enlighter-text"> </span><span class="enlighter-k1">else</span><span class="enlighter-text"> cv2.</span><span class="enlighter-m1">Stitcher_create</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-g1">(</span><span class="enlighter-text">status, stitched</span><span class="enlighter-g1">)</span><span class="enlighter-text"> = stitcher.</span><span class="enlighter-m1">stitch</span><span class="enlighter-g1">(</span><span class="enlighter-text">images</span><span class="enlighter-g1">)</span></div></div></div><div class="enlighter-raw"># initialize OpenCV's image stitcher object and then perform the image
# stitching
print("[INFO] stitching images...")
stitcher = cv2.createStitcher() if imutils.is_cv3() else cv2.Stitcher_create()
(status, stitched) = stitcher.stitch(images)</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="27" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="42"># initialize OpenCV's image stitcher object and then perform the image
# stitching
print("[INFO] stitching images...")
stitcher = cv2.createStitcher() if imutils.is_cv3() else cv2.Stitcher_create()
(status, stitched) = stitcher.stitch(images)
</pre>


<p>The <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">stitcher</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">stitcher</code>  object is created on <strong>Line 30</strong>. Notice that depending on whether you’re using OpenCV 3 or 4, a different constructor is called.</p>
<p>Subsequently, we can pass our <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">images</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">images</code>  to the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">.stitch</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">.stitch</code>  method (<strong>Line 31</strong>). The call to <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">.stitch</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">.stitch</code>  returns both a <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">status</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">status</code>  and our <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">stitched</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">stitched</code>  image (assuming the stitching was successful).</p>
<p>Finally, we’ll both (1) write the stitched image to disk and (2) display it on the screen:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 32"><div class=""><div><span class="enlighter-c0"># if the status is '0', then OpenCV successfully performed image</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># stitching</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k1">if</span><span class="enlighter-text"> status == </span><span class="enlighter-n1">0</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># write the output stitched image to disk</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	cv2.</span><span class="enlighter-m1">imwrite</span><span class="enlighter-g1">(</span><span class="enlighter-text">args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"output"</span><span class="enlighter-g1">]</span><span class="enlighter-text">, stitched</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># display the output stitched image to our screen</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	cv2.</span><span class="enlighter-m1">imshow</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"Stitched"</span><span class="enlighter-text">, stitched</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	cv2.</span><span class="enlighter-m1">waitKey</span><span class="enlighter-g1">(</span><span class="enlighter-n1">0</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># otherwise the stitching failed, likely due to not enough keypoints)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># being detected</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k1">else</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-m0">print</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"[INFO] image stitching failed ({})"</span><span class="enlighter-text">.</span><span class="enlighter-m1">format</span><span class="enlighter-g1">(</span><span class="enlighter-text">status</span><span class="enlighter-g1">))</span></div></div></div><div class="enlighter-raw"># if the status is '0', then OpenCV successfully performed image
# stitching
if status == 0:
	# write the output stitched image to disk
	cv2.imwrite(args["output"], stitched)

	# display the output stitched image to our screen
	cv2.imshow("Stitched", stitched)
	cv2.waitKey(0)

# otherwise the stitching failed, likely due to not enough keypoints)
# being detected
else:
	print("[INFO] image stitching failed ({})".format(status))</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="33" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="49"># if the status is '0', then OpenCV successfully performed image
# stitching
if status == 0:
	# write the output stitched image to disk
	cv2.imwrite(args["output"], stitched)

	# display the output stitched image to our screen
	cv2.imshow("Stitched", stitched)
	cv2.waitKey(0)

# otherwise the stitching failed, likely due to not enough keypoints)
# being detected
else:
	print("[INFO] image stitching failed ({})".format(status))
</pre>


<p>Assuming our <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">status</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">status</code>  flag indicates success (<strong>Line 35</strong>), we write the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">stitched</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">stitched</code>  image to disk (<strong>Line 37</strong>) and display it until a key is pressed (<strong>Lines 40 and 41</strong>).</p>
<p>Otherwise, we’ll simply print a failure message (<strong>Lines 45 and 46</strong>).</p>
<h3>Basic image stitching results</h3>
<p>To give our image stitching script a try, make sure you use the <em><strong>“Downloads”</strong></em> section of the tutorial to download the source code and example images.</p>
<p>Inside the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">images/scottsdale/</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">images/scottsdale/</code>  directory you will find three photos that I took when visiting Frank Lloyd Wright’s famous Taliesin West house in Scottsdale, AZ:</p>
<figure id="attachment_9293" aria-describedby="caption-attachment-9293" style="width: 600px" class="wp-caption aligncenter"><a href="https://pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg"><img class="wp-image-9293 entered lazyloaded" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/image_stitching_opencv_scottsdale.jpg" alt="" width="600" height="150" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?size=126x32&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale-300x75.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?size=378x95&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?size=504x126&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale-768x192.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale-1024x256.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" data-lazy-sizes="(max-width: 600px) 100vw, 600px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?size=600x150&amp;lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" sizes="(max-width: 600px) 100vw, 600px" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?size=126x32&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale-300x75.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?size=378x95&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?size=504x126&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale-768x192.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale-1024x256.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w"><noscript><img class="wp-image-9293" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?lossy=1&strip=1&webp=1" alt="" width="600" height="150" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?size=126x32&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale-300x75.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?size=378x95&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?size=504x126&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale-768x192.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale-1024x256.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_scottsdale.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" sizes="(max-width: 600px) 100vw, 600px" /></noscript></a><figcaption id="caption-attachment-9293" class="wp-caption-text"><strong>Figure 3:</strong> Three photos to test OpenCV image stitching with. These images were taken by me in Scottsdale, AZ at Frank Lloyd Wright’s famous Taliesin West house.</figcaption></figure>
<p>Our goal is to stitch these three images into a single panoramic image. To perform the stitching, open up a terminal, navigate to where you downloaded the code + images, and execute the following command:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-text">$ python image_stitching_simple.py --images images/scottsdale --output output.png</span></div></div><div class=""><div><span class="enlighter-text">[INFO] loading images...</span></div></div><div class=""><div><span class="enlighter-text">[INFO] stitching images...</span></div></div></div><div class="enlighter-raw">$ python image_stitching_simple.py --images images/scottsdale --output output.png
[INFO] loading images...
[INFO] stitching images...</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="53">$ python image_stitching_simple.py --images images/scottsdale --output output.png
[INFO] loading images...
[INFO] stitching images...
</pre>


<figure id="attachment_9294" aria-describedby="caption-attachment-9294" style="width: 600px" class="wp-caption aligncenter"><a href="https://pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg"><img class="wp-image-9294 entered lazyloaded" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/image_stitching_opencv_uncropped.jpg" alt="" width="600" height="268" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?size=126x56&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped-300x134.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?size=378x169&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?size=504x225&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped-768x344.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped-1024x458.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" data-lazy-sizes="(max-width: 600px) 100vw, 600px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?size=600x268&amp;lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" sizes="(max-width: 600px) 100vw, 600px" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?size=126x56&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped-300x134.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?size=378x169&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?size=504x225&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped-768x344.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped-1024x458.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w"><noscript><img class="wp-image-9294" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?lossy=1&strip=1&webp=1" alt="" width="600" height="268" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?size=126x56&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped-300x134.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?size=378x169&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?size=504x225&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped-768x344.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped-1024x458.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_uncropped.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" sizes="(max-width: 600px) 100vw, 600px" /></noscript></a><figcaption id="caption-attachment-9294" class="wp-caption-text"><strong>Figure 4:</strong> Image stitching performed with OpenCV. This image has undergone stitching but has yet to be cropped.</figcaption></figure>
<p>Notice how we have successfully performed image stitching!</p>
<p>But what about those black regions surrounding the panorama? What are those?</p>
<p>Those regions are from performing the perspective warps required to construct the panorama.</p>
<p>There is a way to get rid of them…but we’ll need to implement some additional logic in the next section.</p>
<h3>A better image stitcher with OpenCV and Python</h3>
<figure id="attachment_9295" aria-describedby="caption-attachment-9295" style="width: 600px" class="wp-caption aligncenter"><a href="https://pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg"><img class="wp-image-9295 entered lazyloaded" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/image_stitching_opencv_ideal.jpg" alt="" width="600" height="268" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?size=126x56&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal-300x134.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?size=378x169&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?size=504x225&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal-768x344.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal-1024x458.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" data-lazy-sizes="(max-width: 600px) 100vw, 600px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?size=600x268&amp;lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" sizes="(max-width: 600px) 100vw, 600px" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?size=126x56&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal-300x134.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?size=378x169&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?size=504x225&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal-768x344.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal-1024x458.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w"><noscript><img class="wp-image-9295" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?lossy=1&strip=1&webp=1" alt="" width="600" height="268" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?size=126x56&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal-300x134.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?size=378x169&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?size=504x225&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal-768x344.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal-1024x458.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_ideal.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" sizes="(max-width: 600px) 100vw, 600px" /></noscript></a><figcaption id="caption-attachment-9295" class="wp-caption-text"><strong>Figure 5:</strong> In this section, we’ll learn how to improve image stitching with OpenCV by cropping out the region of the panorama inside the red-dash border shown in the figure.</figcaption></figure>
<p>Our first image stitching script was a good start but those black regions surrounding the panorama itself are not something we would call “aesthetically pleasing”.</p>
<p>And more to the point, you wouldn’t see such an output image from popular image stitching applications built into iOS, Android, etc.</p>
<p>Therefore, we’re going to hack our script a bit and include some additional logic to create more aesthetically pleasing panoramas.</p>
<p><strong>I’m going to again reiterate that this method is a hack.</strong></p>
<p>We’ll be reviewing basic image processing operations including threshold, contour extraction, morphological operations, etc. in order to obtain our desired result.</p>
<p>To my knowledge, OpenCV’s Python bindings do not provide us with the required information to manually extract the maximum inner rectangular region of the panorama. <strong>If OpenCV does, please let me know in the comments as I would love to know.</strong></p>
<p>Let’s go ahead and get started — open up the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">image_stitching.py</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">image_stitching.py</code>  script and insert the following code:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-c0"># import the necessary packages</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">from </span><span class="enlighter-k10">imutils</span><span class="enlighter-k0"> import</span><span class="enlighter-text"> paths</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> numpy </span><span class="enlighter-k0">as</span><span class="enlighter-text"> np</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> argparse</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> imutils</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> cv2</span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># construct the argument parser and parse the arguments</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap = argparse.</span><span class="enlighter-m1">ArgumentParser</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap.</span><span class="enlighter-m1">add_argument</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"-i"</span><span class="enlighter-text">, </span><span class="enlighter-s0">"--images"</span><span class="enlighter-text">, type=str, required=</span><span class="enlighter-e0">True</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">	help=</span><span class="enlighter-s0">"path to input directory of images to stitch"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap.</span><span class="enlighter-m1">add_argument</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"-o"</span><span class="enlighter-text">, </span><span class="enlighter-s0">"--output"</span><span class="enlighter-text">, type=str, required=</span><span class="enlighter-e0">True</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">	help=</span><span class="enlighter-s0">"path to the output image"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap.</span><span class="enlighter-m1">add_argument</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"-c"</span><span class="enlighter-text">, </span><span class="enlighter-s0">"--crop"</span><span class="enlighter-text">, type=int, default=</span><span class="enlighter-n1">0</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">	help=</span><span class="enlighter-s0">"whether to crop out largest rectangular region"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">args = </span><span class="enlighter-m0">vars</span><span class="enlighter-g1">(</span><span class="enlighter-text">ap.</span><span class="enlighter-m1">parse_args</span><span class="enlighter-g1">())</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># grab the paths to the input images and initialize our images list</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-m0">print</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"[INFO] loading images..."</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">imagePaths = </span><span class="enlighter-m0">sorted</span><span class="enlighter-g1">(</span><span class="enlighter-m0">list</span><span class="enlighter-g1">(</span><span class="enlighter-text">paths.</span><span class="enlighter-m1">list_images</span><span class="enlighter-g1">(</span><span class="enlighter-text">args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"images"</span><span class="enlighter-g1">])))</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">images = </span><span class="enlighter-g1">[]</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># loop over the image paths, load each one, and add them to our</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># images to stich list</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k1">for</span><span class="enlighter-text"> imagePath </span><span class="enlighter-k0">in</span><span class="enlighter-text"> imagePaths:</span></div></div><div class=""><div><span class="enlighter-text">	image = cv2.</span><span class="enlighter-m1">imread</span><span class="enlighter-g1">(</span><span class="enlighter-text">imagePath</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	images.</span><span class="enlighter-m1">append</span><span class="enlighter-g1">(</span><span class="enlighter-text">image</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># initialize OpenCV's image sticher object and then perform the image</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># stitching</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-m0">print</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"[INFO] stitching images..."</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">stitcher = cv2.</span><span class="enlighter-m1">createStitcher</span><span class="enlighter-g1">()</span><span class="enlighter-text"> </span><span class="enlighter-k1">if</span><span class="enlighter-text"> imutils.</span><span class="enlighter-m1">is_cv3</span><span class="enlighter-g1">()</span><span class="enlighter-text"> </span><span class="enlighter-k1">else</span><span class="enlighter-text"> cv2.</span><span class="enlighter-m1">Stitcher_create</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-g1">(</span><span class="enlighter-text">status, stitched</span><span class="enlighter-g1">)</span><span class="enlighter-text"> = stitcher.</span><span class="enlighter-m1">stitch</span><span class="enlighter-g1">(</span><span class="enlighter-text">images</span><span class="enlighter-g1">)</span></div></div></div><div class="enlighter-raw"># import the necessary packages
from imutils import paths
import numpy as np
import argparse
import imutils
import cv2

# construct the argument parser and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--images", type=str, required=True,
	help="path to input directory of images to stitch")
ap.add_argument("-o", "--output", type=str, required=True,
	help="path to the output image")
ap.add_argument("-c", "--crop", type=int, default=0,
	help="whether to crop out largest rectangular region")
args = vars(ap.parse_args())

# grab the paths to the input images and initialize our images list
print("[INFO] loading images...")
imagePaths = sorted(list(paths.list_images(args["images"])))
images = []

# loop over the image paths, load each one, and add them to our
# images to stich list
for imagePath in imagePaths:
	image = cv2.imread(imagePath)
	images.append(image)

# initialize OpenCV's image sticher object and then perform the image
# stitching
print("[INFO] stitching images...")
stitcher = cv2.createStitcher() if imutils.is_cv3() else cv2.Stitcher_create()
(status, stitched) = stitcher.stitch(images)</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="55"># import the necessary packages
from imutils import paths
import numpy as np
import argparse
import imutils
import cv2

# construct the argument parser and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--images", type=str, required=True,
	help="path to input directory of images to stitch")
ap.add_argument("-o", "--output", type=str, required=True,
	help="path to the output image")
ap.add_argument("-c", "--crop", type=int, default=0,
	help="whether to crop out largest rectangular region")
args = vars(ap.parse_args())

# grab the paths to the input images and initialize our images list
print("[INFO] loading images...")
imagePaths = sorted(list(paths.list_images(args["images"])))
images = []

# loop over the image paths, load each one, and add them to our
# images to stich list
for imagePath in imagePaths:
	image = cv2.imread(imagePath)
	images.append(image)

# initialize OpenCV's image sticher object and then perform the image
# stitching
print("[INFO] stitching images...")
stitcher = cv2.createStitcher() if imutils.is_cv3() else cv2.Stitcher_create()
(status, stitched) = stitcher.stitch(images)
</pre>


<p>All of this code is identical to our previous script with one exception.</p>
<p>The <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">--crop</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">--crop</code>  command line argument has been added. When a <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">1</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">1</code>  is provided for this argument in the terminal, we’ll go ahead and perform our cropping hack.</p>
<p>The next step is where we start implementing additional functionality:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 34"><div class=""><div><span class="enlighter-c0"># if the status is '0', then OpenCV successfully performed image</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># stitching</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k1">if</span><span class="enlighter-text"> status == </span><span class="enlighter-n1">0</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># check to see if we supposed to crop out the largest rectangular</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># region from the stitched image</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-k1">if</span><span class="enlighter-text"> args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"crop"</span><span class="enlighter-g1">]</span><span class="enlighter-text"> </span><span class="enlighter-g1">&gt;</span><span class="enlighter-text"> </span><span class="enlighter-n1">0</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># create a 10 pixel border surrounding the stitched image</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-m0">print</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"[INFO] cropping..."</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		stitched = cv2.</span><span class="enlighter-m1">copyMakeBorder</span><span class="enlighter-g1">(</span><span class="enlighter-text">stitched, </span><span class="enlighter-n1">10</span><span class="enlighter-text">, </span><span class="enlighter-n1">10</span><span class="enlighter-text">, </span><span class="enlighter-n1">10</span><span class="enlighter-text">, </span><span class="enlighter-n1">10</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">			cv2.BORDER_CONSTANT, </span><span class="enlighter-g1">(</span><span class="enlighter-n1">0</span><span class="enlighter-text">, </span><span class="enlighter-n1">0</span><span class="enlighter-text">, </span><span class="enlighter-n1">0</span><span class="enlighter-g1">))</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># convert the stitched image to grayscale and threshold it</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># such that all pixels greater than zero are set to 255</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># (foreground) while all others remain 0 (background)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		gray = cv2.</span><span class="enlighter-m1">cvtColor</span><span class="enlighter-g1">(</span><span class="enlighter-text">stitched, cv2.COLOR_BGR2GRAY</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		thresh = cv2.</span><span class="enlighter-m1">threshold</span><span class="enlighter-g1">(</span><span class="enlighter-text">gray, </span><span class="enlighter-n1">0</span><span class="enlighter-text">, </span><span class="enlighter-n1">255</span><span class="enlighter-text">, cv2.THRESH_BINARY</span><span class="enlighter-g1">)[</span><span class="enlighter-n1">1</span><span class="enlighter-g1">]</span></div></div></div><div class="enlighter-raw"># if the status is '0', then OpenCV successfully performed image
# stitching
if status == 0:
	# check to see if we supposed to crop out the largest rectangular
	# region from the stitched image
	if args["crop"] &gt; 0:
		# create a 10 pixel border surrounding the stitched image
		print("[INFO] cropping...")
		stitched = cv2.copyMakeBorder(stitched, 10, 10, 10, 10,
			cv2.BORDER_CONSTANT, (0, 0, 0))

		# convert the stitched image to grayscale and threshold it
		# such that all pixels greater than zero are set to 255
		# (foreground) while all others remain 0 (background)
		gray = cv2.cvtColor(stitched, cv2.COLOR_BGR2GRAY)
		thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1]</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="35" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="58"># if the status is '0', then OpenCV successfully performed image
# stitching
if status == 0:
	# check to see if we supposed to crop out the largest rectangular
	# region from the stitched image
	if args["crop"] &gt; 0:
		# create a 10 pixel border surrounding the stitched image
		print("[INFO] cropping...")
		stitched = cv2.copyMakeBorder(stitched, 10, 10, 10, 10,
			cv2.BORDER_CONSTANT, (0, 0, 0))

		# convert the stitched image to grayscale and threshold it
		# such that all pixels greater than zero are set to 255
		# (foreground) while all others remain 0 (background)
		gray = cv2.cvtColor(stitched, cv2.COLOR_BGR2GRAY)
		thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1]
</pre>


<p>Notice how I’ve made a new block for when the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">--crop</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">--crop</code>  flag is set on <strong>Line 40</strong>. Let’s begin going through this block:</p>
<ul>
<li>First, we’ll add a <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">10</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">10</code>  pixel border to all sides of our <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">stitched</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">stitched</code>  image (<strong>Lines 43 and 44</strong>), ensuring we’ll be able to find contours of the complete panorama outline later in this section.</li>
<li>Then we’re going to create a <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">gray</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">gray</code>  version of our <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">stitched</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">stitched</code>  image (<strong>Line 49</strong>).</li>
<li>And from there we threshold the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">gray</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">gray</code>  image (<strong>Line 50</strong>).</li>
</ul>
<p>Here is the result (<div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">thresh</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">thresh</code> ) of those three steps:</p>
<figure id="attachment_9296" aria-describedby="caption-attachment-9296" style="width: 600px" class="wp-caption aligncenter"><a href="https://pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg"><img class="wp-image-9296 entered lazyloaded" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/image_stitching_opencv_thresh.jpg" alt="" width="600" height="278" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?size=126x58&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh-300x139.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?size=378x175&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?size=504x234&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh-768x356.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh-1024x475.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" data-lazy-sizes="(max-width: 600px) 100vw, 600px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?size=600x278&amp;lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" sizes="(max-width: 600px) 100vw, 600px" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?size=126x58&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh-300x139.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?size=378x175&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?size=504x234&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh-768x356.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh-1024x475.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w"><noscript><img class="wp-image-9296" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?lossy=1&strip=1&webp=1" alt="" width="600" height="278" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?size=126x58&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh-300x139.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?size=378x175&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?size=504x234&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh-768x356.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh-1024x475.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_thresh.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" sizes="(max-width: 600px) 100vw, 600px" /></noscript></a><figcaption id="caption-attachment-9296" class="wp-caption-text"><strong>Figure 6:</strong> After thresholding, we’re presented with this threshold mask highlighting where the OpenCV stitched + warped image resides.</figcaption></figure>
<p>We now have a binary image of our panorama where white pixels (255) are the foreground and black pixels (0) are the background.</p>
<p>Given our thresholded image we can apply contour extraction, compute the bounding box of the largest contour (i.e., the outline of the panorama itself), and draw the bounding box:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 51"><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># find all external contours in the threshold image then find</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># the *largest* contour which will be the contour/outline of</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># the stitched image</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		cnts = cv2.</span><span class="enlighter-m1">findContours</span><span class="enlighter-g1">(</span><span class="enlighter-text">thresh.</span><span class="enlighter-m1">copy</span><span class="enlighter-g1">()</span><span class="enlighter-text">, cv2.RETR_EXTERNAL,</span></div></div><div class=""><div><span class="enlighter-text">			cv2.CHAIN_APPROX_SIMPLE</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		cnts = imutils.</span><span class="enlighter-m1">grab_contours</span><span class="enlighter-g1">(</span><span class="enlighter-text">cnts</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		c = </span><span class="enlighter-m0">max</span><span class="enlighter-g1">(</span><span class="enlighter-text">cnts, key=cv2.contourArea</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># allocate memory for the mask which will contain the</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># rectangular bounding box of the stitched image region</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		mask = np.</span><span class="enlighter-m1">zeros</span><span class="enlighter-g1">(</span><span class="enlighter-text">thresh.shape, dtype=</span><span class="enlighter-s0">"uint8"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-g1">(</span><span class="enlighter-text">x, y, w, h</span><span class="enlighter-g1">)</span><span class="enlighter-text"> = cv2.</span><span class="enlighter-m1">boundingRect</span><span class="enlighter-g1">(</span><span class="enlighter-text">c</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		cv2.</span><span class="enlighter-m1">rectangle</span><span class="enlighter-g1">(</span><span class="enlighter-text">mask, </span><span class="enlighter-g1">(</span><span class="enlighter-text">x, y</span><span class="enlighter-g1">)</span><span class="enlighter-text">, </span><span class="enlighter-g1">(</span><span class="enlighter-text">x + w, y + h</span><span class="enlighter-g1">)</span><span class="enlighter-text">, </span><span class="enlighter-n1">255</span><span class="enlighter-text">, </span><span class="enlighter-n1">-1</span><span class="enlighter-g1">)</span></div></div></div><div class="enlighter-raw">		# find all external contours in the threshold image then find
		# the *largest* contour which will be the contour/outline of
		# the stitched image
		cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,
			cv2.CHAIN_APPROX_SIMPLE)
		cnts = imutils.grab_contours(cnts)
		c = max(cnts, key=cv2.contourArea)

		# allocate memory for the mask which will contain the
		# rectangular bounding box of the stitched image region
		mask = np.zeros(thresh.shape, dtype="uint8")
		(x, y, w, h) = cv2.boundingRect(c)
		cv2.rectangle(mask, (x, y), (x + w, y + h), 255, -1)</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="52" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="66">		# find all external contours in the threshold image then find
		# the *largest* contour which will be the contour/outline of
		# the stitched image
		cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,
			cv2.CHAIN_APPROX_SIMPLE)
		cnts = imutils.grab_contours(cnts)
		c = max(cnts, key=cv2.contourArea)

		# allocate memory for the mask which will contain the
		# rectangular bounding box of the stitched image region
		mask = np.zeros(thresh.shape, dtype="uint8")
		(x, y, w, h) = cv2.boundingRect(c)
		cv2.rectangle(mask, (x, y), (x + w, y + h), 255, -1)
</pre>


<p>Contours are extracted and parsed on <strong>Lines 55-57</strong>. <strong>Line 58</strong> then grabs the contour with the largest area (i.e., the outline of the stitched image itself).</p>
<p><em><strong>Note:</strong> The <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">imutils.grab_contours</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">imutils.grab_contours</code>  function is new in <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">imutils==</span><span class="enlighter-n0">0.5</span><span class="enlighter-text">.</span><span class="enlighter-n1">2</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">imutils==0.5.2</code>  to accommodate OpenCV 2.4, OpenCV 3, and OpenCV 4 and their different return signatures for <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.findContours</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.findContours</code> .</em></p>
<p><strong>Line 62</strong> allocates memory for our new rectangular mask. <strong>Line 63</strong> then calculates the bounding box of our largest contour. Using the bounding rectangle information, on <strong>Line 64</strong>, we draw a solid white rectangle on the mask.</p>
<p>The output of the above code block would look like the following:</p>
<figure id="attachment_9297" aria-describedby="caption-attachment-9297" style="width: 600px" class="wp-caption aligncenter"><a href="https://pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg"><img class="wp-image-9297 entered lazyloaded" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/image_stitching_opencv_mask.jpg" alt="" width="600" height="272" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?size=126x57&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask-300x136.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?size=378x171&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?size=504x228&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask-768x349.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask-1024x465.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" data-lazy-sizes="(max-width: 600px) 100vw, 600px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?size=600x272&amp;lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" sizes="(max-width: 600px) 100vw, 600px" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?size=126x57&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask-300x136.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?size=378x171&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?size=504x228&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask-768x349.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask-1024x465.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w"><noscript><img class="wp-image-9297" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?lossy=1&strip=1&webp=1" alt="" width="600" height="272" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?size=126x57&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask-300x136.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?size=378x171&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?size=504x228&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask-768x349.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask-1024x465.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_mask.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" sizes="(max-width: 600px) 100vw, 600px" /></noscript></a><figcaption id="caption-attachment-9297" class="wp-caption-text"><strong>Figure 7:</strong> The smallest rectangular region that the entire OpenCV panorama can fit in.</figcaption></figure>
<p>This bounding box is the <em>smallest rectangular region</em> that the <em>entire panorama</em> can fit in.</p>
<p>Now, here comes one of the biggest hacks I’ve ever put together for a blog post:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 65"><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># create two copies of the mask: one to serve as our actual</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># minimum rectangular region and another to serve as a counter</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># for how many pixels need to be removed to form the minimum</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># rectangular region</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		minRect = mask.</span><span class="enlighter-m1">copy</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		sub = mask.</span><span class="enlighter-m1">copy</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># keep looping until there are no non-zero pixels left in the</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># subtracted image</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-k1">while</span><span class="enlighter-text"> cv2.</span><span class="enlighter-m1">countNonZero</span><span class="enlighter-g1">(</span><span class="enlighter-text">sub</span><span class="enlighter-g1">)</span><span class="enlighter-text"> </span><span class="enlighter-g1">&gt;</span><span class="enlighter-text"> </span><span class="enlighter-n1">0</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># erode the minimum rectangular mask and then subtract</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># the thresholded image from the minimum rectangular mask</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># so we can count if there are any non-zero pixels left</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			minRect = cv2.</span><span class="enlighter-m1">erode</span><span class="enlighter-g1">(</span><span class="enlighter-text">minRect, </span><span class="enlighter-e1">None</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			sub = cv2.</span><span class="enlighter-m1">subtract</span><span class="enlighter-g1">(</span><span class="enlighter-text">minRect, thresh</span><span class="enlighter-g1">)</span></div></div></div><div class="enlighter-raw">		# create two copies of the mask: one to serve as our actual
		# minimum rectangular region and another to serve as a counter
		# for how many pixels need to be removed to form the minimum
		# rectangular region
		minRect = mask.copy()
		sub = mask.copy()

		# keep looping until there are no non-zero pixels left in the
		# subtracted image
		while cv2.countNonZero(sub) &gt; 0:
			# erode the minimum rectangular mask and then subtract
			# the thresholded image from the minimum rectangular mask
			# so we can count if there are any non-zero pixels left
			minRect = cv2.erode(minRect, None)
			sub = cv2.subtract(minRect, thresh)</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="66" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="70">		# create two copies of the mask: one to serve as our actual
		# minimum rectangular region and another to serve as a counter
		# for how many pixels need to be removed to form the minimum
		# rectangular region
		minRect = mask.copy()
		sub = mask.copy()

		# keep looping until there are no non-zero pixels left in the
		# subtracted image
		while cv2.countNonZero(sub) &gt; 0:
			# erode the minimum rectangular mask and then subtract
			# the thresholded image from the minimum rectangular mask
			# so we can count if there are any non-zero pixels left
			minRect = cv2.erode(minRect, None)
			sub = cv2.subtract(minRect, thresh)
</pre>


<p>On <strong>Lines 70 and 71</strong> we create two copies of our <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">mask</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">mask</code>  image:</p>
<ol>
<li>The first mask, <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">minMask</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">minMask</code> , will be slowly reduced in size until it can fit inside the inner part of the panorama (see <strong>Figure 5</strong> at the top of this section).</li>
<li>The second mask, <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">sub</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">sub</code> , will be used to determine if we need to keep reducing the size of <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">minMask</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">minMask</code> .</li>
</ol>
<p><strong>Line 75</strong> starts a <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-k1">while</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">while</code>  loop that will continue looping until there are no more foreground pixels in <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">sub</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">sub</code> .</p>
<p><strong>Line 79</strong> performs an erosion morphological operation to reduce the size of <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">minRect</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">minRect</code> .</p>
<p><strong>Line 80</strong> then subtracts <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">thresh</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">thresh</code>  from <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">minRect</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">minRect</code>  — once there are no more foreground pixels in <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">minRect</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">minRect</code>  then we can break from the loop.</p>
<p>I have included an animation of the hack below:</p>
<figure style="width: 600px" class="wp-caption aligncenter"><img class="size-full entered error" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/image_stitching_opencv_morphological.gif" width="600" height="489" data-lazy-src="https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/image-stitching-python/image_stitching_opencv_morphological.gif" data-ll-status="error"><noscript><img class="size-full" src="https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/image-stitching-python/image_stitching_opencv_morphological.gif" width="600" height="489"></noscript><figcaption class="wp-caption-text"><strong>Figure 8:</strong> An animation of the hack I came up with to extract the <code>minRect</code> region of the OpenCV panorama image, making for an aesthetically pleasing stitched image</figcaption></figure>
<p>On the <em>top</em>, we have our <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">sub</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">sub</code>  image and on the <em>bottom</em> we have the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">minRect</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">minRect</code>  image.</p>
<p>Notice how the size of <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">minRect</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">minRect</code>  is progressively reduced until there are no more foreground pixels left in <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">sub</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">sub</code>  — at this point we know we have found the <em>smallest rectangular mask</em> that can fit into the largest rectangular region of the panorama.</p>
<p>Given the minimum inner rectangle we can again find contours and compute the bounding box, but this time we’ll simply extract the ROI from the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">stitched</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">stitched</code>  image:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 81"><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># find contours in the minimum rectangular mask and then</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># extract the bounding box (x, y)-coordinates</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		cnts = cv2.</span><span class="enlighter-m1">findContours</span><span class="enlighter-g1">(</span><span class="enlighter-text">minRect.</span><span class="enlighter-m1">copy</span><span class="enlighter-g1">()</span><span class="enlighter-text">, cv2.RETR_EXTERNAL,</span></div></div><div class=""><div><span class="enlighter-text">			cv2.CHAIN_APPROX_SIMPLE</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		cnts = imutils.</span><span class="enlighter-m1">grab_contours</span><span class="enlighter-g1">(</span><span class="enlighter-text">cnts</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		c = </span><span class="enlighter-m0">max</span><span class="enlighter-g1">(</span><span class="enlighter-text">cnts, key=cv2.contourArea</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-g1">(</span><span class="enlighter-text">x, y, w, h</span><span class="enlighter-g1">)</span><span class="enlighter-text"> = cv2.</span><span class="enlighter-m1">boundingRect</span><span class="enlighter-g1">(</span><span class="enlighter-text">c</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># use the bounding box coordinates to extract the our final</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># stitched image</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		stitched = stitched</span><span class="enlighter-g1">[</span><span class="enlighter-text">y:y + h, x:x + w</span><span class="enlighter-g1">]</span></div></div></div><div class="enlighter-raw">		# find contours in the minimum rectangular mask and then
		# extract the bounding box (x, y)-coordinates
		cnts = cv2.findContours(minRect.copy(), cv2.RETR_EXTERNAL,
			cv2.CHAIN_APPROX_SIMPLE)
		cnts = imutils.grab_contours(cnts)
		c = max(cnts, key=cv2.contourArea)
		(x, y, w, h) = cv2.boundingRect(c)

		# use the bounding box coordinates to extract the our final
		# stitched image
		stitched = stitched[y:y + h, x:x + w]</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="82" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="86">		# find contours in the minimum rectangular mask and then
		# extract the bounding box (x, y)-coordinates
		cnts = cv2.findContours(minRect.copy(), cv2.RETR_EXTERNAL,
			cv2.CHAIN_APPROX_SIMPLE)
		cnts = imutils.grab_contours(cnts)
		c = max(cnts, key=cv2.contourArea)
		(x, y, w, h) = cv2.boundingRect(c)

		# use the bounding box coordinates to extract the our final
		# stitched image
		stitched = stitched[y:y + h, x:x + w]
</pre>


<p>Here we have:</p>
<ul>
<li>Found contours in <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">minRect</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">minRect</code>  (<strong>Lines 84 and 85</strong>).</li>
<li>Handled parsing contours for multiple OpenCV versions (<strong>Line 86</strong>). You’ll need <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">imutils</span><span class="enlighter-g1">&gt;</span><span class="enlighter-text">=</span><span class="enlighter-n0">0.5</span><span class="enlighter-text">.</span><span class="enlighter-n1">2</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">imutils&gt;=0.5.2</code>  to use this function.</li>
<li>Grabbed the largest contour (<strong>Line 87</strong>).</li>
<li>Computed the bounding box of the largest contour (<strong>Line 88</strong>).</li>
<li>Extracted the ROI from our <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">stitched</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">stitched</code> using the bounding box information (<strong>Line 92</strong>).</li>
</ul>
<p>The final <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">stitched</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">stitched</code>  image can be displayed to our screen and then saved to disk:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 93"><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># write the output stitched image to disk</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	cv2.</span><span class="enlighter-m1">imwrite</span><span class="enlighter-g1">(</span><span class="enlighter-text">args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"output"</span><span class="enlighter-g1">]</span><span class="enlighter-text">, stitched</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># display the output stitched image to our screen</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	cv2.</span><span class="enlighter-m1">imshow</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"Stitched"</span><span class="enlighter-text">, stitched</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	cv2.</span><span class="enlighter-m1">waitKey</span><span class="enlighter-g1">(</span><span class="enlighter-n1">0</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># otherwise the stitching failed, likely due to not enough keypoints)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># being detected</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k1">else</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-m0">print</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"[INFO] image stitching failed ({})"</span><span class="enlighter-text">.</span><span class="enlighter-m1">format</span><span class="enlighter-g1">(</span><span class="enlighter-text">status</span><span class="enlighter-g1">))</span></div></div></div><div class="enlighter-raw">	# write the output stitched image to disk
	cv2.imwrite(args["output"], stitched)

	# display the output stitched image to our screen
	cv2.imshow("Stitched", stitched)
	cv2.waitKey(0)

# otherwise the stitching failed, likely due to not enough keypoints)
# being detected
else:
	print("[INFO] image stitching failed ({})".format(status))</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="94" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="91">	# write the output stitched image to disk
	cv2.imwrite(args["output"], stitched)

	# display the output stitched image to our screen
	cv2.imshow("Stitched", stitched)
	cv2.waitKey(0)

# otherwise the stitching failed, likely due to not enough keypoints)
# being detected
else:
	print("[INFO] image stitching failed ({})".format(status))
</pre>


<p><strong>Lines 95-99</strong> handle saving and displaying the image regardless of whether or not our cropping hack is performed.</p>
<p>Just as before, if the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">status</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">status</code>  flag didn’t come back as a success, we’ll print an error message (<strong>Lines 103 and 104</strong>).</p>
<p>Let’s go ahead and check out the results of our improved image stitching + OpenCV pipeline.</p>
<h3>Improved image stitching results</h3>
<p>Again, make sure you have used the <em><strong>“Downloads”</strong></em> section of today’s tutorial to download the source code and example images.</p>
<p>From there, open up a terminal and execute the following command:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-text">$ python image_stitching.py --images images/scottsdale --output output.png \</span></div></div><div class=""><div><span class="enlighter-text">	--crop </span><span class="enlighter-n1">1</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">[INFO] loading images...</span></div></div><div class=""><div><span class="enlighter-text">[INFO] stitching images...</span></div></div><div class=""><div><span class="enlighter-text">[INFO] cropping...</span></div></div></div><div class="enlighter-raw">$ python image_stitching.py --images images/scottsdale --output output.png \
	--crop 1
[INFO] loading images...
[INFO] stitching images...
[INFO] cropping...</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="93">$ python image_stitching.py --images images/scottsdale --output output.png \
	--crop 1
[INFO] loading images...
[INFO] stitching images...
[INFO] cropping...
</pre>


<figure id="attachment_9298" aria-describedby="caption-attachment-9298" style="width: 600px" class="wp-caption aligncenter"><a href="https://pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg"><img class="wp-image-9298 entered lazyloaded" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/image_stitching_opencv_cropped.jpg" alt="" width="600" height="245" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?size=126x51&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped-300x123.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?size=378x154&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?size=504x206&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped-768x314.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped-1024x418.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" data-lazy-sizes="(max-width: 600px) 100vw, 600px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?size=600x245&amp;lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" sizes="(max-width: 600px) 100vw, 600px" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?size=126x51&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped-300x123.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?size=378x154&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?size=504x206&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped-768x314.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped-1024x418.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w"><noscript><img class="wp-image-9298" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?lossy=1&strip=1&webp=1" alt="" width="600" height="245" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?size=126x51&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped-300x123.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?size=378x154&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?size=504x206&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped-768x314.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped-1024x418.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/12/image_stitching_opencv_cropped.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" sizes="(max-width: 600px) 100vw, 600px" /></noscript></a><figcaption id="caption-attachment-9298" class="wp-caption-text"><strong>Figure 8:</strong> The result of our multiple image stitching with OpenCV and Python.</figcaption></figure>
<p>Notice how this time we have removed the black regions from the output stitched images (caused by the warping transformations) by applying our hack detailed in the section above.</p>
<h3>Limitations and drawbacks</h3>
<p>In a previous tutorial, I demonstrated how you could build a <a href="https://pyimagesearch.com/2016/01/25/real-time-panorama-and-image-stitching-with-opencv/" target="_blank" rel="noopener noreferrer">real-time panorama and image stitching algorithm</a> — this tutorial hinged on the fact that we were manually performing keypoint detection, feature extraction, and keypoint matching, giving us access to the homography matrix used to warp our two input images into a panorama.</p>
<p>And while OpenCV’s built-in <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.createStitcher</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.createStitcher</code>  and <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.Stitcher_create</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.Stitcher_create</code>  functions are certainly capable of constructing accurate, aesthetically pleasing panoramas, one of the primary drawbacks of the method is that it abstracts away any access to the homography matrices.</p>
<p>One of the assumptions of real-time panorama construction is that the scene itself is not changing much in terms of content.</p>
<p>Once we compute the initial homography estimation we should only have to occasionally recompute the matrix.</p>
<p>Not having to perform a full-blown keypoint matching and RANSAC estimation gives us a tremendous boost of speed when building our panorama, so without access to the raw homography matrices, it would be challenging to take OpenCV’s built-in image stitching algorithm and convert it to real-time.</p>
<h3>Running into errors when performing image stitching using OpenCV?</h3>
<p>It is possible that you may run into errors when trying to use either the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.createStitcher</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.createStitcher</code>  function or <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.Stitcher_create</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.Stitcher_create</code>  functions.</p>
<p>The two “easy to resolve” errors I see people encounter is forgetting what version of OpenCV they are using.</p>
<p>For example, if you are using OpenCV 4 but try to call <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.createSticher</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.createSticher</code>  you will encounter the following error message:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-g1">&gt;&gt;&gt;</span><span class="enlighter-text"> cv2.createStitcher</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-m0">Traceback</span><span class="enlighter-text"> </span><span class="enlighter-g1">(</span><span class="enlighter-text">most recent call last</span><span class="enlighter-g1">)</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text">  File </span><span class="enlighter-s0">"&lt;stdin&gt;"</span><span class="enlighter-text">, line </span><span class="enlighter-n1">1</span><span class="enlighter-text">, </span><span class="enlighter-k0">in</span><span class="enlighter-text"> </span><span class="enlighter-g1">&lt;</span><span class="enlighter-text">module</span><span class="enlighter-g1">&gt;</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">AttributeError: module </span><span class="enlighter-s0">'cv2'</span><span class="enlighter-text"> has no attribute </span><span class="enlighter-s0">'createStitcher'</span></div></div></div><div class="enlighter-raw">&gt;&gt;&gt; cv2.createStitcher
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
AttributeError: module 'cv2' has no attribute 'createStitcher'</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="99">&gt;&gt;&gt; cv2.createStitcher
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
AttributeError: module 'cv2' has no attribute 'createStitcher'
</pre>


<p>You should instead be using the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.Stitcher_create</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.Stitcher_create</code>  function.</p>
<p>Similarly, if you are using OpenCV 3 and you try to call <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.Sticher_create</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.Sticher_create</code>  you will receive this error:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-g1">&gt;&gt;&gt;</span><span class="enlighter-text"> cv2.Stitcher_create</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-m0">Traceback</span><span class="enlighter-text"> </span><span class="enlighter-g1">(</span><span class="enlighter-text">most recent call last</span><span class="enlighter-g1">)</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text">  File </span><span class="enlighter-s0">"&lt;stdin&gt;"</span><span class="enlighter-text">, line </span><span class="enlighter-n1">1</span><span class="enlighter-text">, </span><span class="enlighter-k0">in</span><span class="enlighter-text"> </span><span class="enlighter-g1">&lt;</span><span class="enlighter-text">module</span><span class="enlighter-g1">&gt;</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">AttributeError: module </span><span class="enlighter-s0">'cv2'</span><span class="enlighter-text"> has no attribute </span><span class="enlighter-s0">'Stitcher_create'</span></div></div></div><div class="enlighter-raw">&gt;&gt;&gt; cv2.Stitcher_create
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
AttributeError: module 'cv2' has no attribute 'Stitcher_create'</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="102">&gt;&gt;&gt; cv2.Stitcher_create
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
AttributeError: module 'cv2' has no attribute 'Stitcher_create'
</pre>


<p>Instead, use the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.createSticher</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.createSticher</code>  function.</p>
<p>If you are unsure which OpenCV version you are using you can check using <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.</span><span class="enlighter-e3">__version__</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.__version__</code> :</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Image Stitching with OpenCV and Python</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-g1">&gt;&gt;&gt;</span><span class="enlighter-text"> cv2.</span><span class="enlighter-e3">__version__</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-s0">'4.0.0'</span></div></div></div><div class="enlighter-raw">&gt;&gt;&gt; cv2.__version__
'4.0.0'</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Image Stitching with OpenCV and Python" data-enlighter-group="105">&gt;&gt;&gt; cv2.__version__
'4.0.0'
</pre>


<p>Here you can see that I am using OpenCV 4.0.0.</p>
<p>You can perform the same check on your system.</p>
<p><strong>The final error that you can encounter, and arguably the most common,</strong> is related to OpenCV (1) not having contrib support and (2) being compiled without the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-k7">OPENCV_ENABLE_NONFREE</span><span class="enlighter-text">=ON</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">OPENCV_ENABLE_NONFREE=ON</code>&nbsp; option enabled.</p>
<p>To resolve this error you must have the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">opencv_contrib</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">opencv_contrib</code>&nbsp; modules installed along with the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">OPENCV_ENABLE_NONFREE</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">OPENCV_ENABLE_NONFREE</code>&nbsp; option set to <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">ON</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">ON</code>&nbsp;.</p>
<p>If you are encountering an error related to OpenCV’s non-free and contrib modules, make sure you refer to my <a href="https://pyimagesearch.com/opencv-tutorials-resources-guides/" target="_blank" rel="noopener noreferrer">OpenCV install guides</a>&nbsp;to ensure you have the full install of OpenCV.</p>
<p><em><strong>Note:</strong> Please note that I cannot help debug your own OpenCV install if you did not follow one of my install guides so please make sure you’re using my <a href="https://pyimagesearch.com/opencv-tutorials-resources-guides/" target="_blank" rel="noopener noreferrer">OpenCV install guides</a>&nbsp;when configuring your system.</em></p>
<div id="pitch" style="padding: 40px; width: 100%; background-color: #F4F6FA;">
	<h3>What's next? I recommend <a target="_blank" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&amp;utm_medium=bottomBanner&amp;utm_campaign=What%27s%20next%3F%20I%20recommend">PyImageSearch University</a>.</h3>

	<div class="wistia_responsive_padding" style="padding:56.25% 0 0 0;position:relative;"><div class="wistia_responsive_wrapper" style="height:100%;left:0;position:absolute;top:0;width:100%;"><div class="wistia_video_foam_dummy" data-source-container-id="wistia-kno0cmko2z-1" style="border: 0px; display: block; height: 0px; margin: 0px; padding: 0px; position: static; visibility: hidden; width: auto;"></div><div class="wistia_embed wistia_async_kno0cmko2z videoFoam=true wistia_embed_initialized" style="height: 349px; position: relative; width: 622px;" id="wistia-kno0cmko2z-1"><div class="wistia_swatch" style="height: 100%; left: 0px; opacity: 1; overflow: hidden; position: absolute; top: 0px; transition: opacity 200ms ease 0s; width: 100%;"><img src="./Image Stitching with OpenCV and Python - PyImageSearch_files/swatch" style="filter:blur(5px);height:100%;object-fit:contain;width:100%;" alt="" aria-hidden="true" onload="this.parentNode.style.opacity=1;" data-lazy-src="https://fast.wistia.com/embed/medias/kno0cmko2z/swatch" data-ll-status="loaded" class="entered lazyloaded"><noscript><img src="https://fast.wistia.com/embed/medias/kno0cmko2z/swatch" style="filter:blur(5px);height:100%;object-fit:contain;width:100%;" alt="" aria-hidden="true" onload="this.parentNode.style.opacity=1;" /></noscript></div><div id="wistia_chrome_37" class="w-chrome" tabindex="-1" style="display: inline-block; height: 349px; line-height: normal; margin: 0px; padding: 0px; position: relative; vertical-align: top; width: 622px; zoom: 1; outline: none; overflow: hidden; box-sizing: content-box;"><div id="wistia_grid_46_wrapper" style="display: block; width: 622px; height: 349px;"><div id="wistia_grid_46_above" style="height: 0px; font-size: 0px; line-height: 0px;"> </div><div id="wistia_grid_46_main" style="width: 622px; left: 0px; height: 349px; margin-top: 0px;"><div id="wistia_grid_46_behind"></div><div id="wistia_grid_46_center" style="width: 100%; height: 100%;"><div class="w-video-wrapper w-css-reset" style="height: 100%; position: absolute; top: 0px; width: 100%; opacity: 1; background-color: rgb(0, 0, 0);"><video id="wistia_simple_video_127" crossorigin="anonymous" poster="https://fast.wistia.net/assets/images/blank.gif" aria-label="Video" src="https://embed-fastly.wistia.com/deliveries/b03c3cd4a5cad34b6596ce95b85891f80b1852f3/file.mp4" controlslist="nodownload" playsinline="" preload="none" type="video/mp4" x-webkit-airplay="allow" style="background: transparent; display: block; height: 100%; max-height: none; max-width: none; position: static; visibility: visible; width: 100%; object-fit: fill;"><source src="https://embed-fastly.wistia.com/deliveries/b03c3cd4a5cad34b6596ce95b85891f80b1852f3/file.mp4" type="video/mp4"></video></div><div class="w-ui-container" style="height: 100%; left: 0px; position: absolute; top: 0px; width: 100%; opacity: 1;"><div class="w-vulcan-v2 w-css-reset" id="w-vulcan-v2-45" style="box-sizing: border-box; cursor: default; height: 100%; left: 0px; position: absolute; visibility: visible; top: 0px; width: 100%;"><div class="w-vulcan--background w-css-reset" style="height: 100%; left: 0px; position: absolute; top: 0px; width: 100%;"><div class="w-css-reset" data-handle="statusBar"></div><div class="w-css-reset" data-handle="backgroundFocus"><button aria-label="Play Video" class="w-css-reset w-vulcan-v2-button" tabindex="0" style="width: 0px; height: 0px; pointer-events: none;"></button></div><div class="w-css-reset" data-handle="thumbnail"><div><div class="w-css-reset" style="filter: blur(5px); height: 100%; left: 0px; position: absolute; top: 0px; width: 100%; display: block;"><img class="w-css-reset" srcset="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/swatch(1)" alt="Video Thumbnail" aria-hidden="true" style="height: 349px; left: 0px; position: absolute; top: 0px; width: 622px; clip: auto; display: block; border-width: 0px; border-style: solid; border-color: rgb(0, 0, 0); box-sizing: content-box;"></div><div class="w-css-reset" style="height: 100%; left: 0px; opacity: 1; position: absolute; top: 0px; width: 100%; display: block; transition: opacity 3s ease 0s;"><img class="w-css-reset" srcset="https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=640x360 320w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=640x360 640w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=960x540 960w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=1280x720 1280w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=1920x1080 1920w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=1920x1080 3840w" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/4bda0a1602c8b4d96d63a02617f3069e.webp" alt="Video Thumbnail" style="height: 349px; left: 0px; position: absolute; top: 0px; width: 622px; clip: auto; display: block; border-width: 0px; border-style: solid; border-color: rgb(0, 0, 0); box-sizing: content-box;"></div></div></div></div><div aria-live="polite" class="w-vulcan--aria-live w-css-reset" aria-atomic="true" style="position: absolute; left: -99999em;"></div><div class="w-vulcan-overlays-table w-css-reset" style="display: table; pointer-events: none; position: absolute; width: 100%;"><div class="w-vulcan-overlays--left w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 0px;"><div class="w-css-reset" style="height: 316px;"></div></div><div class="w-vulcan-overlays--center w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 100%;"><div class="w-css-reset" style="height: 316px;"><div class="w-css-reset" data-handle="bigPlayButton" style="pointer-events: auto;"><div class="w-bpb-wrapper w-css-reset w-css-reset-tree" style="display: block; left: calc(50%); margin-left: -60.7422px; margin-top: -38.875px; position: absolute; top: calc(50%);"><button class="w-big-play-button w-css-reset-button-important w-vulcan-v2-button" aria-label="Play Video: Pyimagesearch_Sales_page w/out Autoplay" style="cursor: pointer; height: 77.75px; box-shadow: none; width: 121.484px;"><div style="background: rgb(30, 113, 231); display: block; left: 0px; height: 77.75px; mix-blend-mode: darken; position: absolute; top: 0px; width: 121.484px;"></div><div style="background-color: rgba(30, 113, 231, 0.7); height: 77.75px; left: 0px; position: absolute; top: 0px; transition: background-color 150ms ease 0s; width: 121.484px;"></div><svg x="0px" y="0px" viewBox="0 0 125 80" enable-background="new 0 0 125 80" focusable="false" alt="" style="fill: rgb(255, 255, 255); height: 77.75px; left: 0px; stroke-width: 0px; top: 0px; width: 100%; position: absolute;"><rect fill-rule="evenodd" clip-rule="evenodd" fill="none" width="125" height="80"></rect><polygon fill-rule="evenodd" clip-rule="evenodd" fill="#FFFFFF" points="53,22 53,58 79,40"></polygon></svg></button></div></div><div class="w-css-reset" data-handle="clickForSoundButton" style="pointer-events: auto;"><div class="w-css-reset w-css-reset-tree" data-handle="click-for-sound-backdrop" style="display: none; height: 100%; left: 0px; pointer-events: auto; position: absolute; top: 0px; width: 100%;"><button aria-label="Click for sound" class="w-vulcan-v2-button" style="background: rgba(0, 0, 0, 0.8); border: 2px solid transparent; border-radius: 50%; cursor: pointer; height: 51.0234px; width: 51.0234px; line-height: 51.0234px; outline: none; pointer-events: auto; position: absolute; right: 19.8672px; text-align: left; top: 19.8672px;"><svg viewBox="0 0 237 237"><style>
      @keyframes VOLUME_SMALL_WAVE_FLASH {
          0% { opacity: 0; }
         33% { opacity: 1; }
         66% { opacity: 1; }
        100% { opacity: 0; }
      }

      @keyframes VOLUME_LARGE_WAVE_FLASH {
          0% { opacity: 0; }
         33% { opacity: 1; }
         66% { opacity: 1; }
        100% { opacity: 0; }
      }

      .volume__small-wave {
        animation: VOLUME_SMALL_WAVE_FLASH 2s infinite;
        opacity: 0;
      }

      .volume__large-wave {
        animation: VOLUME_LARGE_WAVE_FLASH 2s infinite .3s;
        opacity: 0;
      }
    </style><polygon fill="white" points="88 107 65 107 65 131 89 131 112 154 112 84"></polygon><g fill="none" stroke="white" stroke-width="10" stroke-linecap="round"><path class="volume__small-wave" d="M 142 86 C 151 107 151 130 142 151"></path><path class="volume__large-wave" d="M 165 74 C 178 97 178 140 165 163"></path></g></svg></button></div></div><div class="w-css-reset" data-handle="playPauseNotifier" style="pointer-events: auto;"></div><div class="w-css-reset" data-handle="playPauseLoading" style="pointer-events: auto;"><div class="w-css-reset w-css-reset-tree" style="height: 100%; left: 0px; pointer-events: none; position: absolute; top: 0px; width: 100%;"><button aria-label="Play Video" class="w-vulcan-v2-button" style="background: rgba(0, 0, 0, 0.6); border: 0px; border-radius: 50%; cursor: pointer; display: none; height: 136.062px; left: 50%; margin: 0px; padding: 0px; pointer-events: auto; position: absolute; opacity: 0; outline: none; top: 50%; transform: translate(-50%, -50%) scale(0.8); transition: opacity 200ms ease 0s, transform 600ms ease 0s; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); width: 136.062px;"><div style="box-sizing: border-box; height: 100%; padding: 45.9211px 45.9211px 45.9211px 56.1258px;"><div style="height: 100%; width: 100%;"><div style="display: none; height: 100%; width: 100%;"><svg x="0px" y="0px" viewBox="0 0 11.556 16" enable-background="new 0 0 11.556 16" class="w-css-reset w-css-reset-tree" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><g><rect x="0" y="0" width="3.5" height="12"></rect><rect x="6.5" y="0" width="3.5" height="12"></rect></g></svg></div><div style="display: block; height: 100%; width: 100%;"><svg x="0px" y="0px" viewBox="0 0 11.556 16" enable-background="new 0 0 11.556 16" class="w-css-reset w-css-reset-tree" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><polygon points="11.556,7.5 0,15 0,0"></polygon></svg></div></div></div></button></div></div></div></div><div class="w-vulcan-overlays--right w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 0px;"><div class="w-css-reset" style="height: 316px;"></div></div></div><div class="w-bottom-bar w-css-reset" style="bottom: 0px; border-collapse: collapse; display: table; height: 33px; pointer-events: none; position: absolute; right: 0px; table-layout: auto; width: 100%;"><div class="w-bottom-bar-lower w-css-reset" style="position: relative;"><div style="height: 100%; left: 0px; position: absolute; top: 0px; width: 100%;"><div style="background: rgb(30, 113, 231); display: none; height: 100%; mix-blend-mode: darken; left: 0px; opacity: 1; position: absolute; top: 0px; transition: opacity 0s ease 0s; width: 100%;"></div><div style="background: rgba(30, 113, 231, 0.85); height: 100%; opacity: 1; left: 0px; position: absolute; top: 0px; transition: opacity 0s ease 0s; width: 100%;"></div></div><div style="display: none;"><div style="background: rgb(30, 113, 231); display: none; height: 100%; mix-blend-mode: darken; left: 0px; opacity: 1; position: absolute; top: 0px; transition: opacity 0s ease 0s; width: 100%;"></div><div style="background: rgba(30, 113, 231, 0.85); height: 100%; opacity: 1; left: 0px; position: absolute; top: 0px; transition: opacity 0s ease 0s; width: 100%;"></div></div><div class="w-bottom-bar-left w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 0px; opacity: 1; transition: opacity 0s ease 0s;"><div class="w-bottom-bar-left-inner w-css-reset" style="height: 33px; position: relative; pointer-events: auto; white-space: nowrap;"><div class="w-css-reset" data-handle="smallPlayButton" style="display: inline-block; vertical-align: top;"><div class="w-vulcan-button-wrapper w-css-reset" style="display: inline-block; height: 33px; position: relative; vertical-align: top; width: 38.875px;"><button tagname="button" class="w-vulcan-v2-button w-css-reset w-css-reset-tree w-css-reset-button-important" aria-label="Play Video" title="Play Video" style="background-color: rgba(0, 0, 0, 0); box-shadow: none; cursor: pointer; height: 100%; position: relative; transition: background-color 150ms ease 0s; width: 100%;"><div class="w-vulcan-icon-wrapper" data-handle="smallPlayButton" style="box-sizing: border-box; height: 100%; position: relative; transform: scale(1.001); transition: transform 200ms ease 0s;"><div style="box-sizing: border-box; height: 100%; margin-left: 0.971875px; padding: 9.71875px 0px 8.74688px; position: relative; width: 100%;"><div style="height: 100%; width: 100%;"><div style="display: none; height: 100%; width: 100%;"><svg x="0px" y="0px" viewBox="0 0 11.556 16" enable-background="new 0 0 11.556 16" focusable="false" class="w-css-reset w-css-reset-tree" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%; vertical-align: top;"><g><rect x="0" y="0" width="3.5" height="12"></rect><rect x="6.5" y="0" width="3.5" height="12"></rect></g></svg></div><div style="display: block; height: 100%; width: 100%;"><svg x="0px" y="0px" viewBox="0 0 11.556 16" enable-background="new 0 0 11.556 16" focusable="false" class="w-css-reset w-css-reset-tree" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%; vertical-align: top;"><polygon points="11.556,7.5 0,15 0,0"></polygon></svg></div></div></div></div></button></div></div></div></div><div class="w-bottom-bar-middle w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 100%; opacity: 1; transition: opacity 0s ease 0s;"><div class="w-bottom-bar-middle-inner w-css-reset" style="height: 33px; position: relative; pointer-events: auto; white-space: nowrap; opacity: 1; transform: translateY(0px); transition: opacity 0ms ease 0s, transform 0ms ease 0s;"><div class="w-css-reset" data-handle="playbar" style="height: 100%; position: relative;"><div class="w-playbar-wrapper w-css-reset w-css-reset-tree" style="display: flex; height: 100%; width: 100%;"><div class="w-playbar__time" style="box-sizing: content-box; color: white; font-family: WistiaPlayerInterNumbersSemiBold, Helvetica, sans-serif; font-size: 12.6344px; letter-spacing: 0.485938px; line-height: 33px; padding-left: 4.85938px; pointer-events: none; position: relative; text-align: center; width: 27.2125px;">3:52</div><div aria-label="Playbar" aria-orientation="horizontal" aria-valuemax="231.5" aria-valuemin="0" aria-valuenow="0" aria-valuetext="0:00" role="slider" tabindex="0" style="cursor: pointer; flex: 1 1 0%; height: 33px; outline: none; margin-left: 14.5781px; margin-right: 9.71875px; position: relative;"><canvas height="41" width="543" style="height: 33px; left: -14.5781px; position: absolute; top: 0px; width: 434.428px;"></canvas><div style="border-radius: 50%; height: 10.885px; left: -5.4425px; opacity: 0; position: absolute; top: 11.0575px; width: 10.885px;"></div></div></div></div></div></div><div class="w-bottom-bar-right w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 0px; opacity: 1; transition: opacity 0s ease 0s; white-space: nowrap;"><div class="w-bottom-bar-right-inner-anchor w-css-reset" style="height: 33px; position: relative; pointer-events: auto; white-space: nowrap; display: inline-block; right: 0px; top: 0px; vertical-align: top;"><div class="w-bottom-bar-right-inner w-css-reset" style="height: 33px; position: relative; pointer-events: auto; white-space: nowrap; display: inline-block; opacity: 1; right: 0px; top: 0px; transform: translateY(0px); transition: opacity 0ms ease 0s, transform 0ms ease 0s;"><div class="w-css-reset" data-handle="volumeButton" style="display: inline-block; vertical-align: top;"><div class="w-vulcan-button-wrapper w-css-reset" style="display: inline-block; height: 33px; position: relative; vertical-align: top; width: 38.875px;"><button tagname="button" class="w-vulcan-v2-button w-css-reset w-css-reset-tree w-css-reset-button-important" aria-label="Mute" title="Mute" style="background-color: rgba(0, 0, 0, 0); box-shadow: none; cursor: pointer; height: 100%; position: relative; transition: background-color 150ms ease 0s; width: 100%;"><div class="w-vulcan-icon-wrapper" data-handle="volumeButton" style="box-sizing: border-box; height: 100%; position: relative; transform: scale(1.001); transition: transform 200ms ease 0s;"><svg x="0px" y="0px" viewBox="0 0 40 34" enable-background="new 0 0 40 34" focusable="false" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><g style="transform: translateX(1.25px); transition: transform 100ms ease 0s;"><g><path d="M13.8,14.2c-0.5,0.5-1.4,0.8-2,0.8h-1.6C9.5,15,9,15.5,9,16.2v1.6c0,0.7,0.5,1.2,1.2,1.2h1.6c0.7,0,1.6,0.4,2,0.8l2.3,2.3c0.5,0.5,0.8,0.3,0.8-0.4v-9.6c0-0.7-0.4-0.8-0.8-0.4L13.8,14.2z"></path></g><g><path fill="none" stroke="#ffffff" stroke-line-cap="round" stroke-miterlimit="10" stroke-width="2" d="M22,11.7c0,0,1.1,2.5,1.1,5s-1.1,5-1.1,5" style="opacity: 1; transition: opacity 100ms ease 0s;"></path><path fill="none" stroke="#ffffff" stroke-line-cap="round" stroke-miterlimit="10" stroke-width="2" d="M25.8,9.2c0,0,1.7,3.8,1.7,7.5c0,3.7-1.7,7.5-1.7,7.5" style="opacity: 1; transition: opacity 100ms ease 0s;"></path></g><g style="opacity: 0; transition: opacity 100ms ease 0s;"><line fill="none" stroke="#ffffff" stroke-line-cap="round" stroke-miterlimit="10" stroke-width="1.8102" x1="19.2" y1="15" x2="23.2" y2="19"></line><line fill="none" stroke="#ffffff" stroke-line-cap="round" stroke-miterlimit="10" stroke-width="1.8102" x1="19.2" y1="19" x2="23.2" y2="15"></line></g></g></svg></div></button></div></div><div class="w-css-reset" data-handle="settingsButton" style="display: inline-block; vertical-align: top;"><div class="w-vulcan-button-wrapper w-css-reset" style="display: inline-block; height: 33px; position: relative; vertical-align: top; width: 38.875px;"><button tagname="button" class="w-vulcan-v2-button w-css-reset w-css-reset-tree w-css-reset-button-important" aria-expanded="false" aria-label="Show settings menu" title="Show settings menu" style="background-color: rgba(0, 0, 0, 0); box-shadow: none; cursor: pointer; height: 100%; position: relative; transition: background-color 150ms ease 0s; width: 100%;"><div class="w-vulcan-icon-wrapper" data-handle="settingsButton" style="box-sizing: border-box; height: 100%; position: relative; transform: scale(1.001); transition: transform 200ms ease 0s;"><svg x="0px" y="0px" viewBox="0 0 40 34" enable-background="new 0 0 40 34" focusable="false" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><g><g><path d="M28.3,16.4h-1.9c-0.4,0-0.8-0.3-0.9-0.7l-0.4-1.1c-0.2-0.3-0.1-0.8,0.2-1.1l1.3-1.3c0.3-0.3,0.3-0.7,0-1l-0.4-0.4c-0.3-0.3-0.7-0.3-1,0l-1.3,1.3c-0.3,0.3-0.8,0.3-1.1,0.1l-1.1-0.5c-0.4-0.1-0.7-0.5-0.7-0.9V9.1c0-0.4-0.3-0.7-0.7-0.7h-0.6c-0.4,0-0.7,0.3-0.7,0.7v1.7c0,0.4-0.3,0.8-0.7,0.9l-1.2,0.5c-0.3,0.2-0.8,0.1-1.1-0.2l-1.2-1.2c-0.3-0.3-0.7-0.3-1,0l-0.4,0.4c-0.3,0.3-0.3,0.7,0,1l1.2,1.2c0.3,0.3,0.3,0.8,0.1,1.1l-0.5,1.2c-0.1,0.4-0.5,0.7-0.9,0.7h-1.6c-0.4,0-0.7,0.3-0.7,0.7v0.6c0,0.4,0.3,0.7,0.7,0.7h1.6c0.4,0,0.8,0.3,0.9,0.7l0.5,1.2c0.2,0.3,0.1,0.8-0.1,1.1l-1.2,1.2c-0.3,0.3-0.3,0.7,0,1l0.4,0.4c0.3,0.3,0.7,0.3,1,0l1.2-1.2c0.3-0.3,0.8-0.3,1.1-0.2l1.2,0.5c0.4,0.1,0.7,0.5,0.7,0.9v1.7c0,0.4,0.3,0.7,0.7,0.7h0.6c0.4,0,0.7-0.3,0.7-0.7V24c0-0.4,0.3-0.8,0.7-0.9l1.1-0.5c0.3-0.2,0.8-0.1,1.1,0.1l1.3,1.3c0.3,0.3,0.7,0.3,1,0l0.4-0.4c0.3-0.3,0.3-0.7,0-1l-1.3-1.3C25,21,25,20.5,25.1,20.2l0.4-1.1c0.1-0.4,0.5-0.7,0.9-0.7h1.9c0.4,0,0.7-0.3,0.7-0.7v-0.6C29,16.7,28.7,16.4,28.3,16.4z M23.8,17.5c0,2.2-1.8,3.9-3.9,3.9c-2.2,0-3.9-1.8-3.9-3.9s1.7-3.9,3.9-3.9C22.1,13.6,23.8,15.3,23.8,17.5z"></path></g></g></svg></div></button></div></div><div class="w-css-reset" data-handle="fullscreenButton" style="display: inline-block; vertical-align: top;"><div class="w-vulcan-button-wrapper w-css-reset" style="display: inline-block; height: 33px; position: relative; vertical-align: top; width: 38.875px;"><button tagname="button" class="w-vulcan-v2-button w-css-reset w-css-reset-tree w-css-reset-button-important" aria-label="Fullscreen" title="Fullscreen" style="background-color: rgba(0, 0, 0, 0); box-shadow: none; cursor: pointer; height: 100%; position: relative; transition: background-color 150ms ease 0s; width: 100%;"><div class="w-vulcan-icon-wrapper" data-handle="fullscreenButton" style="box-sizing: border-box; height: 100%; position: relative; transform: scale(1.001); transition: transform 200ms ease 0s;"><svg x="0px" y="0px" viewBox="0 0 40 34" enable-background="new 0 0 40 34" focusable="false" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><g><g><polyline fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" points="31.4,12.6 31.4,8.7 25.8,8.7"></polyline><polyline fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" points="14.7,8.7 9.1,8.7 9.1,12.6"></polyline><polyline fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" points="25.8,24.8 31.4,24.8 31.4,20.9"></polyline><polyline fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" points="9.1,20.9 9.1,24.8 14.7,24.8"></polyline></g><rect x="13.7" y="12.3" fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" enable-background="new" width="13.3" height="8.9"></rect></g></svg></div></button></div></div></div></div><div class="w-ellipsis w-css-reset" style="height: 33px; position: relative; pointer-events: auto; white-space: nowrap; display: none;"></div></div></div></div><div class="w-foreground w-css-reset" style="height: 100%; left: 0px; pointer-events: none; position: absolute; top: 0px; width: 100%;"><div class="w-css-reset" data-handle="contextMenu" style="pointer-events: auto;"></div><div class="w-css-reset" data-handle="loadingHourglass" style="pointer-events: auto;"></div><div class="w-css-reset" data-handle="focusOutline" style="pointer-events: auto;"><div class="w-focus-outline" style="box-shadow: rgb(255, 255, 255) 0px 0px 0px 2px inset; display: none; height: 100%; left: 0px; pointer-events: none; position: absolute; right: 0px; width: 100%;"></div></div></div></div><style id="wistia_52_style" type="text/css" class="wistia_injected_style">
      #wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset{font-size:14px;}
#wistia_chrome_37 #wistia_grid_46_wrapper div.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper span.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper ul.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper li.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper label.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper fieldset.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper button.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper img.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper a.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper svg.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper p.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper a.w-css-reset{border:0;}
#wistia_chrome_37 #wistia_grid_46_wrapper h1.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:2em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper h2.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:1.5em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper h3.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:1.17em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper p.w-css-reset{margin:1.4em 0;}
#wistia_chrome_37 #wistia_grid_46_wrapper a.w-css-reset{display:inline;}
#wistia_chrome_37 #wistia_grid_46_wrapper span.w-css-reset{display:inline;}
#wistia_chrome_37 #wistia_grid_46_wrapper svg.w-css-reset{display:inline;}
#wistia_chrome_37 #wistia_grid_46_wrapper ul.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_46_wrapper ol.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_46_wrapper li.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_46_wrapper ul:before.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper ol:before.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper li:before.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper ul:after.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper ol:after.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper li:after.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper label.w-css-reset{background-attachment:scroll;background-color:transparent;background-image:none;background-position:0 0;background-repeat:no-repeat;background-size:100% 100%;float:none;outline:none}
#wistia_chrome_37 #wistia_grid_46_wrapper button.w-css-reset{background-attachment:scroll;background-color:transparent;background-image:none;background-position:0 0;background-repeat:no-repeat;background-size:100% 100%;border:0;border-radius:0;outline:none;position:static}
#wistia_chrome_37 #wistia_grid_46_wrapper img.w-css-reset{border:0;display:inline-block;vertical-align:top;border-radius:0;outline:none;position:static}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset button::-moz-focus-inner{border: 0;}
      #wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree {font-size:14px;}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree div{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree span{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ul{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree li{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree label{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree fieldset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree button{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree img{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree a{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree svg{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree p{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree a{border:0;}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree h1{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:2em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree h2{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:1.5em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree h3{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:1.17em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree p{margin:1.4em 0;}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree a{display:inline;}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree span{display:inline;}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree svg{display:inline;}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ul{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ol{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree li{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ul:before{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ol:before{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree li:before{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ul:after{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ol:after{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree li:after{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree label{background-attachment:scroll;background-color:transparent;background-image:none;background-position:0 0;background-repeat:no-repeat;background-size:100% 100%;float:none;outline:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree button{background-attachment:scroll;background-color:transparent;background-image:none;background-position:0 0;background-repeat:no-repeat;background-size:100% 100%;border:0;border-radius:0;outline:none;position:static}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree img{border:0;display:inline-block;vertical-align:top;border-radius:0;outline:none;position:static}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree  button::-moz-focus-inner{border: 0;}
      #wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-max-width-none-important{max-width:none!important}
      #wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-button-important{border-radius:0!important;color:#fff!important;}
    </style></div></div><div id="wistia_grid_46_front"></div><div id="wistia_grid_46_top_inside"><div id="wistia_grid_46_top" style="height: 0px; font-size: 0px; line-height: 0px;"> </div></div><div id="wistia_grid_46_bottom_inside"><div id="wistia_grid_46_bottom" style="height: 0px; font-size: 0px; line-height: 0px;"> </div></div><div id="wistia_grid_46_left_inside"><div id="wistia_grid_46_left" style="height: 0px; font-size: 0px; line-height: 0px;"> </div></div><div id="wistia_grid_46_right_inside"><div id="wistia_grid_46_right" style="height: 0px; font-size: 0px; line-height: 0px;"> </div></div></div><div id="wistia_grid_46_below" style="height: 0px; font-size: 0px; line-height: 0px;"> </div><style id="wistia_47_style" type="text/css" class="wistia_injected_style">#wistia_grid_46_wrapper{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;font-family:Arial,sans-serif;font-size:14px;height:100%;position:relative;text-align:left;width:100%;}
#wistia_grid_46_wrapper *{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;}
#wistia_grid_46_above{position:relative;}
#wistia_grid_46_main{display:block;height:100%;position:relative;}
#wistia_grid_46_behind{height:100%;left:0;position:absolute;top:0;width:100%;}
#wistia_grid_46_center{height:100%;overflow:hidden;position:relative;width:100%;}
#wistia_grid_46_front{display:none;height:100%;left:0;position:absolute;top:0;width:100%;}
#wistia_grid_46_top_inside{position:absolute;left:0;top:0;width:100%;}
#wistia_grid_46_top{width:100%;position:absolute;bottom:0;left:0;}
#wistia_grid_46_bottom_inside{position:absolute;left:0;bottom:0;width:100%;}
#wistia_grid_46_bottom{width:100%;position:absolute;top:0;left:0;}
#wistia_grid_46_left_inside{height:100%;position:absolute;left:0;top:0;}
#wistia_grid_46_left{height:100%;position:absolute;right:0;top:0;}
#wistia_grid_46_right_inside{height:100%;right:0;position:absolute;top:0;}
#wistia_grid_46_right{height:100%;left:0;position:absolute;top:0;}
#wistia_grid_46_below{position:relative;}</style></div></div></div></div></div>

	<div style="margin-top: 32px; margin-bottom: 32px; ">
		<strong>Course information:</strong><br>
		53+ total classes • 57+ hours of on-demand code walkthrough videos • Last updated: October 2022<br>
		<span style="color: #169FE6;">★★★★★</span> 4.84 (128 Ratings) • 15,800+ Students Enrolled
	</div>

	<p><strong>I strongly believe that if you had the right teacher you could <em>master</em> computer vision and deep learning.</strong></p>

	<p>Do you think learning computer vision and deep learning has to be time-consuming, overwhelming, and complicated? Or has to involve complex mathematics and equations? Or requires a degree in computer science?</p>

	<p>That’s <em>not</em> the case.</p>

	<p>All you need to master computer vision and deep learning is for someone to explain things to you in <em>simple, intuitive</em> terms. <em>And that’s exactly what I do</em>. My mission is to change education and how complex Artificial Intelligence topics are taught.</p>

	<p>If you're serious about learning computer vision, your next stop should be PyImageSearch University, the most comprehensive computer vision, deep learning, and OpenCV course online today. Here you’ll learn how to <em>successfully</em> and <em>confidently</em> apply computer vision to your work, research, and projects. Join me in computer vision mastery.</p>

	<p><strong>Inside PyImageSearch University you'll find:</strong></p>

	<ul style="margin-left: 0px;">
		<li style="list-style: none;">✓ <strong>53+ courses</strong> on essential computer vision, deep learning, and OpenCV topics</li>
		<li style="list-style: none;">✓ <strong>53+ Certificates</strong> of Completion</li>
		<li style="list-style: none;">✓ <strong>57+ hours</strong> of on-demand video</li>
		<li style="list-style: none;">✓ <strong>Brand new courses released <em>regularly</em></strong>, ensuring you can keep up with state-of-the-art techniques</li>
		<li style="list-style: none;">✓ <strong>Pre-configured Jupyter Notebooks in Google Colab</strong></li>
		<li style="list-style: none;">✓ Run all code examples in your web browser — works on Windows, macOS, and Linux (no dev environment configuration required!)</li>
		<li style="list-style: none;">✓ Access to <strong>centralized code repos for <em>all</em> 450+ tutorials</strong> on PyImageSearch</li>
		<li style="list-style: none;">✓ <strong> Easy one-click downloads</strong> for code, datasets, pre-trained models, etc.</li>
		<li style="list-style: none;">✓ <strong>Access</strong> on mobile, laptop, desktop, etc.</li>
	</ul>

	<p style="text-align: center;">
		<a target="_blank" class="button link" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&amp;utm_medium=bottomBanner&amp;utm_campaign=What%27s%20next%3F%20I%20recommend" style="background-color: #6DC713; border-bottom: none;">Click here to join PyImageSearch University</a>
	</p>
</div>
<h2>Summary</h2>
<p>In today’s tutorial you learned how to perform multiple image stitching using OpenCV and Python.</p>
<p>Using both OpenCV and Python we were able to stitch multiple images together and create panoramic images.</p>
<p>Our output panoramic images were not only <em>accurate</em> in their stitching placement but also <em>aesthetically pleasing</em> as well.</p>
<p>However, one of the biggest drawbacks of using OpenCV’s built-in image stitching class is that it abstracts away much of the internal computation, including the resulting homography matrices themselves.</p>
<p>If you are trying to perform real-time image stitching, <a href="https://pyimagesearch.com/2016/01/25/real-time-panorama-and-image-stitching-with-opencv/" target="_blank" rel="noopener noreferrer">as we did in a previous post</a>, you may find it beneficial to cache the homography matrix and only occasionally perform keypoint detection, feature extraction, and feature matching.</p>
<p>Skipping these steps and using the cached matrix to perform perspective warping can reduce the computational burden of your pipeline and ultimately speed-up the real-time image stitching algorithm, but unfortunately, OpenCV’s <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">cv2.createStitcher</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">cv2.createStitcher</code>&nbsp; Python bindings do not provide us with access to the raw matrices.</p>
<p>If you are interested in learning more about real-time panorama construction, please refer to <a href="https://pyimagesearch.com/2016/01/25/real-time-panorama-and-image-stitching-with-opencv/" target="_blank" rel="noopener noreferrer">my previous post</a>.</p>
<p>I hope you enjoyed today’s tutorial on image stitching!</p>
<p><strong>To download the source code to today’s post, and be notified tutorials are published here on PyImageSearch, <em>just enter your email address in the form below!</em></strong></p>
<div id="download-the-code" class="post-cta-wrap">
<div class="gpd-post-cta">
	<div class="gpd-post-cta-content">
		

			<div class="gpd-post-cta-top">
				<div class="gpd-post-cta-top-image"><img src="./Image Stitching with OpenCV and Python - PyImageSearch_files/cta-source-guide-1.png" alt="" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" class="entered lazyloaded"><noscript><img src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?lossy=1&strip=1&webp=1" alt="" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?lossy=1&strip=1&webp=1 410w,https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?size=126x174&lossy=1&strip=1&webp=1 126w,https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?size=252x348&lossy=1&strip=1&webp=1 252w" sizes="(max-width: 410px) 100vw, 410px" /></noscript></div>
				
				<div class="gpd-post-cta-top-title"><h4>Download the Source Code and FREE 17-page Resource Guide</h4></div>
				<div class="gpd-post-cta-top-desc"><p>Enter your email address below to get a .zip of the code and a <strong>FREE 17-page Resource Guide on Computer Vision, OpenCV, and Deep Learning.</strong> Inside you'll find my hand-picked tutorials, books, courses, and libraries to help you master CV and DL!</p></div>


			</div>

			<div class="gpd-post-cta-bottom">
				<form id="footer-cta-code" class="footer-cta" action="https://www.getdrip.com/forms/4130035/submissions" method="post" target="blank" data-drip-embedded-form="4130035">
					<input name="fields[email]" type="email" value="" placeholder="Your email address" class="form-control">

					<button type="submit">Download the code!</button>

					<div style="display: none;" aria-hidden="true"><label for="website">Website</label><br><input type="text" id="website" name="website" tabindex="-1" autocomplete="false" value=""></div>
				</form>
			</div>


		
	</div>

</div>
</div><!-- RightMessage WP -->
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/"
    dc:identifier="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/"
    dc:title="Image Stitching with OpenCV and Python"
    trackback:ping="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/trackback/" />
</rdf:RDF>-->
</div></article><section class="author-box"><img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c.jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=480&amp;d=mm&amp;r=g 2x" class="avatar avatar-240 photo" height="240" width="240" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=240&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=240&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=480&#038;d=mm&#038;r=g 2x' class='avatar avatar-240 photo' height='240' width='240' /></noscript><h4 class="author-box-title"><strong>About the Author</strong></h4><div class="author-box-content" itemprop="description"><p>Hi there, I’m Adrian Rosebrock, PhD. All too often I see developers, students, and researchers wasting their time, studying the wrong things, and generally struggling to get started with Computer Vision, Deep Learning, and OpenCV. I created this website to show you what I believe is the best possible way to get your start.</p>
</div></section><h2 class="screen-reader-text">Reader Interactions</h2><div class="single-post-nav"><a href="https://pyimagesearch.com/2018/12/10/keras-save-and-load-your-deep-learning-models/"><div class="single-post-nav__previous"><p>Previous Article:</p><h3>Keras – Save and Load Your Deep Learning Models</h3></div></a><a href="https://pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/"><div class="single-post-nav__next"><p>Next Article:</p><h3>How to use Keras fit and fit_generator (a hands-on tutorial)</h3></div></a></div><div class="entry-comments" id="comments"><h3>53 responses to: Image Stitching with OpenCV and Python</h3><ol class="comment-list">
	<li class="comment even thread-even depth-1" id="comment-492701">
	<article id="article-comment-492701">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/fd342a72557a93e528bfb0448b3ed27c.png" data-lazy-srcset="https://secure.gravatar.com/avatar/fd342a72557a93e528bfb0448b3ed27c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/fd342a72557a93e528bfb0448b3ed27c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/fd342a72557a93e528bfb0448b3ed27c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/fd342a72557a93e528bfb0448b3ed27c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Manmohan Bishnoi</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492701">December 17, 2018 at 12:05 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hello Adrian, </p>
<p>Thanks for a great tutorial once again.<br>
Typical steps for panorama creation from multiple images are:</p>
<p>1. Detect Features<br>
2. Compute Descriptors<br>
3. Match features<br>
4. Remove false matches<br>
5. Calculate Homography<br>
6. Stitch images<br>
7. Detect seams<br>
8. Multi-band blend for final panorama<br>
9. Crop for aesthetic final image</p>
<p>I am trying to generate real-time panorama from images taken using burst shots from a mobile camera rotated in horizontal circular direction, similar to most Apps in App store.<br>
But doing all these steps for two adjacent images takes about 10 seconds with OpenCV Stitcher pipeline.</p>
<p>So if I take 32 images at 11.25 degrees apart and try to stitch them in real-time, it is way too slow.<br>
To speed up things I tried doing some tasks in parallel using multi-threading.</p>
<p>Any tips how to speedup this and reduce time for stitching two adjacent images to about 2-4 seconds?</p>
<p>I am trying to generate panorama incrementally by stitching images in sequence.</p>
<p>Thanks</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-492707">
	<article id="article-comment-492707">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492707">December 17, 2018 at 12:45 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Manmohan — I would suggest looking at the GPU functionality I hinted at in the post. That should ideally help you speedup the pipeline but it may require you going down the rabbit hole and playing with the raw C++ code to get it to work (I haven’t been able to).</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment even depth-2" id="comment-492739">
	<article id="article-comment-492739">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/c5e005726033e68d607ebc06671a71f2.png" data-lazy-srcset="https://secure.gravatar.com/avatar/c5e005726033e68d607ebc06671a71f2?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/c5e005726033e68d607ebc06671a71f2?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/c5e005726033e68d607ebc06671a71f2?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/c5e005726033e68d607ebc06671a71f2?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Tim</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492739">December 17, 2018 at 7:44 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Thanks @Manmohan. I was wondering if I could stitch the frames from 3 cameras together a deliver a panoramic video stream. (I currently use a high-res fisheye camera but even with de-warping the image is not ‘right’, and I’d like better resolution for zoom in)</p>
<p>Your comment leads me to believe I’ll never get ~15 frames per sec via stitching.</p>
<p>(I’ve been playing inference accelerators (Movidius) but that is no help here)</p>
<p>@Adrian, thoughts?<br>
My use case is a video of a wilderness; ~165 deg FoV. Boars, deer, mnt lion might be, rarely, anywhere, and when they are I like to zoom in.<br>
Note, the object detection is to alert me when something interesting appears. Also this is  a personal ‘fun’ project so time and resources are scarce.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-3" id="comment-492801">
	<article id="article-comment-492801">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492801">December 18, 2018 at 8:53 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Is your wildlife camera stationary and non-moving? If so, yes, you can absolutely achieve 15+ FPS. <a target="blank" href="https://pyimagesearch.com/2016/01/25/real-time-panorama-and-image-stitching-with-opencv/">This tutorial</a> will show you how. You’ll need to update the code to work with more than two images or hack the OpenCV C++ source to access the raw homography matrix.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even depth-2" id="comment-682399">
	<article id="article-comment-682399">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/eba47229d7500436baa0a482d60385fc.png" data-lazy-srcset="https://secure.gravatar.com/avatar/eba47229d7500436baa0a482d60385fc?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/eba47229d7500436baa0a482d60385fc?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/eba47229d7500436baa0a482d60385fc?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/eba47229d7500436baa0a482d60385fc?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Ramkumar</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-682399">January 28, 2020 at 6:22 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Manmohan,<br>
       i am very impressive about this post. But, i have query regarding image stitching. If we are passing multiple images. It will provide the output stitched image. But, the same way i need to find the missing images while doing stitching operation. If i pass 5 input images, 3 are relevant images so it’s got stitched. I can’t able to find the remaining 2 input images. please help to me.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-3" id="comment-689010">
	<article id="article-comment-689010">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-689010">January 30, 2020 at 8:46 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>That’s now how OpenCV’s stitching algorithm works. All of the images need to be relevant.</p>
<p>If you want to detect which images <em>should not</em> be stitched, you’ll want to manually inspect the keypoint correspondences and ensure they are sufficiently matched. If you are new to keypoints and keypoint matching, I would recommend you read <a target="blank" href="https://pyimagesearch.com/practical-python-opencv/" rel="noopener noreferrer">Practical Python and OpenCV.</a></p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-492711">
	<article id="article-comment-492711">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/dc5542c2ca46e2bc5f11d59b3f5d21ee.png" data-lazy-srcset="https://secure.gravatar.com/avatar/dc5542c2ca46e2bc5f11d59b3f5d21ee?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/dc5542c2ca46e2bc5f11d59b3f5d21ee?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/dc5542c2ca46e2bc5f11d59b3f5d21ee?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/dc5542c2ca46e2bc5f11d59b3f5d21ee?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Cenk</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492711">December 17, 2018 at 1:52 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Many thanks for the detailed demo.</p>
<p>Do you think Cython would help to speed up the stitching process?</p>
<p>Thanks</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-492714">
	<article id="article-comment-492714">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492714">December 17, 2018 at 2:22 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>No, mainly because we’re calling OpenCV’s functions which are C++ compiled functions. There is a small overhead between the Python call and the compiled bindings but that overhead is essentially nothing.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-492763">
	<article id="article-comment-492763">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/0ec86fa8b7a67a923616dd280099f0a5.png" data-lazy-srcset="https://secure.gravatar.com/avatar/0ec86fa8b7a67a923616dd280099f0a5?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/0ec86fa8b7a67a923616dd280099f0a5?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/0ec86fa8b7a67a923616dd280099f0a5?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/0ec86fa8b7a67a923616dd280099f0a5?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Agus Ambarwari</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492763">December 17, 2018 at 11:54 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Thank you Mr. Adrian, I am from Indonesia and interest in computer vision.<br>
Can stitching image use more than two images and not only from right to left? May, from top to bottom.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-492797">
	<article id="article-comment-492797">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492797">December 18, 2018 at 8:49 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Technically yes, but I haven’t tried with this particular implementation. Be sure to give it a try!</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-492773">
	<article id="article-comment-492773">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/3e66b70f5451265b96153bd202bcd492.png" data-lazy-srcset="https://secure.gravatar.com/avatar/3e66b70f5451265b96153bd202bcd492?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/3e66b70f5451265b96153bd202bcd492?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/3e66b70f5451265b96153bd202bcd492?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/3e66b70f5451265b96153bd202bcd492?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Ankit Agrawal</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492773">December 18, 2018 at 4:13 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hello Adrian,</p>
<p>Thank you for you post, this has been a lot of help for me.</p>
<p>Also, I wanted to ask are you coming up with the post for realtime panorama stitching with more than two cameras, precisely 4 cameras?</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-492792">
	<article id="article-comment-492792">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492792">December 18, 2018 at 8:46 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>As I mentioned in the post, the method used here realistically cannot be used for real-time panorama stitching. You would need to hack the OpenCV C++ code to access the homography matrix and only apply new feature matching once every N frames.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment even depth-3" id="comment-492908">
	<article id="article-comment-492908">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/546f42f648816f931d7aeddcfe3bffe2.png" data-lazy-srcset="https://secure.gravatar.com/avatar/546f42f648816f931d7aeddcfe3bffe2?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/546f42f648816f931d7aeddcfe3bffe2?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/546f42f648816f931d7aeddcfe3bffe2?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/546f42f648816f931d7aeddcfe3bffe2?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Younus</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492908">December 19, 2018 at 12:23 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hello Adrian i am also trying to achieve the same as Ankit mentioned, isn’t it possble by combining your this tutorial and real time stitching tutorial by saving cache and applying it to every frame possible? and if not then what are you telling about hacking opencv c++ code can you guide a little about it. Thank you.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-4" id="comment-492979">
	<article id="article-comment-492979">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492979">December 19, 2018 at 1:52 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>No, make sure you re-read this tutorial as I explain why you cannot cache the homography matrix. I personally have not worked with the C++ code. My suggestion was that you would need to do your own research with the code and so if you could hack the code and compile your own bindings that exposes the matrix. It would be a challenging, non-trivial process.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-492949">
	<article id="article-comment-492949">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/5aa13e39877f932326594fc90a0a466f.jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/5aa13e39877f932326594fc90a0a466f?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/5aa13e39877f932326594fc90a0a466f?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/5aa13e39877f932326594fc90a0a466f?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/5aa13e39877f932326594fc90a0a466f?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Rahul Ragesh</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492949">December 19, 2018 at 8:00 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hello Adrian,</p>
<p>I have 3 retinal images which have warped using Homography manually (I couldn’t use the built-in function because image qualities were bad). Now I want to blend these images together. I couldn’t find any opencv python functions for blending. Am I missing something?</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-492970">
	<article id="article-comment-492970">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492970">December 19, 2018 at 1:47 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Are you referring to the specific blending functions used by the algorithm in this post? If so, those functions are abstracted by the C++ API. You should refer to the OpenCV docs and source code for the stitching module.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment even depth-2" id="comment-524663">
	<article id="article-comment-524663">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/01dc7c595021681a931d631a8961f757.jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/01dc7c595021681a931d631a8961f757?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/01dc7c595021681a931d631a8961f757?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/01dc7c595021681a931d631a8961f757?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/01dc7c595021681a931d631a8961f757?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Thomas Paul</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-524663">July 6, 2019 at 3:29 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hello Rahul,</p>
<p>Did you figure out how to do this? I’m facing a similar problem.</p>
<p>Thanks,<br>
Thomas.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-492994">
	<article id="article-comment-492994">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/b2540c2d0c0e73f5603196c99f23bcd2.png" data-lazy-srcset="https://secure.gravatar.com/avatar/b2540c2d0c0e73f5603196c99f23bcd2?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/b2540c2d0c0e73f5603196c99f23bcd2?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/b2540c2d0c0e73f5603196c99f23bcd2?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/b2540c2d0c0e73f5603196c99f23bcd2?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">mjbordalo</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492994">December 19, 2018 at 2:39 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hello, thanks for another great tutorial.<br>
I would like to do a stitching but with a top-view camera.<br>
Like photos taken from a drone and sequentially stritch this photos.<br>
Which steps should i change?<br>
tnhks in advance</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-2" id="comment-493057">
	<article id="article-comment-493057">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-493057">December 20, 2018 at 5:21 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Have you tried using the code as-is? If so, what problems did you run into?</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment odd alt depth-3" id="comment-494634">
	<article id="article-comment-494634">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/b2540c2d0c0e73f5603196c99f23bcd2.png" data-lazy-srcset="https://secure.gravatar.com/avatar/b2540c2d0c0e73f5603196c99f23bcd2?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/b2540c2d0c0e73f5603196c99f23bcd2?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/b2540c2d0c0e73f5603196c99f23bcd2?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/b2540c2d0c0e73f5603196c99f23bcd2?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">mjbordalo</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-494634">January 3, 2019 at 12:14 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>yes. I tried to take a bunch of photos with my phone pointing downward while i was turning around. (so that the last picture would be similiar to the first one)  The output resolt tries to put the images in a landscape mode like all are side by side</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-492998">
	<article id="article-comment-492998">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/6c4a6831ed9765e726c240ff9c80012e.png" data-lazy-srcset="https://secure.gravatar.com/avatar/6c4a6831ed9765e726c240ff9c80012e?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/6c4a6831ed9765e726c240ff9c80012e?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/6c4a6831ed9765e726c240ff9c80012e?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/6c4a6831ed9765e726c240ff9c80012e?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">William Stevenson</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-492998">December 19, 2018 at 3:28 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hello Adrian</p>
<p>I used pip install opencv_contrib_python, which fetched opencv_contrib_python-3.4.4.19-cp37-cp37m-win_amd64.whl for 64 bit python 3.7. It does not show errors during installation. cv2.__version__  shows 3.4.4. Release date is 27 Nov 2018.</p>
<p>Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function ‘cv::xfeatures2d::SURF::create’</p>
<p>I thought that opencv_contrib_modules would contain all the contributed modules, or is this not guaranteed?</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-493055">
	<article id="article-comment-493055">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-493055">December 20, 2018 at 5:20 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>No, the pip install of opencv-contrib-python does not include the NONFREE modules. To enable them you would need to compile OpenCV from source. You should follow one of my <a target="blank" href="https://pyimagesearch.com/opencv-tutorials-resources-guides/">OpenCV install guides</a> to compile from source.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-493005">
	<article id="article-comment-493005">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/d4f46b7d72602165973e62b39e05ca40.png" data-lazy-srcset="https://secure.gravatar.com/avatar/d4f46b7d72602165973e62b39e05ca40?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/d4f46b7d72602165973e62b39e05ca40?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/d4f46b7d72602165973e62b39e05ca40?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/d4f46b7d72602165973e62b39e05ca40?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Hure</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-493005">December 19, 2018 at 7:16 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Can this sample code, perhaps with some parameter change, also be used to do what I’ll call pixel exact stiching? For example stitch together 5 screen captures of parts of a Google map with some overlap between each screen capture (and same zoom level and so on of course) into a larger map image? In other words find vertical or horizontal one pixel thick lines that are identical and join two images at each such seam. If this code won’t do that, do you know of some other opencv commands to use for that?</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-493052">
	<article id="article-comment-493052">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-493052">December 20, 2018 at 5:16 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>That is a pretty specific use case. You can try it and see but I don’t think you’ll be able to obtain that level of accuracy. It’s certainly worth a test though!</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-493089">
	<article id="article-comment-493089">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/3bf1d7f3213d2cd3f40d5e177cd2ef08.png" data-lazy-srcset="https://secure.gravatar.com/avatar/3bf1d7f3213d2cd3f40d5e177cd2ef08?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/3bf1d7f3213d2cd3f40d5e177cd2ef08?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/3bf1d7f3213d2cd3f40d5e177cd2ef08?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/3bf1d7f3213d2cd3f40d5e177cd2ef08?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Sebastian</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-493089">December 20, 2018 at 10:19 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Great tutorial as usual, but I want to use image stitching for commercial use. But the NONFREE OpenCV functions are unfortionally patented. I’d like (my boss) to pay for them, but I’m without a clue where to ask for permission or how to buy a license for commercial usage. Do you by any chance know how I can obtain a license or use it comercially without breaking the law?</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-493883">
	<article id="article-comment-493883">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-493883">December 27, 2018 at 11:07 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>You would want to reach out to the patent holders. You can find them via Google’s patent search.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-495602">
	<article id="article-comment-495602">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/0d0a0b5239b8067ca5ac64952529b7db.png" data-lazy-srcset="https://secure.gravatar.com/avatar/0d0a0b5239b8067ca5ac64952529b7db?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/0d0a0b5239b8067ca5ac64952529b7db?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/0d0a0b5239b8067ca5ac64952529b7db?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/0d0a0b5239b8067ca5ac64952529b7db?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Emilio</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-495602">January 10, 2019 at 12:34 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian,</p>
<p>Great tutorial as always! I was wondering, back in your OpenCV panorama stitching from 2016, you made a stitcher script and you were able to compute matches yourself. Have you found any way to retrieve matches from this method? I would like to store all the matches computed while stitching. </p>
<p>Thanks!</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-495917">
	<article id="article-comment-495917">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-495917">January 11, 2019 at 9:35 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Emilio — could you clarify a bit more what you mean by “retrieve matches from this method”? What specifically are you trying to accomplish?</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-509871">
	<article id="article-comment-509871">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/2ca83fd154bf09ee9f712af32f4ab5f0.png" data-lazy-srcset="https://secure.gravatar.com/avatar/2ca83fd154bf09ee9f712af32f4ab5f0?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/2ca83fd154bf09ee9f712af32f4ab5f0?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/2ca83fd154bf09ee9f712af32f4ab5f0?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/2ca83fd154bf09ee9f712af32f4ab5f0?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Jerry</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-509871">March 29, 2019 at 5:21 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian, Really nice tutorial. I just have one small doubt. I think it may be along the lines of what Emilio was asking. This stitcher_create() method uses SIFT to find key points right? so would it be possible to use ORB method instead of SIFT. </p>
<p>ORB is open source right and according to the Opencv’s documentation page, if combined with FLANN matching supposed to be faster that SIFT + RANSAC. Although i may be wrong about be wrong about the performance, I just wanted to know if ORB + FLANN can be used in this method.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-511029">
	<article id="article-comment-511029">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/0a6ecd8eb870b226f8e50f108637e6e1.png" data-lazy-srcset="https://secure.gravatar.com/avatar/0a6ecd8eb870b226f8e50f108637e6e1?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/0a6ecd8eb870b226f8e50f108637e6e1?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/0a6ecd8eb870b226f8e50f108637e6e1?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/0a6ecd8eb870b226f8e50f108637e6e1?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">chen qu</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-511029">April 4, 2019 at 4:02 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>An excellent article and thank you again !</p>
<p>Another draw-back of this approach I observed is that probably within the stitching algorithm, the input tiles(images) are blurred, so the output of the stitching (image) looses the details from the original input, particularly for those already obscured features in the original images.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-511261">
	<article id="article-comment-511261">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/77a2c5ecbc35f1406717ecbfd6b816d3.png" data-lazy-srcset="https://secure.gravatar.com/avatar/77a2c5ecbc35f1406717ecbfd6b816d3?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/77a2c5ecbc35f1406717ecbfd6b816d3?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/77a2c5ecbc35f1406717ecbfd6b816d3?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/77a2c5ecbc35f1406717ecbfd6b816d3?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Shruti</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-511261">April 5, 2019 at 1:27 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian,</p>
<p>Thanks for the tutorial. It is incredibly helpful. I was wondering if you could help me out with something.</p>
<p>I am trying to use opencv on Python to make a mosaic of images. So far I have been able to make a mosaic from around 20 images. But I am having trouble going beyond that. I get a status code of 3 when I use more than 20-25 images. Do you know if there is a limit on the number/size of images you can merge using opencv.</p>
<p>My images are incredibly large (4000 * 4000 pixels). I have around 100 such images.</p>
<p>Do you have any suggestions for me? Also, is it possible to see the raw opencv code for the createStitcher() and stitch() functions?</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-512956">
	<article id="article-comment-512956">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/849c17b42a33cbd41549ed43901731ba.png" data-lazy-srcset="https://secure.gravatar.com/avatar/849c17b42a33cbd41549ed43901731ba?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/849c17b42a33cbd41549ed43901731ba?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/849c17b42a33cbd41549ed43901731ba?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/849c17b42a33cbd41549ed43901731ba?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Yusuf</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-512956">April 15, 2019 at 12:58 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian, in Image stitching we are finding similarity between two images. so can we use the same concept in background subtraction in scenarios when background frame get slightly changed. So we can find the similar areas and create a new background frame for the new foreground frame. i dont know how to go starting in this direction</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-2" id="comment-513451">
	<article id="article-comment-513451">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-513451">April 18, 2019 at 7:10 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Sorry, I’m not fully understanding this question. You’re using stitching frames and then performing background subtraction/motion detection, correct? I’m not sure how or why the “similar areas” is being used or why they are important.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment odd alt thread-even depth-1" id="comment-513337">
	<article id="article-comment-513337">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/570ad92865b3d9b5479a1a8b1f14c376.png" data-lazy-srcset="https://secure.gravatar.com/avatar/570ad92865b3d9b5479a1a8b1f14c376?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/570ad92865b3d9b5479a1a8b1f14c376?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/570ad92865b3d9b5479a1a8b1f14c376?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/570ad92865b3d9b5479a1a8b1f14c376?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Marcel Jaramillo</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-513337">April 17, 2019 at 6:44 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Thanks for this amazing demo!</p>
<p>I having a problem with the memory, im getting this error:</p>
<p>Traceback (most recent call last):<br>
Failed to allocate 746307632 bytes in function ‘cv::OutOfMemoryError’</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-2" id="comment-513409">
	<article id="article-comment-513409">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-513409">April 18, 2019 at 6:29 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Take a look at your error, it shows you what the problem is: you’re machine ran out of RAM, likely because you are trying to stitch together too many images and/or the images are too large (in terms of resolution). Try resizing your images first.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-513375">
	<article id="article-comment-513375">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/077f38d0d507dabd65d806e4142f485e.png" data-lazy-srcset="https://secure.gravatar.com/avatar/077f38d0d507dabd65d806e4142f485e?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/077f38d0d507dabd65d806e4142f485e?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/077f38d0d507dabd65d806e4142f485e?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/077f38d0d507dabd65d806e4142f485e?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Mohanad</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-513375">April 18, 2019 at 2:50 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hello Adrian,<br>
Is it possible to solve jigsaw puzzle using Python and openCV? The link bellow has some ideas and he already tried but no luck.</p>
<p><a href="https://towardsdatascience.com/solving-jigsaw-puzzles-with-python-and-opencv-d775ba730660" rel="nofollow ugc">https://towardsdatascience.com/solving-jigsaw-puzzles-with-python-and-opencv-d775ba730660</a></p>
<p>Appreciated</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-2" id="comment-513407">
	<article id="article-comment-513407">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-513407">April 18, 2019 at 6:27 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>By my understanding, you could potentially solve the jigsaw problem if the pieces were tiles (i.e., square or rectangular). But if they are actual pieces like a normal jigsaw it would require far too much computation to perform the exhaustive process of shape matching. It’s not really feasible.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment odd alt thread-even depth-1" id="comment-516232">
	<article id="article-comment-516232">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/e90a84a5d0d24198a5e46e4c374efb79.png" data-lazy-srcset="https://secure.gravatar.com/avatar/e90a84a5d0d24198a5e46e4c374efb79?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/e90a84a5d0d24198a5e46e4c374efb79?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/e90a84a5d0d24198a5e46e4c374efb79?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/e90a84a5d0d24198a5e46e4c374efb79?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Verina</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-516232">May 6, 2019 at 10:45 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>can this code be used to make 360 camera ?? and if it can’t , can you give me any tip or tutorial to help me ,please.<br>
I am working on a 360 camera app.<br>
Thanks in advance.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-2" id="comment-516579">
	<article id="article-comment-516579">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-516579">May 8, 2019 at 1:05 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Sorry, I don’t have any code for a full 360 panorama camera.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-517557">
	<article id="article-comment-517557">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/5635d2e56daaef101a74d5fdda2cd2e4.png" data-lazy-srcset="https://secure.gravatar.com/avatar/5635d2e56daaef101a74d5fdda2cd2e4?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/5635d2e56daaef101a74d5fdda2cd2e4?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/5635d2e56daaef101a74d5fdda2cd2e4?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/5635d2e56daaef101a74d5fdda2cd2e4?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">peacherwu</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-517557">May 14, 2019 at 2:43 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>The Lowe’s paper is dated 2007, not 2017.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-2" id="comment-517782">
	<article id="article-comment-517782">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-517782">May 15, 2019 at 2:41 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Whoops, thanks for catching that!</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment odd alt thread-even depth-1" id="comment-520239">
	<article id="article-comment-520239">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/3441d96b137a4fedaeba4cbe88dfc1ba.jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/3441d96b137a4fedaeba4cbe88dfc1ba?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/3441d96b137a4fedaeba4cbe88dfc1ba?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/3441d96b137a4fedaeba4cbe88dfc1ba?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/3441d96b137a4fedaeba4cbe88dfc1ba?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">David</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-520239">May 31, 2019 at 4:58 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian , I am  using opencv 4.1.0 but code is not execute after this line<br>
stitcher = cv2.createStitcher() if imutils.is_cv3() else cv2.Stitcher_create()</p>
<p>then can you tell me where is my problem ?</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-2" id="comment-521054">
	<article id="article-comment-521054">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-521054">June 6, 2019 at 8:43 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>What is the error you are receiving?</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment odd alt depth-3" id="comment-522219">
	<article id="article-comment-522219">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/44a83b3020c3153aad25f7ee9318757b.png" data-lazy-srcset="https://secure.gravatar.com/avatar/44a83b3020c3153aad25f7ee9318757b?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/44a83b3020c3153aad25f7ee9318757b?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/44a83b3020c3153aad25f7ee9318757b?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/44a83b3020c3153aad25f7ee9318757b?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Brad</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-522219">June 18, 2019 at 4:10 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>I am using the same opencv 4.1.0 and receive a “Bus error” after the call to stitcher.stitch(images). The code then stops.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-4" id="comment-522309">
	<article id="article-comment-522309">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-522309">June 19, 2019 at 1:42 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Thanks Brad. I’ll be sure to take a look.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-520867">
	<article id="article-comment-520867">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/fecad878c7dfd4273ebc8fed108afdf1.png" data-lazy-srcset="https://secure.gravatar.com/avatar/fecad878c7dfd4273ebc8fed108afdf1?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/fecad878c7dfd4273ebc8fed108afdf1?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/fecad878c7dfd4273ebc8fed108afdf1?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/fecad878c7dfd4273ebc8fed108afdf1?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Ángel Ortiz</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-520867">June 5, 2019 at 9:20 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>With how many images can this be done? And what if I have an array of images? Meaning that there are not only made from taking pictures from left to right, but also from up and down.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-522988">
	<article id="article-comment-522988">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/d077af24e5ff5c488161fc74b87383e1.png" data-lazy-srcset="https://secure.gravatar.com/avatar/d077af24e5ff5c488161fc74b87383e1?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/d077af24e5ff5c488161fc74b87383e1?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/d077af24e5ff5c488161fc74b87383e1?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/d077af24e5ff5c488161fc74b87383e1?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Abhijit Nathwani</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-522988">June 25, 2019 at 9:10 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian,</p>
<p>Thanks for the wonderful tutorial. I have been a regular reader of pyimagesearch and found most of your stuff useful!</p>
<p>I have a question regarding your hack that you have neatly applied for the border. Is it possible to control the rectangle dimensions? I’m losing some image data due to this. Can we select the rectangle co-ordinates or know the contour dimensions?</p>
<p>Thanks<br>
Abhijit</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-523133">
	<article id="article-comment-523133">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-523133">June 26, 2019 at 1:04 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>What do you mean by selecting the rectangle dimensions? As long as you have the contour itself you can compute the bounding box info via the “cv2.boundingRect” function. If you’d like more information on contours you should refer to <a target="blank" href="https://pyimagesearch.com/practical-python-opencv/">Practical Python and OpenCV.</a></p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-529189">
	<article id="article-comment-529189">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/9c4b53c4b4622b1a872c98d6c612f802.png" data-lazy-srcset="https://secure.gravatar.com/avatar/9c4b53c4b4622b1a872c98d6c612f802?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/9c4b53c4b4622b1a872c98d6c612f802?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/9c4b53c4b4622b1a872c98d6c612f802?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/9c4b53c4b4622b1a872c98d6c612f802?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Koa</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-529189">July 31, 2019 at 8:00 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hello,</p>
<p>I am trying to use this method to stitch together multiple images (6 in total). When I run the stitcher (before all of the panoramic image cleanup), it only stitches together 2 out of the 6 images together. I don’t get any errors. What should I do?</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment odd alt thread-even depth-1" id="comment-572267">
	<article id="article-comment-572267">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/98d3d7132b6eab64335c631343abde67.png" data-lazy-srcset="https://secure.gravatar.com/avatar/98d3d7132b6eab64335c631343abde67?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/98d3d7132b6eab64335c631343abde67?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/98d3d7132b6eab64335c631343abde67?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/98d3d7132b6eab64335c631343abde67?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name"><a href="http://google/" class="comment-author-link" rel="external nofollow">jason0425</a></span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-572267">November 12, 2019 at 12:46 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hello Adrian!</p>
<p>I am trying to use this method to stitch together multiple 5 images. When I run the stitcher together 5 images together. When the image is stitched, black distortion points occur at the overlapping points. what’s the problem…?</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-659088">
	<article id="article-comment-659088">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/d02000af0fc987ed03dd371c3c08f1f5.png" data-lazy-srcset="https://secure.gravatar.com/avatar/d02000af0fc987ed03dd371c3c08f1f5?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/d02000af0fc987ed03dd371c3c08f1f5?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/d02000af0fc987ed03dd371c3c08f1f5?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/d02000af0fc987ed03dd371c3c08f1f5?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Andy</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-659088">January 17, 2020 at 11:27 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian,<br>
Thanks for the tutorial, very simple to follow and very informative.<br>
With my project I am somewhere between this tutorial and the “Real-time panorama and image stitching with Open-CV”, where by I have 3 sources of video with the need to stitch them to a panorama. The OpenCV stitching class does a really good job in generating a smooth pano, is there no way of extracting the homography matrices to be applied to 3 independant videos post recording? Essentially here is my thought process:<br>
1. Capture images from 3 cameras<br>
2. Perform stitch and store homography matrices somewhere<br>
3. Record videos from the 3 cameras<br>
4. Apply panorama homography matrices to videos to generate a single panorama</p>
<p>Any help would be much appreciated, keep up the great work and thanks again!<br>
All the best, Andy</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-671613">
	<article id="article-comment-671613">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-671613">January 23, 2020 at 9:34 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Unfortunately, no. OpenCV does not expose the homography matrix. I wish it did 🙁</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-735855">
	<article id="article-comment-735855">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/ff8f0721868155235559891a068a5e4c.png" data-lazy-srcset="https://secure.gravatar.com/avatar/ff8f0721868155235559891a068a5e4c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/ff8f0721868155235559891a068a5e4c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/ff8f0721868155235559891a068a5e4c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/ff8f0721868155235559891a068a5e4c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name"><a href="https://mxz2013.github.io/online-cv/" class="comment-author-link" rel="external nofollow">Sky_zhou</a></span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#comment-735855">February 17, 2020 at 1:14 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian,</p>
<p>Thank you very much for sharing your experience in computer vision. I am new to CV, and currently training myself following your post. Using your code in this post, I found the “status = 1” after “(status, stitched) = stitcher.stitch(images)” when I want to stitch two images of my own. Could you please tell me how should I solve this problem? Or this is due to the limitation of the cv2.createStitcher() function? Should I change the function that looks for the matches, if yes, how should I do that?</p>
<p>Thank you very much!</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ol></div><div class="comment-policy">  <h3 class="comment-policy__title">Comment section</h3>  <div class="comment-policy__content"><p>Hey, Adrian Rosebrock here, author and creator of PyImageSearch. While I love hearing from readers, a couple years ago I made the tough decision to no longer offer 1:1 help over blog post comments.</p>
<p>At the time I was receiving 200+ emails per day and another 100+ blog post comments. I simply did not have the time to moderate and respond to them all, and the sheer volume of requests was taking a toll on me.</p>
<p>Instead, my goal is to <em>do the most good</em> for the computer vision, deep learning, and OpenCV community at large by focusing my time on authoring high-quality blog posts, tutorials, and books/courses.</p>
<p><strong>If you need help learning computer vision and deep learning, <a href="https://pyimagesearch.com/books-and-courses/" target="_blank" rel="noopener">I suggest you refer to my full catalog of books and courses</a></strong> — they have helped tens of thousands of developers, students, and researchers <em>just like yourself</em> learn Computer Vision, Deep Learning, and OpenCV.</p>
<p><a href="https://pyimagesearch.com/books-and-courses/" target="_blank" rel="noopener">Click here to browse my full catalog.</a></p>
</div></div>
<div id="pyis-cta-modal-sticky-bottom-anchor"></div></main><aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar" id="genesis-sidebar-primary"><h2 class="genesis-sidebar-title screen-reader-text">Primary Sidebar</h2><section id="custom_html-11" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><div class="textwidget custom-html-widget"><section id="custom_html-12" class="widget_text widget widget_custom_html" vwo-el-id="12905566480"><div class="widget_text widget-wrap" vwo-el-id="4379272940"><div class="textwidget custom-html-widget" vwo-el-id="10491450000"><div class="sidebar__block" vwo-el-id="38280549740">
	<h4 class="sidebar__block-title" vwo-el-id="31559285170"><a target="_blank" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&amp;utm_medium=sideBanner&amp;utm_campaign=joinNow" rel="noopener" vwo-el-id="27590303210">PyImageSearch University </a></h4>	
	<a target="_blank" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&amp;utm_medium=sideBanner&amp;utm_campaign=joinNow" rel="noopener" vwo-el-id="42914948080"><img src="./Image Stitching with OpenCV and Python - PyImageSearch_files/pyuni_full_access_plan_small.png" alt="" class="wp-image-11909" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?size=126x95&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?lossy=1&amp;strip=1&amp;webp=1 200w" data-lazy-sizes="(max-width: 200px) 100vw, 200px" no-resize-detection="" vwo-el-id="32333822360" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?lossy=1&amp;strip=1&amp;webp=1"><noscript><img src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?lossy=1&amp;strip=1&amp;webp=1" alt="" class="wp-image-11909" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?size=126x95&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?lossy=1&amp;strip=1&amp;webp=1 200w" sizes="(max-width: 200px) 100vw, 200px" no-resize-detection="" vwo-el-id="32333822360"></noscript></a>	
	<div class="sidebar__block-content" vwo-el-id="4986532880">
		<p style="font-size: 16px;" vwo-el-id="17980791980">
			<strong vwo-el-id="33978259780">Course information:</strong><br vwo-el-id="9360110700"> 			
			53+ total classes • 57+ hours of on demand video • Last updated: October 2022<br vwo-el-id="9360111010">
			<span style="color: #169FE6;" vwo-el-id="24661359750">★★★★★</span><br vwo-el-id="9360111320">
			4.84 (128 Ratings) • 15,800+ Students Enrolled
		</p>
		<p style="text-align: left; font-size: 16px; line-height: 34px;" vwo-el-id="17980792290">
			✓ <strong vwo-el-id="34288457850">53+ courses</strong> on essential computer vision, deep learning, and OpenCV topics<br vwo-el-id="31929219840">
			✓ <strong>53+ Certificates of Completion </strong><br vwo-el-id="31929220150">
			✓ <strong vwo-el-id="34288458160">57+ hours</strong> of on-demand video<br vwo-el-id="31929220460">
			✓ <strong vwo-el-id="34288458470">Brand new courses released <em vwo-el-id="17816517780">every month</em></strong>, ensuring you can keep up with state-of-the-art techniques<br vwo-el-id="31929220770">
			✓ <strong vwo-el-id="34288458780">Pre-configured Jupyter Notebooks in Google Colab</strong><br vwo-el-id="31929221080">
			✓ Run all code examples in your web browser — works on Windows, macOS, and Linux (no dev environment configuration required!)<br vwo-el-id="31929221390">
			✓ Access to <strong vwo-el-id="34288459090">centralized code repos for <em vwo-el-id="20005064960">all</em> 500+ tutorials</strong> on PyImageSearch<br vwo-el-id="31929221700">
			✓ <strong vwo-el-id="34288459400"> Easy one-click downloads</strong> for code, datasets, pre-trained models, etc.<br vwo-el-id="31929222010">
			✓ Access on mobile, laptop, desktop, etc.

		</p> 

	</div>
	<!-- <p style="text-align: center;">
		<a target="_blank" class="button link" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&utm_medium=sideBanner&utm_campaign=joinNow" style="background-color: #169FE6; color: white; border-bottom: none;" rel="noopener">Learn More</a>
	</p> -->

<a target="_blank" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&amp;utm_medium=sideBanner&amp;utm_campaign=joinNow" class="button sidebar__block-button" rel="noopener" vwo-el-id="14332567680">Join Now</a>

</div></div></div></section></div></div></section>
<section id="related-posts-by-taxonomy-2" class="widget related_posts_by_taxonomy"><div class="widget-wrap">
<h3 class="widgettitle widget-title">Picked For You</h3>
<div id="rpbt-related-gallery-1" class="gallery related-gallery related-galleryid-9285 gallery-columns-1 gallery-size-medium"><figure class="gallery-item" role="group" aria-label="Intro to anomaly detection with OpenCV, Computer Vision, and scikit-learn">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2020/01/20/intro-to-anomaly-detection-with-opencv-computer-vision-and-scikit-learn/"><img width="300" height="270" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/intro_anomaly_detection_header-300x270.jpg" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-12048" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/intro_anomaly_detection_header.jpg?size=126x113&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/intro_anomaly_detection_header-300x270.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/intro_anomaly_detection_header.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" data-lazy-sizes="(max-width: 300px) 100vw, 300px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/intro_anomaly_detection_header-300x270.jpg?size=300x300&amp;lossy=1&amp;strip=1&amp;webp=1"><noscript><img width="300" height="270" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/intro_anomaly_detection_header-300x270.jpg?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-12048" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/intro_anomaly_detection_header.jpg?size=126x113&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/intro_anomaly_detection_header-300x270.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/intro_anomaly_detection_header.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-12048">
				<a href="https://pyimagesearch.com/2020/01/20/intro-to-anomaly-detection-with-opencv-computer-vision-and-scikit-learn/">Intro to anomaly detection with OpenCV, Computer Vision, and scikit-learn</a>
				</figcaption></figure><figure class="gallery-item" role="group" aria-label="Multiprocessing with OpenCV and Python">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2019/09/09/multiprocessing-with-opencv-and-python/"><img width="300" height="200" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/multiprocessing_opencv_header-300x200.jpg" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-11015" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2019/09/multiprocessing_opencv_header.jpg?size=126x84&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2019/09/multiprocessing_opencv_header-300x200.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2019/09/multiprocessing_opencv_header.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" data-lazy-sizes="(max-width: 300px) 100vw, 300px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2019/09/multiprocessing_opencv_header-300x200.jpg?size=300x300&amp;lossy=1&amp;strip=1&amp;webp=1"><noscript><img width="300" height="200" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2019/09/multiprocessing_opencv_header-300x200.jpg?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-11015" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2019/09/multiprocessing_opencv_header.jpg?size=126x84&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2019/09/multiprocessing_opencv_header-300x200.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2019/09/multiprocessing_opencv_header.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-11015">
				<a href="https://pyimagesearch.com/2019/09/09/multiprocessing-with-opencv-and-python/">Multiprocessing with OpenCV and Python</a>
				</figcaption></figure><figure class="gallery-item" role="group" aria-label="Real-time panorama and image stitching with OpenCV">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2016/01/25/real-time-panorama-and-image-stitching-with-opencv/"><img width="300" height="188" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/realtime_panorama_stitching_featured-300x188.jpg" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-3588" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/realtime_panorama_stitching_featured.jpg?size=126x79&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/realtime_panorama_stitching_featured-300x188.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/realtime_panorama_stitching_featured.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" data-lazy-sizes="(max-width: 300px) 100vw, 300px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/realtime_panorama_stitching_featured-300x188.jpg?size=300x300&amp;lossy=1&amp;strip=1&amp;webp=1"><noscript><img width="300" height="188" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/realtime_panorama_stitching_featured-300x188.jpg?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-3588" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/realtime_panorama_stitching_featured.jpg?size=126x79&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/realtime_panorama_stitching_featured-300x188.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/realtime_panorama_stitching_featured.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-3588">
				<a href="https://pyimagesearch.com/2016/01/25/real-time-panorama-and-image-stitching-with-opencv/">Real-time panorama and image stitching with OpenCV</a>
				</figcaption></figure><figure class="gallery-item" role="group" aria-label="OpenCV panorama stitching">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2016/01/11/opencv-panorama-stitching/"><img width="300" height="238" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/bryce_result_02-300x238.jpg" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-3548" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/bryce_result_02.jpg?size=126x100&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/bryce_result_02-300x238.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/bryce_result_02-1024x811.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/bryce_result_02.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" data-lazy-sizes="(max-width: 300px) 100vw, 300px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/bryce_result_02-300x238.jpg?size=300x300&amp;lossy=1&amp;strip=1&amp;webp=1"><noscript><img width="300" height="238" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/bryce_result_02-300x238.jpg?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-3548" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/bryce_result_02.jpg?size=126x100&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/bryce_result_02-300x238.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/bryce_result_02-1024x811.jpg?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2016/01/bryce_result_02.jpg?lossy=1&amp;strip=1&amp;webp=1 1080w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-3548">
				<a href="https://pyimagesearch.com/2016/01/11/opencv-panorama-stitching/">OpenCV panorama stitching</a>
				</figcaption></figure><figure class="gallery-item" role="group" aria-label="Local Binary Patterns with Python &amp; OpenCV">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/"><img width="300" height="243" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/lbp_results_montage-300x243.jpg" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-3428" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2015/12/lbp_results_montage.jpg?size=126x102&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2015/12/lbp_results_montage-300x243.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2015/12/lbp_results_montage.jpg?lossy=1&amp;strip=1&amp;webp=1 800w" data-lazy-sizes="(max-width: 300px) 100vw, 300px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2015/12/lbp_results_montage-300x243.jpg?size=300x300&amp;lossy=1&amp;strip=1&amp;webp=1"><noscript><img width="300" height="243" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2015/12/lbp_results_montage-300x243.jpg?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-3428" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2015/12/lbp_results_montage.jpg?size=126x102&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2015/12/lbp_results_montage-300x243.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2015/12/lbp_results_montage.jpg?lossy=1&amp;strip=1&amp;webp=1 800w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-3428">
				<a href="https://pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/">Local Binary Patterns with Python &amp; OpenCV</a>
				</figcaption></figure>
		</div>
</div></section></aside></div></div></div><div class="similar-articles"><div class="wrap"><h3>Similar articles</h3><div class="gpd-simple-card-group"><article class="post-summary"><a href="https://pyimagesearch.com/2021/12/27/torch-hub-series-2-vgg-and-resnet/" class="post-summary--link"><header class="entry-header"><div class="entry-categories"><div class="entry-category">Deep Learning</div><div class="entry-category">PyTorch</div><div class="entry-category">ResNet</div><div class="entry-category">Tutorials</div><div class="entry-category">VGG</div></div><h2 class="entry-title">Torch Hub Series #2: VGG and ResNet</h2><div class="entry-date">December 27, 2021</div></header><p class="entry-content-link"><svg class="svg-icon long-arrow" width="14" height="14" aria-hidden="true" role="img" focusable="false" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.8125 0.1875C6.875 0.125 6.96875 0.09375 7.09375 0.09375C7.1875 0.09375 7.28125 0.125 7.34375 0.1875L13.875 6.75C13.9375 6.8125 14 6.90625 14 7C14 7.125 13.9375 7.1875 13.875 7.25L7.34375 13.8125C7.28125 13.875 7.1875 13.9062 7.09375 13.9062C6.96875 13.9062 6.875 13.875 6.8125 13.8125L6.1875 13.1875C6.125 13.125 6.09375 13.0625 6.09375 12.9375C6.09375 12.8438 6.125 12.75 6.1875 12.6562L11.0312 7.8125H0.375C0.25 7.8125 0.15625 7.78125 0.09375 7.71875C0.03125 7.65625 0 7.5625 0 7.4375V6.5625C0 6.46875 0.03125 6.375 0.09375 6.3125C0.15625 6.25 0.25 6.1875 0.375 6.1875H11.0312L6.1875 1.34375C6.125 1.28125 6.09375 1.1875 6.09375 1.0625C6.09375 0.96875 6.125 0.875 6.1875 0.8125L6.8125 0.1875Z" fill="#169FE6"></path></svg></p></a></article><article class="post-summary"><a href="https://pyimagesearch.com/2014/05/26/opencv-python-k-means-color-clustering/" class="post-summary--link"><header class="entry-header"><div class="entry-categories"><div class="entry-category">Image Processing</div><div class="entry-category">Tutorials</div></div><h2 class="entry-title">OpenCV and Python K-Means Color Clustering</h2><div class="entry-date">May 26, 2014</div></header><p class="entry-content-link"><svg class="svg-icon long-arrow" width="14" height="14" aria-hidden="true" role="img" focusable="false" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.8125 0.1875C6.875 0.125 6.96875 0.09375 7.09375 0.09375C7.1875 0.09375 7.28125 0.125 7.34375 0.1875L13.875 6.75C13.9375 6.8125 14 6.90625 14 7C14 7.125 13.9375 7.1875 13.875 7.25L7.34375 13.8125C7.28125 13.875 7.1875 13.9062 7.09375 13.9062C6.96875 13.9062 6.875 13.875 6.8125 13.8125L6.1875 13.1875C6.125 13.125 6.09375 13.0625 6.09375 12.9375C6.09375 12.8438 6.125 12.75 6.1875 12.6562L11.0312 7.8125H0.375C0.25 7.8125 0.15625 7.78125 0.09375 7.71875C0.03125 7.65625 0 7.5625 0 7.4375V6.5625C0 6.46875 0.03125 6.375 0.09375 6.3125C0.15625 6.25 0.25 6.1875 0.375 6.1875H11.0312L6.1875 1.34375C6.125 1.28125 6.09375 1.1875 6.09375 1.0625C6.09375 0.96875 6.125 0.875 6.1875 0.8125L6.8125 0.1875Z" fill="#169FE6"></path></svg></p></a></article><article class="post-summary"><a href="https://pyimagesearch.com/2016/12/19/install-opencv-3-on-macos-with-homebrew-the-easy-way/" class="post-summary--link"><header class="entry-header"><div class="entry-categories"><div class="entry-category">OpenCV Tutorials</div><div class="entry-category">Tutorials</div></div><h2 class="entry-title">Install OpenCV 3 on macOS with Homebrew (the easy way)</h2><div class="entry-date">December 19, 2016</div></header><p class="entry-content-link"><svg class="svg-icon long-arrow" width="14" height="14" aria-hidden="true" role="img" focusable="false" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.8125 0.1875C6.875 0.125 6.96875 0.09375 7.09375 0.09375C7.1875 0.09375 7.28125 0.125 7.34375 0.1875L13.875 6.75C13.9375 6.8125 14 6.90625 14 7C14 7.125 13.9375 7.1875 13.875 7.25L7.34375 13.8125C7.28125 13.875 7.1875 13.9062 7.09375 13.9062C6.96875 13.9062 6.875 13.875 6.8125 13.8125L6.1875 13.1875C6.125 13.125 6.09375 13.0625 6.09375 12.9375C6.09375 12.8438 6.125 12.75 6.1875 12.6562L11.0312 7.8125H0.375C0.25 7.8125 0.15625 7.78125 0.09375 7.71875C0.03125 7.65625 0 7.5625 0 7.4375V6.5625C0 6.46875 0.03125 6.375 0.09375 6.3125C0.15625 6.25 0.25 6.1875 0.375 6.1875H11.0312L6.1875 1.34375C6.125 1.28125 6.09375 1.1875 6.09375 1.0625C6.09375 0.96875 6.125 0.875 6.1875 0.8125L6.8125 0.1875Z" fill="#169FE6"></path></svg></p></a></article></div></div></div><div class="gpd-footer-cta"><div class="wrap"><div class="footer-cta-grid"><div class="footer-cta-image"><img width="932" height="833" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/man-on-sofa-with-laptop-1.jpg" class="attachment-full size-full" alt="" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=126x113&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1-300x268.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=378x338&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=504x450&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=630x563&amp;lossy=1&amp;strip=1&amp;webp=1 630w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1-768x686.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?lossy=1&amp;strip=1&amp;webp=1 932w" data-lazy-sizes="(max-width: 932px) 100vw, 932px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?lossy=1&amp;strip=1&amp;webp=1"><noscript><img width="932" height="833" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?lossy=1&strip=1&webp=1" class="attachment-full size-full" alt="" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=126x113&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1-300x268.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=378x338&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=504x450&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=630x563&amp;lossy=1&amp;strip=1&amp;webp=1 630w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1-768x686.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?lossy=1&amp;strip=1&amp;webp=1 932w" sizes="(max-width: 932px) 100vw, 932px" /></noscript></div><div class="footer-cta-title"><h3>You can learn Computer Vision, Deep Learning, and OpenCV.</h3></div><div class="footer-cta-content"><div class="footer-cta-content-desc"><p>Get your FREE 17 page Computer Vision, OpenCV, and Deep Learning Resource Guide PDF. Inside you’ll find our hand-picked tutorials, books, courses, and libraries to help you master CV and DL.</p>
</div><div class="footer-cta-content-action"><form class="footer-cta" action="https://www.getdrip.com/forms/657075648/submissions" method="post" target="_blank" data-drip-embedded-form="657075648">
	<input type="email" name="fields[email]" class="form-control" id="email" value="" placeholder="Your email address">
	<button type="submit" data-drip-attribute="sign-up-button">Download for free</button>
	<div style="display: none;" aria-hidden="true"><label for="website">Website</label><br><input type="text" id="website" name="website" tabindex="-1" autocomplete="false" value=""></div>
</form></div></div></div></div></div><div class="footer-widgets" id="genesis-footer-widgets"><h2 class="genesis-sidebar-title screen-reader-text">Footer</h2><div class="wrap"><div class="widget-area footer-widgets-1 footer-widget-area"><section id="custom_html-7" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><h3 class="widgettitle widget-title">Topics</h3>
<div class="textwidget custom-html-widget"><ul>
	<li><a href="https://pyimagesearch.com/category/deep-learning-2/">Deep Learning</a></li>
	<li><a href="https://pyimagesearch.com/category/dlib/">Dlib Library</a></li>
	<li><a href="https://pyimagesearch.com/category/embedded/">Embedded/IoT and Computer Vision</a></li>
	<li><a href="https://pyimagesearch.com/category/faces/">Face Applications</a></li>
	<li><a href="https://pyimagesearch.com/category/image-processing/">Image Processing</a></li>
	<li><a href="https://pyimagesearch.com/category/interviews/">Interviews</a></li>
	<li><a href="https://pyimagesearch.com/category/keras/">Keras</a></li>
</ul>
</div></div></section>
</div><div class="widget-area footer-widgets-2 footer-widget-area"><section id="custom_html-8" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><div class="textwidget custom-html-widget"><ul>
	<li><a href="https://pyimagesearch.com/category/machine-learning-2/">Machine Learning and Computer Vision</a></li>
	<li><a href="https://pyimagesearch.com/category/medical/">Medical Computer Vision</a></li>
	<li><a href="https://pyimagesearch.com/category/optical-character-recognition-ocr/">Optical Character Recognition (OCR)</a></li>
	<li><a href="https://pyimagesearch.com/category/object-detection/">Object Detection</a></li>
	<li><a href="https://pyimagesearch.com/category/object-tracking/">Object Tracking</a></li>
	<li><a href="https://pyimagesearch.com/category/opencv/">OpenCV Tutorials</a></li>
	<li><a href="https://pyimagesearch.com/category/raspberry-pi/">Raspberry Pi</a></li>
</ul></div></div></section>
</div><div class="widget-area footer-widgets-3 footer-widget-area"><section id="custom_html-9" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><h3 class="widgettitle widget-title">Books &amp; Courses</h3>
<div class="textwidget custom-html-widget"><ul>
<li><a href="https://pyimagesearch.com/pyimagesearch-university/">PyImageSearch University</a></li>
<li><a href="https://pyimagesearch.com/free-opencv-computer-vision-deep-learning-crash-course/">FREE CV, DL, and OpenCV Crash Course</a></li>
<li><a href="https://pyimagesearch.com/practical-python-opencv/">Practical Python and OpenCV</a></li>
<li><a href="https://pyimagesearch.com/deep-learning-computer-vision-python-book/">Deep Learning for Computer Vision with Python</a></li>
<li><a href="https://pyimagesearch.com/pyimagesearch-gurus/">PyImageSearch Gurus Course</a></li>
<li><a href="https://pyimagesearch.com/raspberry-pi-for-computer-vision/">Raspberry Pi for Computer Vision</a></li>
</ul></div></div></section>
</div><div class="widget-area footer-widgets-4 footer-widget-area"><section id="custom_html-10" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><h3 class="widgettitle widget-title">PyImageSearch</h3>
<div class="textwidget custom-html-widget"><ul>
		<li><a href="https://pyimagesearch.com/affiliates/">Affiliates</a></li>
	<li><a href="https://pyimagesearch.com/start-here/">Get Started</a></li>
	<li><a href="https://pyimagesearch.com/opencv-tutorials-resources-guides/">OpenCV Install Guides</a></li>
	<li><a href="https://pyimagesearch.com/about/">About</a></li>
	<li><a href="https://pyimagesearch.com/faqs/">FAQ</a></li>
	<li><a href="https://pyimagesearch.com/topics/">Blog</a></li>
	<li><a href="https://pyimagesearch.com/contact/">Contact</a></li>
	<li><a href="https://pyimagesearch.com/privacy-policy/">Privacy Policy</a></li>
</ul></div></div></section>
</div></div></div><footer class="site-footer"><div class="wrap"><div class="footer-logo"><p class="site-title"><a href="https://pyimagesearch.com/"></a></p></div><div class="footer-social"><a target="_blank" href="https://www.facebook.com/pyimagesearch"><svg class="svg-icon social-icon" width="18" height="18" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 264 512"><path d="M215.8 85H264V3.6C255.7 2.5 227.1 0 193.8 0 124.3 0 76.7 42.4 76.7 120.3V192H0v91h76.7v229h94V283h73.6l11.7-91h-85.3v-62.7c0-26.3 7.3-44.3 45.1-44.3z"></path></svg></a><a target="_blank" href="https://twitter.com/PyImageSearch"><svg class="svg-icon social-icon" width="18" height="18" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a target="_blank" href="http://www.linkedin.com/pub/adrian-rosebrock/2a/873/59b"><svg class="svg-icon social-icon" width="18" height="18" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a><a target="_blank" href="https://www.youtube.com/channel/UCoQK7OVcIVy-nV4m-SMCk_Q/videos"><svg class="svg-icon social-icon" width="18" height="18" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></div><div class="footer-info">© 2022 <a href="https://pyimagesearch.com/">PyImageSearch</a>. All Rights Reserved.</div></div></footer></div><!-- RightMessage WP -->


<div class="front-page-modal modal" id="pyis-cta-modal">

    <div class="modal-content">

        
<div class="optin-modal-content">

    <div style="text-align: center; font-size: 18px; padding-bottom: 20px;">
        <a target="_blank" href="https://pyimagesearch.mykajabi.com/login" style="font-weight: normal; color: #808080;">Already a member of PyImageSearch University? <strong>Click here to login.</strong></a>
    </div>

    <center>
        <img class="pyuni-logo" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/pyimagesearch_university_logo.png" alt="PyImageSearch University Logo">
    </center>

    <div class="front-modal-top">
        <h3>Access the code to this tutorial and all other 500+ tutorials on PyImageSearch</h3>
    </div>

    <div class="front-modal-video first">
        <div class="front-modal-video-embed">
            <div class="wistia_responsive_padding" style="padding:56.25% 0 0 0;position:relative;"><div class="wistia_responsive_wrapper" style="height:100%;left:0;position:absolute;top:0;width:100%;"><div class="wistia_embed wistia_async_8ggk996ods videoFoam=true wistia_embed_initialized" style="height:100%;position:relative;width:100%" id="wistia-8ggk996ods-1"><div class="wistia_swatch" style="height: 100%; left: 0px; opacity: 1; overflow: hidden; position: absolute; top: 0px; transition: opacity 200ms ease 0s; width: 100%;"><img src="./Image Stitching with OpenCV and Python - PyImageSearch_files/swatch(2)" style="filter:blur(5px);height:100%;object-fit:contain;width:100%;" alt="" aria-hidden="true" onload="this.parentNode.style.opacity=1;" data-lazy-src="https://fast.wistia.com/embed/medias/8ggk996ods/swatch"><noscript><img src="https://fast.wistia.com/embed/medias/8ggk996ods/swatch" style="filter:blur(5px);height:100%;object-fit:contain;width:100%;" alt="" aria-hidden="true" onload="this.parentNode.style.opacity=1;" /></noscript></div><div id="wistia_chrome_40" class="w-chrome" tabindex="-1" style="display: inline-block; height: 100%; line-height: normal; margin: 0px; padding: 0px; position: relative; vertical-align: top; width: 100%; zoom: 1; outline: none; overflow: hidden; box-sizing: content-box;"><div id="wistia_grid_110_wrapper" style="display: block;"><div id="wistia_grid_110_above"></div><div id="wistia_grid_110_main"><div id="wistia_grid_110_behind"></div><div id="wistia_grid_110_center"><div class="w-video-wrapper w-css-reset" style="clip: rect(0px, 0px, 0px, 0px); height: 100%; position: absolute; top: 0px; width: 100%; opacity: 1; background-color: rgb(0, 0, 0);"></div><div class="w-ui-container" style="height: 100%; left: 0px; position: absolute; top: 0px; width: 100%; opacity: 1;"></div></div><div id="wistia_grid_110_front"></div><div id="wistia_grid_110_top_inside"><div id="wistia_grid_110_top"></div></div><div id="wistia_grid_110_bottom_inside"><div id="wistia_grid_110_bottom"></div></div><div id="wistia_grid_110_left_inside"><div id="wistia_grid_110_left"></div></div><div id="wistia_grid_110_right_inside"><div id="wistia_grid_110_right"></div></div></div><div id="wistia_grid_110_below"></div><style id="wistia_111_style" type="text/css" class="wistia_injected_style">#wistia_grid_110_wrapper{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;font-family:Arial,sans-serif;font-size:14px;height:100%;position:relative;text-align:left;width:100%;}
#wistia_grid_110_wrapper *{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;}
#wistia_grid_110_above{position:relative;}
#wistia_grid_110_main{display:block;height:100%;position:relative;}
#wistia_grid_110_behind{height:100%;left:0;position:absolute;top:0;width:100%;}
#wistia_grid_110_center{height:100%;overflow:hidden;position:relative;width:100%;}
#wistia_grid_110_front{display:none;height:100%;left:0;position:absolute;top:0;width:100%;}
#wistia_grid_110_top_inside{position:absolute;left:0;top:0;width:100%;}
#wistia_grid_110_top{width:100%;position:absolute;bottom:0;left:0;}
#wistia_grid_110_bottom_inside{position:absolute;left:0;bottom:0;width:100%;}
#wistia_grid_110_bottom{width:100%;position:absolute;top:0;left:0;}
#wistia_grid_110_left_inside{height:100%;position:absolute;left:0;top:0;}
#wistia_grid_110_left{height:100%;position:absolute;right:0;top:0;}
#wistia_grid_110_right_inside{height:100%;right:0;position:absolute;top:0;}
#wistia_grid_110_right{height:100%;left:0;position:absolute;top:0;}
#wistia_grid_110_below{position:relative;}</style></div></div></div></div></div>
        </div>
        <div class="front-modal-action" style="margin-top: 20px;">
            <p><strong>Enter your email address below to learn more about PyImageSearch University</strong> (including how you can download the source code to this post):</p>
            <form class="footer-cta" action="https://www.getdrip.com/forms/857913265/submissions" method="post" target="_blank" data-drip-embedded-form="857913265" id="drip-ef-857913265">
                <input type="email" name="fields[email]" class="form-control" id="email" value="" placeholder="Your email address">
                <input id="code_submit_post_title" type="hidden" name="fields[code_submit_post_title]" value="">
                <button type="submit" data-drip-attribute="sign-up-button">Learn More</button>
                <div style="display: none;" aria-hidden="true"><label for="website">Website</label><br><input type="text" id="website" name="website" tabindex="-1" autocomplete="false" value=""></div>
            </form>
        </div>
    </div>

    <div class="front-modal-top">
        <h3>What's included in PyImageSearch University?</h3>
    </div>

    <div class="front-modal-video">
        <div class="front-modal-video-desc">
            <ul class="is-style-list-checks">
                <li><strong>Easy access to the code, datasets, and pre-trained models</strong> for all 500+ tutorials on the PyImageSearch blog</li>
                <li><strong>High-quality, well documented source code</strong> with line-by-line explanations (ensuring you know exactly what the code is doing)</li>
                <li><strong>Jupyter Notebooks</strong> that are pre-configured to run in <strong>Google Colab</strong> with a <em>single click</em></li>
                <li><strong>Run all code examples in your web browser</strong> — no dev environment configuration required!</li>
            </ul>
        </div>
        <div class="front-modal-video-desc">
            <ul class="is-style-list-checks">
                <li><strong>Support for all major operating systems</strong> (Windows, macOS, Linux, and Raspbian)</li>
                <li><strong>Full access to PyImageSearch University courses</strong></li>
                <li><strong>Detailed video tutorials</strong> for every lesson</li>
                <li><strong>Certificates of Completion</strong> for all courses</li>
                <li><strong>New courses added <em>every month!</em></strong> — stay on top of state-of-the-art trends in computer vision and deep learning</li>
            </ul>
        </div>
    </div>

    <div class="front-modal-testimonial">
        <blockquote><p>PyImageSearch University is really the best Computer Visions "Masters" Degree that I wish I had when starting out. <strong>Being able to access all of Adrian's tutorials in a single indexed page and being able to start playing around with the code without going through the nightmare of setting up everything is just amazing.</strong> 10/10 would recommend.</p><cite><span class="quote-name">Sanyam Bhutani</span><span class="cite-title">Machine Learning Engineer and 2x Kaggle Master</span></cite></blockquote>
    </div>

</div>
    </div>

    <a href="https://pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/#close-modal" rel="modal:close" target="_self" class="close-modal">
        Close    </a>

</div><!-- Drip -->


<!-- facebook -->

<noscript><img height="1" width="1" style="display:none"
  src="https://www.facebook.com/tr?id=1465896023527386&ev=PageView&noscript=1"
/></noscript>

<!-- Global site tag (gtag.js) - Google Analytics -->



<!-- Start VWO Async SmartCode -->
<script type="text/javascript">
window._vwo_code = window._vwo_code || (function(){
var account_id=586234,
settings_tolerance=2000,
library_tolerance=2500,
use_existing_jquery=false,
is_spa=1,
hide_element='body',

/* DO NOT EDIT BELOW THIS LINE */
f=false,d=document,code={use_existing_jquery:function(){return use_existing_jquery;},library_tolerance:function(){return library_tolerance;},finish:function(){if(!f){f=true;var a=d.getElementById('_vis_opt_path_hides');if(a)a.parentNode.removeChild(a);}},finished:function(){return f;},load:function(a){var b=d.createElement('script');b.src=a;b.type='text/javascript';b.innerText;b.onerror=function(){_vwo_code.finish();};d.getElementsByTagName('head')[0].appendChild(b);},init:function(){
window.settings_timer=setTimeout(function () {_vwo_code.finish() },settings_tolerance);var a=d.createElement('style'),b=hide_element?hide_element+'{opacity:0 !important;filter:alpha(opacity=0) !important;background:none !important;}':'',h=d.getElementsByTagName('head')[0];a.setAttribute('id','_vis_opt_path_hides');a.setAttribute('type','text/css');if(a.styleSheet)a.styleSheet.cssText=b;else a.appendChild(d.createTextNode(b));h.appendChild(a);this.load('https://dev.visualwebsiteoptimizer.com/j.php?a='+account_id+'&u='+encodeURIComponent(d.URL)+'&f='+(+is_spa)+'&r='+Math.random());return settings_timer; }};window._vwo_settings_timer = code.init(); return code; }());
</script>
<!-- End VWO Async SmartCode --><!-- This site is converting visitors into subscribers and customers with OptinMonster - https://optinmonster.com :: Campaign Title: 2022/09/10 baseline -->

<!-- / OptinMonster --><!-- This site is converting visitors into subscribers and customers with OptinMonster - https://optinmonster.com :: Campaign Title: PyImageSearch Gurus Syllabus --><div id="om-kizfm1tpclo79dji-holder"></div><!-- / OptinMonster --><div style="position:absolute;overflow:hidden;clip:rect(0 0 0 0);height:1px;width:1px;margin:-1px;padding:0;border:0"><div class="omapi-shortcode-helper">[class^="wpforms-"]</div><div class="omapi-shortcode-parsed omapi-encoded">[class^="wpforms-"]</div></div>		
		
<script type="text/javascript" id="rocket-browser-checker-js-after">
"use strict";var _createClass=function(){function defineProperties(target,props){for(var i=0;i<props.length;i++){var descriptor=props[i];descriptor.enumerable=descriptor.enumerable||!1,descriptor.configurable=!0,"value"in descriptor&&(descriptor.writable=!0),Object.defineProperty(target,descriptor.key,descriptor)}}return function(Constructor,protoProps,staticProps){return protoProps&&defineProperties(Constructor.prototype,protoProps),staticProps&&defineProperties(Constructor,staticProps),Constructor}}();function _classCallCheck(instance,Constructor){if(!(instance instanceof Constructor))throw new TypeError("Cannot call a class as a function")}var RocketBrowserCompatibilityChecker=function(){function RocketBrowserCompatibilityChecker(options){_classCallCheck(this,RocketBrowserCompatibilityChecker),this.passiveSupported=!1,this._checkPassiveOption(this),this.options=!!this.passiveSupported&&options}return _createClass(RocketBrowserCompatibilityChecker,[{key:"_checkPassiveOption",value:function(self){try{var options={get passive(){return!(self.passiveSupported=!0)}};window.addEventListener("test",null,options),window.removeEventListener("test",null,options)}catch(err){self.passiveSupported=!1}}},{key:"initRequestIdleCallback",value:function(){!1 in window&&(window.requestIdleCallback=function(cb){var start=Date.now();return setTimeout(function(){cb({didTimeout:!1,timeRemaining:function(){return Math.max(0,50-(Date.now()-start))}})},1)}),!1 in window&&(window.cancelIdleCallback=function(id){return clearTimeout(id)})}},{key:"isDataSaverModeOn",value:function(){return"connection"in navigator&&!0===navigator.connection.saveData}},{key:"supportsLinkPrefetch",value:function(){var elem=document.createElement("link");return elem.relList&&elem.relList.supports&&elem.relList.supports("prefetch")&&window.IntersectionObserver&&"isIntersecting"in IntersectionObserverEntry.prototype}},{key:"isSlowConnection",value:function(){return"connection"in navigator&&"effectiveType"in navigator.connection&&("2g"===navigator.connection.effectiveType||"slow-2g"===navigator.connection.effectiveType)}}]),RocketBrowserCompatibilityChecker}();
</script>
<script type="text/javascript" id="rocket-preload-links-js-extra">
/* <![CDATA[ */
var RocketPreloadLinksConfig = {"excludeUris":"\/contact\/|\/(?:.+\/)?feed(?:\/(?:.+\/?)?)?$|\/(?:.+\/)?embed\/|\/(index\\.php\/)?wp\\-json(\/.*|$)|\/refer\/|\/go\/|\/recommend\/|\/recommends\/","usesTrailingSlash":"1","imageExt":"jpg|jpeg|gif|png|tiff|bmp|webp|avif|pdf|doc|docx|xls|xlsx|php","fileExt":"jpg|jpeg|gif|png|tiff|bmp|webp|avif|pdf|doc|docx|xls|xlsx|php|html|htm","siteUrl":"https:\/\/pyimagesearch.com","onHoverDelay":"100","rateThrottle":"3"};
/* ]]> */
</script>
<script type="text/javascript" id="rocket-preload-links-js-after">
(function() {
"use strict";var r="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e},e=function(){function i(e,t){for(var n=0;n<t.length;n++){var i=t[n];i.enumerable=i.enumerable||!1,i.configurable=!0,"value"in i&&(i.writable=!0),Object.defineProperty(e,i.key,i)}}return function(e,t,n){return t&&i(e.prototype,t),n&&i(e,n),e}}();function i(e,t){if(!(e instanceof t))throw new TypeError("Cannot call a class as a function")}var t=function(){function n(e,t){i(this,n),this.browser=e,this.config=t,this.options=this.browser.options,this.prefetched=new Set,this.eventTime=null,this.threshold=1111,this.numOnHover=0}return e(n,[{key:"init",value:function(){!this.browser.supportsLinkPrefetch()||this.browser.isDataSaverModeOn()||this.browser.isSlowConnection()||(this.regex={excludeUris:RegExp(this.config.excludeUris,"i"),images:RegExp(".("+this.config.imageExt+")$","i"),fileExt:RegExp(".("+this.config.fileExt+")$","i")},this._initListeners(this))}},{key:"_initListeners",value:function(e){-1<this.config.onHoverDelay&&document.addEventListener("mouseover",e.listener.bind(e),e.listenerOptions),document.addEventListener("mousedown",e.listener.bind(e),e.listenerOptions),document.addEventListener("touchstart",e.listener.bind(e),e.listenerOptions)}},{key:"listener",value:function(e){var t=e.target.closest("a"),n=this._prepareUrl(t);if(null!==n)switch(e.type){case"mousedown":case"touchstart":this._addPrefetchLink(n);break;case"mouseover":this._earlyPrefetch(t,n,"mouseout")}}},{key:"_earlyPrefetch",value:function(t,e,n){var i=this,r=setTimeout(function(){if(r=null,0===i.numOnHover)setTimeout(function(){return i.numOnHover=0},1e3);else if(i.numOnHover>i.config.rateThrottle)return;i.numOnHover++,i._addPrefetchLink(e)},this.config.onHoverDelay);t.addEventListener(n,function e(){t.removeEventListener(n,e,{passive:!0}),null!==r&&(clearTimeout(r),r=null)},{passive:!0})}},{key:"_addPrefetchLink",value:function(i){return this.prefetched.add(i.href),new Promise(function(e,t){var n=document.createElement("link");n.rel="prefetch",n.href=i.href,n.onload=e,n.onerror=t,document.head.appendChild(n)}).catch(function(){})}},{key:"_prepareUrl",value:function(e){if(null===e||"object"!==(void 0===e?"undefined":r(e))||!1 in e||-1===["http:","https:"].indexOf(e.protocol))return null;var t=e.href.substring(0,this.config.siteUrl.length),n=this._getPathname(e.href,t),i={original:e.href,protocol:e.protocol,origin:t,pathname:n,href:t+n};return this._isLinkOk(i)?i:null}},{key:"_getPathname",value:function(e,t){var n=t?e.substring(this.config.siteUrl.length):e;return n.startsWith("/")||(n="/"+n),this._shouldAddTrailingSlash(n)?n+"/":n}},{key:"_shouldAddTrailingSlash",value:function(e){return this.config.usesTrailingSlash&&!e.endsWith("/")&&!this.regex.fileExt.test(e)}},{key:"_isLinkOk",value:function(e){return null!==e&&"object"===(void 0===e?"undefined":r(e))&&(!this.prefetched.has(e.href)&&e.origin===this.config.siteUrl&&-1===e.href.indexOf("?")&&-1===e.href.indexOf("#")&&!this.regex.excludeUris.test(e.href)&&!this.regex.images.test(e.href))}}],[{key:"run",value:function(){"undefined"!=typeof RocketPreloadLinksConfig&&new n(new RocketBrowserCompatibilityChecker({capture:!0,passive:!0}),RocketPreloadLinksConfig).init()}}]),n}();t.run();
}());
</script>





<script type="text/javascript" id="gforms_recaptcha_recaptcha-js-extra">
/* <![CDATA[ */
var gforms_recaptcha_recaptcha_strings = {"site_key":"6LdUr2EfAAAAAJ6_2rW0WWD9TkARt5bIjiIJeGnJ","ajaxurl":"https:\/\/pyimagesearch.com\/wp-admin\/admin-ajax.php","nonce":"1124d2675f"};
/* ]]> */
</script>







		<script type="text/javascript">var omapi_localized = {
			ajax: 'https://pyimagesearch.com/wp-admin/admin-ajax.php?optin-monster-ajax-route=1',
			nonce: 'c89028fe77',
			slugs:
			{"vksgrjuaic5dopynajjn":{"slug":"vksgrjuaic5dopynajjn","mailpoet":false},"kizfm1tpclo79dji":{"slug":"kizfm1tpclo79dji","mailpoet":false}}		};</script>
				<script type="text/javascript">var omapi_data = {"wc_cart":[],"object_id":9285,"object_key":"post","object_type":"post","term_ids":[21,27,218,332,222,329,331,330],"wp_json":"https:\/\/pyimagesearch.com\/wp-json"};</script>
		<script>window.lazyLoadOptions=[{elements_selector:"img[data-lazy-src],.rocket-lazyload,iframe[data-lazy-src]",data_src:"lazy-src",data_srcset:"lazy-srcset",data_sizes:"lazy-sizes",class_loading:"lazyloading",class_loaded:"lazyloaded",threshold:300,callback_loaded:function(element){if(element.tagName==="IFRAME"&&element.dataset.rocketLazyload=="fitvidscompatible"){if(element.classList.contains("lazyloaded")){if(typeof window.jQuery!="undefined"){if(jQuery.fn.fitVids){jQuery(element).parent().fitVids()}}}}}},{elements_selector:".rocket-lazyload",data_src:"lazy-src",data_srcset:"lazy-srcset",data_sizes:"lazy-sizes",class_loading:"lazyloading",class_loaded:"lazyloaded",threshold:300,}];window.addEventListener('LazyLoad::Initialized',function(e){var lazyLoadInstance=e.detail.instance;if(window.MutationObserver){var observer=new MutationObserver(function(mutations){var image_count=0;var iframe_count=0;var rocketlazy_count=0;mutations.forEach(function(mutation){for(var i=0;i<mutation.addedNodes.length;i++){if(typeof mutation.addedNodes[i].getElementsByTagName!=='function'){continue}
if(typeof mutation.addedNodes[i].getElementsByClassName!=='function'){continue}
images=mutation.addedNodes[i].getElementsByTagName('img');is_image=mutation.addedNodes[i].tagName=="IMG";iframes=mutation.addedNodes[i].getElementsByTagName('iframe');is_iframe=mutation.addedNodes[i].tagName=="IFRAME";rocket_lazy=mutation.addedNodes[i].getElementsByClassName('rocket-lazyload');image_count+=images.length;iframe_count+=iframes.length;rocketlazy_count+=rocket_lazy.length;if(is_image){image_count+=1}
if(is_iframe){iframe_count+=1}}});if(image_count>0||iframe_count>0||rocketlazy_count>0){lazyLoadInstance.update()}});var b=document.getElementsByTagName("body")[0];var config={childList:!0,subtree:!0};observer.observe(b,config)}},!1)</script><script>"use strict";function wprRemoveCPCSS(){var preload_stylesheets=document.querySelectorAll('link[data-rocket-async="style"][rel="preload"]');if(preload_stylesheets&&0<preload_stylesheets.length)for(var stylesheet_index=0;stylesheet_index<preload_stylesheets.length;stylesheet_index++){var media=preload_stylesheets[stylesheet_index].getAttribute("media")||"all";if(window.matchMedia(media).matches)return void setTimeout(wprRemoveCPCSS,200)}var elem=document.getElementById("rocket-critical-css");elem&&"remove"in elem&&elem.remove()}window.addEventListener?window.addEventListener("load",wprRemoveCPCSS):window.attachEvent&&window.attachEvent("onload",wprRemoveCPCSS);</script><noscript><link data-avlabs-exclude-css="1"  rel="stylesheet" href="https://pyimagesearch.com/wp-content/cache/min/1/eef0bf32586d57e4ed24eb224ecbaf2f.css" media="all" data-minify="1" /></noscript><script>
        var avlabs_load_scripts_immediately =false ;
        var avlabs_primary_scripts = [] ;
        var avlabs_secondary_scripts = [] ;
        var avlabs_primary_scripts_to_be_loaded =[];
        var avlabs_secondary_scripts_to_be_loaded=[];
        var primary_script_timer, secondary_script_timer;
        avlabs_primary_scripts.push('https://pyimagesearch.com/wp-includes/js/jquery/jquery.js');
        avlabs_primary_scripts.push('https://pyimagesearch.com/wp-content/cache/min/1/f67da8ef1bb72583a9be2d03590e071d_avlabs_primary_script.js');
        avlabs_primary_scripts.push('https://pyimagesearch.com/wp-content/avlabs-cache/js/avlabs-mobile-menu.js?ver=6.0.3');
        avlabs_primary_scripts.push('https://pyimagesearch.com/wp-content/avlabs-cache/js/avlabs-preloader.js?ver=6.0.3');
        avlabs_primary_scripts.push('https://pyimagesearch.com/wp-content/themes/pyi/assets/js/stickykit.min.js?ver=1597079258');
        avlabs_secondary_scripts.push('https://fast.wistia.com/embed/medias/kno0cmko2z.jsonp');
        avlabs_secondary_scripts.push('https://fast.wistia.com/embed/medias/8ggk996ods.jsonp');
        avlabs_secondary_scripts.push('https://www.google.com/recaptcha/api.js?render=6LdUr2EfAAAAAJ6_2rW0WWD9TkARt5bIjiIJeGnJ&#038;ver=1.1');
        avlabs_secondary_scripts.push('https://www.googletagmanager.com/gtag/js?id=UA-46641058-1');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/plugins/enlighter/cache/enlighterjs.min.js?ver=lyvLsKN0kw3Q9Uv');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/cache/min/1/ede493e5bb638499b98e1abc76c95105.js');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/themes/genesis/lib/js/skip-links.min.js?ver=3.4.0');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/themes/pyi/assets/js/modal-min.js?ver=1597079258');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/avlabs-cache/js/avlabs-lazy-load.js?ver=6.0.3');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/themes/pyi/assets/js/jquery.flexslider.min.js?ver=1597079258');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/themes/pyi/assets/js/global-min.js?ver=1597079258');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/plugins/wp-rocket/assets/js/lazyload/17.5/lazyload.min.js');
        setTimeout(function(){
        if( document.getElementById('avlabs-lazy-load-bg') !== null )
        {
            bg_none_css = document.getElementById('avlabs-lazy-load-bg').innerHTML;
                document.getElementById('avlabs-lazy-load-bg').innerHTML = bg_none_css.replaceAll("!important",'') ;
        }},8000);
                
        function avlabs_scripts_loader( which,callback) 
        {
            if(which=='primary' )
            {
                if(avlabs_primary_scripts_to_be_loaded=='')
                {
                    return;
                }
                else
                {
                   
                    //clearInterval
                    if( typeof primary_script_timer !== "undefined" )
                    {
                        clearInterval(primary_script_timer)
                    }
                    scripts = avlabs_primary_scripts_to_be_loaded;
                }
                
            }

            if(which=='secondary' )
            {
                if(avlabs_secondary_scripts_to_be_loaded=='')
                {
                    return;
                }
                else
                {
                    //clearInterval
                    if( typeof secondary_script_timer !== "undefined" )
                    {
                        clearInterval(secondary_script_timer)
                    }
                    scripts = avlabs_secondary_scripts_to_be_loaded;
                }
                
            }    

            var count = scripts.length;
            function urlCallback(url) {
                return function () {
                    
                    console.log(url + ' was loaded (' + --count + ' more '+which+' scripts remaining).');
                    if (count < 1) {
                        //callback();
                        if(which =='primary' && avlabs_load_scripts_immediately==true)
                        {
                            avlabs_secondary_scripts_to_be_loaded = avlabs_secondary_scripts;  
                        }
                        if(document.createEvent){
                            var evt = document.createEvent("MutationEvents"); 
                            evt.initMutationEvent("DOMContentLoaded", true, true, document, "", "", "", 0); 
                            document.dispatchEvent(evt);
                        }
                        if (typeof jQuery != 'undefined') {
                            jQuery(window).trigger( 'load' ); 
                            jQuery(window).trigger( 'resize' );
                        }
                    }
                };
            }

            function loadScript(url) {
                var s = document.createElement('script');
                s.setAttribute('src', url);
                s.onload = urlCallback(url);
                s.async=false;
                document.head.appendChild(s);
            }

            for (var i = 0; i<scripts.length; i++) {
                loadScript(scripts[i]);
            }
        };
        
        if(avlabs_primary_scripts!='')
        {
            primary_time_out = setTimeout(function(){
            avlabs_primary_scripts_to_be_loaded = avlabs_primary_scripts;
            }
        ,1000);
            if( typeof primary_script_timer === "undefined" )
            {
                primary_script_timer = setInterval(function(){
                    avlabs_scripts_loader('primary', function() {
                    });
                },200);
            }
            
        }

        if(avlabs_secondary_scripts !='' )
        {
            secondary_time_out = setTimeout(function(){
                avlabs_secondary_scripts_to_be_loaded = avlabs_secondary_scripts;
            }
        ,12000);
            if( typeof secondary_script_timer === "undefined" )
            {
                secondary_script_timer = setInterval(function(){
                    avlabs_scripts_loader('secondary', function() {
                    });
                },200);
            }
        }

        function avlabs_clear_timeout_load_js_script()
        {
            if(avlabs_primary_scripts!='' )
            {
                if(avlabs_primary_scripts_to_be_loaded =='')
                {
                    avlabs_primary_scripts_to_be_loaded = avlabs_primary_scripts;
                    avlabs_load_scripts_immediately=true;
                }
                else
                {
                    avlabs_secondary_scripts_to_be_loaded = avlabs_secondary_scripts;
                }
                    
            }
            else if(avlabs_secondary_scripts!='')
            {
                avlabs_secondary_scripts_to_be_loaded = avlabs_secondary_scripts;
            }

        }

        window.addEventListener("scroll", function(){
            avlabs_clear_timeout_load_js_script();
        });

        window.addEventListener("mousemove", function(){ 
            avlabs_clear_timeout_load_js_script();
        });

        window.addEventListener("touchstart", function(){ 
            avlabs_clear_timeout_load_js_script();
        }); 
            
        </script><script>
        var avlabs_load_css_immediately =false ;
        var avlabs_primary_css = [] ;
        var avlabs_secondary_css = [] ;
        var avlabs_primary_css_to_be_loaded =[];
        var avlabs_secondary_css_to_be_loaded=[];
        var primary_css_timer, secondary_css_timer;
        avlabs_secondary_css.push('https://pyimagesearch.com/wp-content/cache/min/1/eef0bf32586d57e4ed24eb224ecbaf2f.css');

        
        function avlabs_css_loader( which,callback) 
        {
            if(which=='primary' )
            {
                if(avlabs_primary_css_to_be_loaded=='')
                {
                    return;
                }
                else
                {
                    //clearInterval
                    if( typeof primary_css_timer !== "undefined" )
                    {
                            clearInterval(primary_css_timer)
                    }
                    scripts = avlabs_primary_css_to_be_loaded;
                }
                
            }

            if(which=='secondary' )
            {
                if(avlabs_secondary_css_to_be_loaded=='')
                {
                    return;
                }
                else
                {
                    //clearInterval
                    if( typeof secondary_css_timer !== "undefined" )
                    {
                        clearInterval(secondary_css_timer)
                    }
                    scripts = avlabs_secondary_css_to_be_loaded;
                }
                
            }    

            var count = scripts.length;
            function urlCallback(url) {
                return function () {
                    
                    console.log(url + ' was loaded (' + --count + ' more '+which+' css remaining).');
                    if (count < 1) {
                        //callback();
                        if(which =='primary' && avlabs_load_css_immediately==true)
                        {
                            avlabs_secondary_css_to_be_loaded = avlabs_secondary_css;  
                        }
                        
                    }
                };
            }
            var avlabs_atfcss = document.getElementById('avlabs-rocket-critical-css');
            
            function loadScript(url) {
                var css = document.createElement("link");
                css.rel = "stylesheet";
                css.href = url;
                css.media = "all";
                css.type = "text/css";
                css.onload = urlCallback(url);
                
                //document.getElementsByTagName('head')[0].appendChild(css);
                avlabs_atfcss.parentNode.insertBefore(css,avlabs_atfcss.nextSibling);
                
            }       

            for (var i = 0; i<scripts.length; i++) {
                loadScript(scripts[i]);
            }
        };
        
        if(avlabs_primary_css!='')
        {
            setTimeout(function(){
            avlabs_primary_css_to_be_loaded = avlabs_primary_css;
            }
        ,200);
            if( typeof primary_css_timer === "undefined" )
            {
                primary_css_timer = setInterval(function(){
                    avlabs_css_loader('primary', function() {
                    });
                },200);
            }
        }

        if(avlabs_secondary_css !='' )
        {
            setTimeout(function(){
                avlabs_secondary_css_to_be_loaded = avlabs_secondary_css;
            }
        ,12000);
            if( typeof secondary_css_timer === "undefined" )
            {
                secondary_css_timer = setInterval(function(){
                    avlabs_css_loader('secondary', function() {
                    });
                },200);
            }
        }

        function avlabs_clear_timeout_load_css_script()
        {
            if(avlabs_primary_css!='' )
            {
                if(avlabs_primary_css_to_be_loaded =='')
                {
                    avlabs_primary_css_to_be_loaded = avlabs_primary_css;
                    avlabs_load_css_immediately=true;
                }
                else
                {
                    avlabs_secondary_css_to_be_loaded = avlabs_secondary_css;
                }
                    
            }
            else if(avlabs_secondary_css!='')
            {
                avlabs_secondary_css_to_be_loaded = avlabs_secondary_css;
            }

        }

        window.addEventListener("scroll", function(){
            avlabs_clear_timeout_load_css_script();
        });

        window.addEventListener("mousemove", function(){ 
            avlabs_clear_timeout_load_css_script();
        });

        window.addEventListener("touchstart", function(){ 
            avlabs_clear_timeout_load_css_script();
        }); 
            
        </script><script>
if (document.querySelector("body[class*=av-template]") !== null) {
document.querySelector("style#avlabs-rocket-critical-css").innerHTML = "";
}
</script><script> var avlabs_mobile_menu_clicked = false;
var avlabs_mobile_menu = document.getElementsByClassName('mobile-menu-toggle')[0];
if (avlabs_mobile_menu !== undefined) {
    avlabs_mobile_menu.addEventListener("click", function(){
    avlabs_mobile_menu_clicked = true;
    });
}
            </script>

<div></div><style id="wistia_22_style" type="text/css" class="wistia_injected_style">
@font-face {
font-family: 'WistiaPlayerInterNumbersSemiBold';
font-feature-settings: 'tnum' 1;
src: url(data:application/x-font-woff;charset=utf-8;base64,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);
}
</style><div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; position: fixed; visibility: hidden; display: block; transition: right 0.3s ease 0s; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/anchor.html" width="256" height="60" role="presentation" name="a-k9vxlikuz19u" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;" src="./Image Stitching with OpenCV and Python - PyImageSearch_files/saved_resource(1).html"></iframe></div><div id="otherside-root"><div><div id="windows"><div><div style="all: unset;"></div></div></div><div class="css-34tvdx e1gj4xli0"></div></div></div><div id="hyperwrite-login-notification" style="display: none;"></div></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>