<!DOCTYPE html>
<!-- saved from url=(0071)https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/ -->
<html lang="en-US" class="js"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script type="text/javascript" async="" src="./Instance segmentation with OpenCV - PyImageSearch_files/saved_resource"></script><script class="w-json-ld" type="application/ld+json" id="w-json-ldwistia_43">{"@context":"http://schema.org/","@id":"https://fast.wistia.net/embed/iframe/kno0cmko2z","@type":"VideoObject","duration":"PT3M52S","name":"Pyimagesearch_Sales_page w/out Autoplay","thumbnailUrl":"https://embed-ssl.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.jpg?image_crop_resized=640x360","contentUrl":"https://embed-fastly.wistia.com/deliveries/2003a737de7da1bcd5c4d283caa5eefae8c9cbea.m3u8","embedUrl":"https://fast.wistia.net/embed/iframe/kno0cmko2z","uploadDate":"2021-02-19","description":"a PyImageSearch University Opt-in Pitch [v2] video","potentialAction":{"@type":"SeekToAction","target":"https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/?wtime={seek_to_second_number}","startOffset-input":"required name=seek_to_second_number"}}</script><script class="w-json-ld" type="application/ld+json" id="w-json-ldwistia_107">{"@context":"http://schema.org/","@id":"https://fast.wistia.net/embed/iframe/8ggk996ods","@type":"VideoObject","duration":"PT1M34S","name":"PyUniOptinPitch","thumbnailUrl":"https://embed-ssl.wistia.com/deliveries/b8e0c620b2c8f8986aa80fabf27c8de4.jpg?image_crop_resized=640x360","contentUrl":"https://embedwistia-a.akamaihd.net/deliveries/6eb159c40755e5ed484552ce51441db934ff5c1e.m3u8","embedUrl":"https://fast.wistia.net/embed/iframe/8ggk996ods?wseektoaction=true","uploadDate":"2021-03-05","description":"a PyImageSearch University Opt-in Pitch [v2] video","potentialAction":{"@type":"SeekToAction","target":"https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/?wtime={seek_to_second_number}","startOffset-input":"required name=seek_to_second_number"}}</script><script async="" src="./Instance segmentation with OpenCV - PyImageSearch_files/fbevents.js.download"></script><script type="text/javascript" src="./Instance segmentation with OpenCV - PyImageSearch_files/visit"></script>

<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1">

	<!-- This site is optimized with the Yoast SEO plugin v19.6.1 - https://yoast.com/wordpress/plugins/seo/ -->
	<title>Instance segmentation with OpenCV - PyImageSearch</title><style id="avlabs-lazy-load-bg">.pyi-page-hero .pyi-hero-right .pyi-page-hero .pyi-hero-left .nav-primary .is-topics .has-icon.has-icon--pi a::before, .nav-primary .is-topics .has-icon.has-icon--opencv a::before, .nav-primary .is-topics .has-icon.has-icon--object-tracking a::before, .nav-primary .is-topics .has-icon.has-icon--object-detection a::before, .nav-primary .is-topics .has-icon.has-icon--ocr a::before, .nav-primary .is-topics .has-icon.has-icon--medical a::before, .nav-primary .is-topics .has-icon.has-icon--ml a::before, .nav-primary .is-topics .has-icon.has-icon--keras a::before, .nav-primary .is-topics .has-icon.has-icon--interviews a::before, .nav-primary .is-topics .has-icon.has-icon--image a::before, .nav-primary .is-topics .has-icon.has-icon--face a::before, .nav-primary .is-topics .has-icon.has-icon--iot a::before, .nav-primary .is-topics .has-icon.has-icon--dlib a::before, .nav-primary .is-topics .has-icon.has-icon--deep-learning a::before{
background: none ;
}</style><style id="avlabs-custom-critical-css-before-rocket">:root{--wp-admin-theme-color:#007cba;--wp-admin-theme-color-darker-10:#006ba1;--wp-admin-theme-color-darker-20:#005a87}.enlighter-t-pyis-enlighter-theme .enlighter-codegroup-wrapper .enlighter-raw{background-color:#fff;font-size:12px;color:#000;line-height:16px}.enlighter-t-pyis-enlighter-theme .enlighter-codegroup-wrapper .enlighter-toolbar .enlighter-btn{border-radius:0}.enlighter-t-pyis-enlighter-theme .enlighter-codegroup-wrapper .enlighter-toolbar{display:none!important}.enlighter-t-pyis-enlighter-theme .enlighter-codegroup-wrapper .enlighter-toolbar .enlighter-btn{background-color:#fff;color:#717171;font-size:12px;padding:0;border:1px solid #e0e0e0;margin:0 0 0 8px;text-decoration:none;width:23px;height:23px;background-position:0 0;background-size:contain}.foundation-mq{font-family:"small=0em&medium=40em&large=64em&xlarge=75em&xxlarge=90em"}.sticky-container{position:relative}.sticky{position:relative;z-index:0;-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0)}.sticky.is-anchored{position:relative;right:auto;left:auto}#pyis-cta-modal-sticky-bar{margin:1.25rem 0}#pyis-cta-modal-sticky-bar .grid-container{padding-right:.625rem;padding-left:.625rem;max-width:75rem;margin-left:auto;margin-right:auto}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-container{padding-right:.9375rem;padding-left:.9375rem}}#pyis-cta-modal-sticky-bar .grid-x{display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-flow:row wrap;-ms-flex-flow:row wrap;flex-flow:row wrap}#pyis-cta-modal-sticky-bar .cell{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;min-height:0;min-width:0;width:100%}#pyis-cta-modal-sticky-bar .grid-margin-x{margin-left:-.625rem;margin-right:-.625rem}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-margin-x{margin-left:-.9375rem;margin-right:-.9375rem}}#pyis-cta-modal-sticky-bar .grid-margin-x>.cell{width:calc(100% - 1.25rem);margin-left:.625rem;margin-right:.625rem}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-margin-x>.cell{width:calc(100% - 1.875rem);margin-left:.9375rem;margin-right:.9375rem}}#pyis-cta-modal-sticky-bar .text-center{text-align:center}#pyis-cta-modal-sticky-bar .sticky{background-color:#051e50;color:#fefefe;padding:1.625rem 1rem 1.25rem 1.625rem}#pyis-cta-modal-sticky-bar .sticky a{background:0 0;outline:0;font-size:1.2rem;padding:0;border-bottom:none;color:#fefefe;text-decoration:underline;position:relative}#pyis-cta-modal-sticky-bar .sticky a:before{position:absolute;top:-.5625rem;left:-3.75rem;display:block;width:2.5rem;height:2.5rem;content:'';background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/source_code_mini_image.png);background-size:contain}#pyis-cta-modal .modal-content{margin-top:1.5rem}#pyis-cta-modal .optin-modal-content .pyuni-logo{padding-bottom:20px;max-width:400px}#pyis-cta-modal .optin-modal-content h3{margin-bottom:20px;font-size:24px}#pyis-cta-modal .optin-modal-content .is-style-list-checks li{font-weight:400}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff2"),url(https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("woff"),url(https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3) format("opentype");font-display:swap;font-style:normal;font-weight:700}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/4c4052/00000000000000003b9b3069/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff2"),url(https://use.typekit.net/af/4c4052/00000000000000003b9b3069/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("woff"),url(https://use.typekit.net/af/4c4052/00000000000000003b9b3069/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i7&v=3) format("opentype");font-display:swap;font-style:italic;font-weight:700}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff2"),url(https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("woff"),url(https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3) format("opentype");font-display:swap;font-style:normal;font-weight:600}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff2"),url(https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("woff"),url(https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3) format("opentype");font-display:swap;font-style:normal;font-weight:400}@font-face{font-family:proxima-nova;src:url(https://use.typekit.net/af/5c70f2/00000000000000003b9b3063/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff2"),url(https://use.typekit.net/af/5c70f2/00000000000000003b9b3063/27/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("woff"),url(https://use.typekit.net/af/5c70f2/00000000000000003b9b3063/27/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=i4&v=3) format("opentype");font-display:swap;font-style:italic;font-weight:400}button,input{overflow:visible}html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{margin:.67em 0;font-size:2em}code,pre{font-family:monospace;font-size:1em}a{background-color:transparent}strong{font-weight:bolder}img{border-style:none}button,input,textarea{margin:0;font-family:inherit;font-size:100%;line-height:1.15}button{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=submit]::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}[type=submit]:-moz-focusring,button:-moz-focusring{outline:ButtonText dotted 1px}textarea{overflow:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}html{box-sizing:border-box}*,:after{box-sizing:inherit}.entry-content::before,.entry::before,.nav-primary::before,.nav-secondary::before,.site-container::before,.site-header::before,.site-inner::before,.widget::before,.wrap::before{display:table;content:" "}.entry-content::after,.entry::after,.nav-primary::after,.nav-secondary::after,.site-container::after,.site-header::after,.site-inner::after,.widget::after,.wrap::after{display:table;clear:both;content:""}html,input[type=search]{box-sizing:border-box}*,:after,:before{box-sizing:inherit}html{overflow-y:scroll;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}body{margin:0;font-family:proxima-nova,sans-serif;font-weight:400;line-height:1.472;color:#051e50;font-size:17px}@media (min-width:640px){body{line-height:1.52}}@media (min-width:880px){body{line-height:1.568}}@media (min-width:1200px){body{line-height:1.6}}@media (min-width:640px){body{font-size:19px}}@media (min-width:880px){body{font-size:20px}}body a{font-weight:700;color:#169fe6;text-decoration:none}.entry-content a{border-bottom:1px solid #169fe6}:focus{outline:0}ul{padding:0;margin:0}li{list-style-type:none}em{font-style:italic}cite{font-style:normal}iframe,img{max-width:100%}img{display:block;height:auto}p{padding:0;margin:0 0 24px}@media (min-width:640px){p{margin:0 0 32px}}h1,h2,h3,h4{margin:0 0 30px;font-family:proxima-nova,sans-serif;font-weight:700}h4 a{color:#169fe6}h1{line-height:1.06;letter-spacing:-.5px;font-size:40px}@media (min-width:640px){h1{font-size:48px}}@media (min-width:880px){h1{font-size:54px}}@media (min-width:1200px){h1{font-size:62px}}@media (min-width:880px){h1{letter-spacing:-1.5px}}@media (min-width:1200px){h1{letter-spacing:-2.5px}}h2{line-height:1.5;letter-spacing:-.5px;font-size:28px}@media (min-width:640px){h2{font-size:32px}}@media (min-width:880px){h2{font-size:36px}}@media (min-width:1200px){h2{font-size:40px}}@media (min-width:880px){h2{letter-spacing:-1px}}h3{line-height:1.25;font-size:26px}@media (min-width:640px){h3{font-size:28px}}@media (min-width:880px){h3{font-size:30px}}@media (min-width:1200px){h3{font-size:32px}}h4{line-height:1.25;font-size:20px}@media (min-width:640px){h4{font-size:22px}}@media (min-width:880px){h4{font-size:22px}}@media (min-width:1200px){h4{font-size:24px}}.site-container{overflow-x:hidden;word-wrap:break-word}.site-inner{padding:24px 0;margin:0 auto;clear:both}@media (min-width:640px){.site-inner{padding:30px 0}}@media (min-width:880px){.site-inner{padding:48px 0}}@media (min-width:1200px){.site-inner{padding:60px 0}}.wrap{width:auto;max-width:100%;margin:0 16px}.wrap::before{display:table;content:" "}.wrap::after{display:table;clear:both;content:""}@media (min-width:640px){.wrap{margin:0 24px}}@media (min-width:880px){.wrap{margin:0 50px}}@media (min-width:1200px){body .wrap{max-width:1110px;margin:0 auto}}@media (min-width:920px){.site-header{width:100%;padding:20px 0 10px}}@media (max-width:920px){.site-header>.wrap{margin:0 10px}}.title-area{position:relative;z-index:99999;float:left;padding:14px 0}@media (min-width:880px){.title-area{padding:8px 0}}.site-title{margin-bottom:0;font-weight:900;line-height:1;text-indent:-9999px;text-transform:uppercase;letter-spacing:2px;font-size:24px}@media (min-width:640px){.site-title{font-size:24px}}@media (min-width:880px){.site-title{font-size:30px}}@media (min-width:1200px){.site-title{font-size:30px}}.site-title a{display:block;width:140px;height:30px;background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/logo-mobile.png) no-repeat center center;background-size:contain}@media (min-width:400px){.site-title a{width:173px;height:36px}}@media (min-width:920px){.site-title a{width:220px;height:47px;margin-top:21px}}@media (min-width:1058px){.site-title a{width:348px;height:64px;margin-top:0;background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/logo.png) no-repeat center center;background-size:contain}}.site-title a{color:#484848;text-decoration:none}.site-description{position:absolute!important;width:1px;height:1px;overflow:hidden;clip:rect(0,0,0,0);word-wrap:normal!important;border:0}.content{max-width:100%;margin:0 auto}@media (min-width:880px){.content{float:left;width:72%;max-width:730px}}.sidebar{max-width:730px;margin:0 auto}@media (min-width:880px){.sidebar{float:right;width:25%}}.sidebar{font-size:16px;line-height:1.5}.sidebar p{margin-bottom:20px}.sidebar__block-title{font-size:20px;line-height:28px}.sidebar__block-content{margin-top:10px;margin-bottom:10px;font-size:14px;line-height:24px}.sidebar .widget{padding:24px;margin-bottom:10px;background-color:#f4f6fa}.sidebar__block{display:flex;flex-direction:column;align-items:center;justify-content:center;text-align:center}.sidebar__block h4{padding:0;margin:0}.sidebar__block h4 a{font-weight:700;color:#051e50;text-decoration:none}.sidebar__block img{margin-bottom:22px;box-shadow:0 15px 30px rgba(0,0,0,.08),0 10px 15px rgba(0,0,0,.12)}.sidebar__block a img{margin-bottom:0}.sidebar__block>:first-child{margin-bottom:20px}.entry-content>*{max-width:100%;margin:16px 0}@media (min-width:880px){.entry-content>*{margin:22px 0}}@media (min-width:1200px){.entry-content>*{margin:24px 0}}.entry-content>:first-child{margin-top:0}.entry-content>:last-child{margin-bottom:0}.pyi-page-hero{position:relative;padding:20px 0 50px}@media (min-width:880px){.pyi-page-hero{padding:60px 0 80px}}.pyi-page-hero::after{position:absolute;bottom:0;width:100%;height:100px;content:'';background-image:url(https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/wave.png?lossy=1&strip=1&webp=1);background-repeat:repeat-x;background-position:top center;background-size:cover}.single-post .pyi-page-hero::after{display:none;content:none}.pyi-page-hero>.wrap{position:relative}.pyi-page-hero .pyi-hero-left{position:absolute;top:20px;left:-290px;z-index:-1;width:250px;height:250px;background-image:url(https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/hero_bg_left.png?lossy=1&strip=1&webp=1);background-repeat:no-repeat;background-position:top center;background-size:contain}.pyi-page-hero .pyi-hero-right{position:absolute;top:-80px;right:-200px;z-index:-1;z-index:-1;width:400px;height:500px;background-image:url(https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/hero_bg_right.png?lossy=1&strip=1&webp=1);background-repeat:no-repeat;background-position:top center;background-size:contain}@media (max-width:879px){.pyi-page-hero .pyi-hero-right{display:none}}.pyi-page-hero .entry-title{max-width:730px}@media (min-width:640px){.footer-cta{display:flex;align-items:center}}.footer-cta input{width:100%;margin-bottom:5px;line-height:1.5;text-align:center;border:2px #6dc713 solid}@media (min-width:640px){.footer-cta input{width:52%;margin-bottom:0;line-height:1.15;text-align:left}}.footer-cta button{width:100%;padding:16px 14px 14px;font-weight:600;line-height:30px;color:#fff;text-align:center;text-transform:uppercase;letter-spacing:1.5px;background-color:#6dc713;border:none;font-size:16px}@media (min-width:640px){.footer-cta button{width:48%}}@media (min-width:1023px){.footer-cta button{padding:17px 14px 16px}}@media (min-width:640px){.footer-cta button{font-size:18px}}@media (min-width:880px){.footer-cta button{font-size:16px}}@media (min-width:1200px){.footer-cta button{font-size:16px}}::-moz-placeholder{color:#4d5a75;opacity:1}::-webkit-input-placeholder{color:#4d5a75}input,textarea{width:100%;padding:20px 24px 16px;font-weight:400;color:#051e50;background-color:#fff;border:2px solid #f4f6fa;font-size:16px}@media (min-width:640px){input,textarea{font-size:18px}}@media (min-width:880px){input,textarea{font-size:20px}}@media (min-width:1200px){input,textarea{font-size:20px}}input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-results-button{display:none}.search-form{position:relative;max-width:400px;overflow:hidden;border:1px solid #f4f6fa}.search-form .search-field{padding-right:32px;border:none}.search-form .search-submit{position:absolute;top:51%;right:32px;width:24px;min-width:0;height:24px;padding:0;margin:0;margin-top:-12px;text-align:center;background:0 0;border:none}.search-form .search-submit svg{fill:#169fe6}.nav-primary ul{width:100%;margin:0;clear:both;line-height:1}.nav-primary .menu-item{position:relative;float:left;list-style:none}.nav-primary .menu-item a{position:relative;display:block;font-weight:600;line-height:1;color:#051e50;text-decoration:none;border:none;font-size:18px}@media (min-width:640px){.nav-primary .menu-item a{font-size:18px}}@media (min-width:880px){.nav-primary .menu-item a{font-size:14px}}@media (min-width:1200px){.nav-primary .menu-item a{font-size:16px}}@media (max-width:920px){.nav-primary{position:absolute;right:10px;left:10px;z-index:999999;display:none;width:calc(100% - 20px);height:100%;padding:0;clear:both;background:#f4f6fa}.nav-primary .menu-primary{background-color:#051e50}}@media (min-width:921px){.nav-primary{float:right;width:auto}.nav-primary .menu>.menu-item.menu-item-has-children>a{padding-right:26px}.nav-primary .menu>.menu-item>a{padding:24px 12px;border-bottom:2px solid transparent}.nav-primary .menu>.menu-item>a span{padding-bottom:10px;border-bottom:2px solid transparent}.nav-primary .submenu-expand{position:absolute;top:50%;right:8px;margin-top:-5px;line-height:0}.nav-primary .submenu-expand svg{width:10px;height:10px}.nav-primary .sub-menu{position:absolute;left:-9999px;z-index:99;width:180px;background:#fff;box-shadow:0 15px 30px rgba(0,0,0,.08),0 10px 15px rgba(0,0,0,.12);opacity:0}.nav-primary .sub-menu .menu-item{float:none}.nav-primary .sub-menu .menu-item>a{padding:18px 16px 14px 16px;font-size:14px;border-bottom:1px solid #eceff5}}@media (min-width:1200px){.nav-primary .menu>.menu-item>a{padding:24px 16px}}.main-nav-wrap{display:block;float:right;width:auto}@media (min-width:920px){.main-nav-wrap{display:flex}}.nav-primary .is-topics>.sub-menu{width:auto;margin:0 32px 0 42px}@media (min-width:920px){.nav-primary .is-topics>.sub-menu{width:335px;margin-left:16px}}.nav-primary .is-topics .has-icon a{position:relative;padding-left:0}@media (min-width:920px){.nav-primary .is-topics .has-icon a{padding-left:42px}}.nav-primary .is-topics .has-icon a::before{position:absolute;top:13px;left:0;width:16px;height:16px;content:'';filter:brightness(0) invert(1)}@media (min-width:920px){.nav-primary .is-topics .has-icon a::before{top:16px;left:12px;width:16px;height:16px;filter:grayscale(1)}}.nav-primary .is-topics .has-icon.has-icon--deep-learning a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-deeplearning.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--dlib a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-dlib.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--iot a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-iot.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--face a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-face.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--image a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-image.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--interviews a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-interviews.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--keras a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-keras.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--ml a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-ml.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--medical a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-medical.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--ocr a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-ocr.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--object-detection a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-object_detection.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--object-tracking a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-object_tracking.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--opencv a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-opencv.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--pi a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-pi.png) no-repeat center center;background-size:contain}.nav-secondary{display:none;float:right;margin-top:10px}@media (min-width:920px){.nav-secondary{display:block}}.nav-secondary .wrap{margin:0}.nav-secondary ul{width:100%;margin:0;clear:both;line-height:1}.nav-secondary .menu-item{position:relative;float:left;margin-left:28px;list-style:none}@media (min-width:1200px){.nav-secondary .menu-item{margin-left:36px}}.nav-secondary .menu-item a{position:relative;display:block;font-size:16px;font-weight:400;color:#4d5a75;text-decoration:none;border:none;font-size:14px}@media (min-width:640px){.nav-secondary .menu-item a{font-size:14px}}@media (min-width:880px){.nav-secondary .menu-item a{font-size:15px 16px}}.nav-mobile{float:right;width:auto}@media (min-width:921px){.nav-mobile{display:none}}.mobile-menu-toggle{display:block;width:100%;padding:12px 20px 10px;margin-top:14px;font-size:13px;font-weight:700;text-transform:uppercase;letter-spacing:1px;background-color:#eceff5;border:none}.mobile-menu-toggle svg{margin:-2px 10px 0 0;fill:#051e50}.mobile-menu-toggle svg{vertical-align:middle}.mobile-menu-toggle .menu-close,.mobile-menu-toggle .mobile-menu-close{display:none}.header-search{position:relative;display:block;float:right;width:auto;margin:0 auto}@media (max-width:919px){.header-search ::-moz-placeholder{color:#4d5a75;opacity:1}.header-search ::-webkit-input-placeholder{color:#4d5a75}}.header-search input{margin-bottom:0}.header-search ::-moz-placeholder{color:#4d5a75;opacity:1}.header-search ::-webkit-input-placeholder{color:#4d5a75}.header-search .search-form{position:relative;z-index:99999;display:none;display:none;width:100%;margin:0 auto}.header-search .search-submit svg{fill:#169fe6}@media (min-width:920px){.header-search .search-submit svg{fill:#169fe6}}.header-search .mobile-search-toggle{display:block;padding:8px 11px 8px;margin:14px 0 0 4px;background-color:#169fe6;border:none;opacity:1}@media (min-width:920px){.header-search .mobile-search-toggle{position:relative;display:block;float:right;padding:11px 14px 7px;margin:6px -6px 0 16px;background-color:#169fe6}}@media (min-width:1200px){.header-search .mobile-search-toggle{padding:10px 19px 5px 17px;margin:12px 0 0 16px}}.header-search .mobile-search-toggle svg{fill:#fff;width:14px;height:14px;margin-top:calc((14px - 14px)/ 2)}@media (min-width:920px){.header-search .mobile-search-toggle svg{fill:#fff;width:16px;height:16px;margin-top:calc((16px - 16px)/ 2)}}.header-search .mobile-search-toggle .search-close{display:none}.nav-primary .mobile-only{display:block}@media (min-width:920px){.nav-primary .mobile-only{display:none}}.entry-content code{background-color:#f5f5f5}blockquote{font-style:italic;text-align:left;background:0 0}blockquote p{font-weight:400;line-height:1.5;color:#051e50}blockquote cite{display:block;margin-top:20px;font-weight:700;color:#4d5a75;font-size:16px}@media (min-width:640px){blockquote cite{font-size:18px}}blockquote cite .cite-title{display:block;font-weight:400}blockquote p:last-of-type{margin-bottom:0}blockquote::before{position:relative;top:-37px;left:-51px;display:block;height:0;font-size:90px;color:#169fe6;content:'\201C'}@media (min-width:640px){blockquote::before{top:-48px;left:-61px;font-size:110px}}@media (min-width:880px){blockquote::before{top:-48px;left:-55px;font-size:110px}}@media (min-width:1200px){blockquote::before{top:-58px;left:-71px;font-size:120px}}p.entry-meta{margin-bottom:0;font-size:14px}@media (min-width:640px){p.entry-meta{font-size:15px}}@media (min-width:880px){p.entry-meta{font-size:16px}}@media (min-width:1200px){p.entry-meta{font-size:16px}}.entry-categories{display:block}.widget{margin-bottom:60px}.widget a{font-weight:400;color:#4d5a75;text-decoration:underline}.modal{position:relative;z-index:2;box-sizing:border-box;display:none;width:90%;max-width:500px;padding:15px 30px;text-align:left;vertical-align:middle;background:#fff;border-radius:8px;box-shadow:0 0 10px #000;-webkit-border-radius:8px;-moz-border-radius:8px;-o-border-radius:8px;-ms-border-radius:8px;-webkit-box-shadow:0 0 10px #000;-moz-box-shadow:0 0 10px #000;-o-box-shadow:0 0 10px #000;-ms-box-shadow:0 0 10px #000}.modal a.close-modal{position:absolute;top:-12.5px;right:-12.5px;display:block;width:30px;height:30px;text-indent:-9999px;background-repeat:no-repeat;background-position:center center;background-size:contain}.front-page-modal.modal{width:96%;max-width:1110px;padding:20px 20px;border-radius:0}@media (min-width:640px){.front-page-modal.modal{padding:40px 40px}}@media (min-width:880px){.front-page-modal.modal{padding:50px 60px}}@media (min-width:1200px){.front-page-modal.modal{padding:60px 80px}}.front-page-modal.modal p{margin-bottom:24px;font-size:16px}@media (min-width:640px){.front-page-modal.modal p{font-size:18px}}@media (min-width:880px){.front-page-modal.modal p{font-size:18px}}.front-page-modal.modal .front-modal-top{text-align:center}.front-page-modal.modal .front-modal-top h3{margin-bottom:20px;line-height:1.4;font-size:24px}@media (min-width:640px){.front-page-modal.modal .front-modal-top h3{font-size:28px}}@media (min-width:880px){.front-page-modal.modal .front-modal-top h3{font-size:32px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-top h3{font-size:40px}}@media (min-width:880px){.front-page-modal.modal .front-modal-top h3{margin-bottom:40px}}.front-page-modal.modal .front-modal-action{max-width:730px;margin:20px auto}@media (min-width:880px){.front-page-modal.modal .front-modal-action{margin:40px auto}}.front-page-modal.modal .front-modal-action .footer-cta{display:block}@media (min-width:880px){.front-page-modal.modal .front-modal-action .footer-cta{display:flex}}@media (max-width:879px){.front-page-modal.modal .front-modal-action .footer-cta button,.front-page-modal.modal .front-modal-action .footer-cta input{width:100%;margin-bottom:4px;text-align:center}}.front-page-modal.modal .front-modal-video{display:grid;margin:30px auto 30px;grid-gap:30px;grid-template-columns:1fr}@media (min-width:880px){.front-page-modal.modal .front-modal-video{max-width:920px;margin:50px auto 60px;grid-template-columns:1fr 1fr;grid-gap:50px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-video{margin:60px auto 80px;grid-gap:80px}}.front-page-modal.modal .front-modal-testimonial{padding:24px 30px;margin:0 -20px -24px -20px;background-color:#f4f6fa}@media (min-width:640px){.front-page-modal.modal .front-modal-testimonial{padding:40px 50px;margin:0 -40px -40px -40px}}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial{padding:50px 60px;margin:0 -60px -50px -60px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-testimonial{padding:66px 80px;margin:0 -80px -60px -80px}}.front-page-modal.modal .front-modal-testimonial blockquote{max-width:730px;margin:0 auto 0 40px}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial blockquote{margin:0 auto}}.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:16px}@media (min-width:640px){.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:18px}}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:18px}}.front-page-modal.modal .front-modal-testimonial blockquote cite{margin-top:30px}.front-page-modal ul.is-style-list-checks li{position:relative;padding-left:40px;margin-bottom:15px;font-size:18px;font-weight:600;list-style-type:none}.front-page-modal ul.is-style-list-checks li::before{position:absolute;top:4px;left:0;width:20px;height:20px;content:'';background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/checks_blue.png) no-repeat center center;background-size:contain}.front-page-modal a.close-modal{background-color:#000}.single-post .pyi-page-hero .entry-meta{font-style:italic;color:#4d5a75}.single-post .pyi-page-hero .entry-meta .entry-author,.single-post .pyi-page-hero .entry-meta .entry-time{font-style:normal;font-weight:600}.single-post .pyi-page-hero .entry-meta .entry-categories{font-style:normal}.single-post .pyi-page-hero{padding-bottom:0}.single-post .pyi-page-hero .entry-title{max-width:730px;margin-bottom:20px}.single-post .entry-categories{margin-bottom:20px}.single-post .entry-categories a{display:inline-block;padding:6px 8px;margin-bottom:4px;font-size:13px;line-height:1;color:#4d5a75;text-transform:uppercase;letter-spacing:1px;background-color:#f4f6fa}@media (min-width:880px){.single-post .entry-categories a{margin-bottom:0}}.single-post .site-inner{padding-top:30px}.screen-reader-shortcut,.screen-reader-text{position:absolute!important;width:1px;height:1px;overflow:hidden;clip:rect(0,0,0,0);word-wrap:normal!important;border:0}.genesis-skip-link{margin:0}.genesis-skip-link li{width:0;height:0;list-style:none}.grecaptcha-badge{display:none!important}.enlighter-default .enlighter-raw{display:none;min-width:100%;line-height:inherit;font-size:1em;font-family:inherit;margin:0;padding:0;white-space:pre-wrap;word-wrap:break-word;border:none;box-shadow:none}.enlighter-default .enlighter-btn{display:inline-block;margin:0 5px 0 5px;padding:3px 5px 3px 5px;border:solid 1px #333;background-color:#f0f0f0;font-family:inherit}.enlighter-default .enlighter-toolbar .enlighter-btn-raw{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3C!DOCTYPE%20svg%20PUBLIC%20%22-%2F%2FW3C%2F%2FDTD%20SVG%201.1%2F%2FEN%22%20%22http%3A%2F%2Fwww.w3.org%2FGraphics%2FSVG%2F1.1%2FDTD%2Fsvg11.dtd%22%3E%0D%0A%3Csvg%20version%3D%221.1%22%20id%3D%22Ebene_2%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20x%3D%220px%22%20y%3D%220px%22%0D%0A%09%20width%3D%2246px%22%20height%3D%2246px%22%20viewBox%3D%220%200%2046%2046%22%20enable-background%3D%22new%200%200%2046%2046%22%20xml%3Aspace%3D%22preserve%22%3E%0D%0A%3Cg%3E%0D%0A%09%3Cpath%20d%3D%22M19.436%2C36.875L6.568%2C25.002v-3.863L19.436%2C9.267v5.041l-9.583%2C8.668v0.188l9.583%2C8.669V36.875z%22%2F%3E%0D%0A%09%3Cpath%20d%3D%22M26.343%2C36.875v-5.041l9.583-8.669v-0.188l-9.583-8.668V9.267l12.868%2C11.872v3.863L26.343%2C36.875z%22%2F%3E%0D%0A%3C%2Fg%3E%0D%0A%3C%2Fsvg%3E%0D%0A)}.enlighter-default .enlighter-toolbar .enlighter-btn-copy{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3C!DOCTYPE%20svg%20PUBLIC%20%22-%2F%2FW3C%2F%2FDTD%20SVG%201.1%2F%2FEN%22%20%22http%3A%2F%2Fwww.w3.org%2FGraphics%2FSVG%2F1.1%2FDTD%2Fsvg11.dtd%22%3E%0D%0A%3Csvg%20version%3D%221.1%22%20id%3D%22Ebene_2%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20x%3D%220px%22%20y%3D%220px%22%0D%0A%09%20width%3D%2246px%22%20height%3D%2246px%22%20viewBox%3D%220%200%2046%2046%22%20enable-background%3D%22new%200%200%2046%2046%22%20xml%3Aspace%3D%22preserve%22%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%2253.75%22%20y1%3D%2239.353%22%20x2%3D%2286.375%22%20y2%3D%2239.353%22%2F%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%2251.711%22%20y1%3D%2230.534%22%20x2%3D%2284.336%22%20y2%3D%2230.534%22%2F%3E%0D%0A%3Crect%20x%3D%228.932%22%20y%3D%227.334%22%20fill%3D%22%23FFFFFF%22%20stroke%3D%22%23000000%22%20stroke-width%3D%223%22%20stroke-miterlimit%3D%2210%22%20width%3D%2221.097%22%20height%3D%2224.952%22%2F%3E%0D%0A%3Crect%20x%3D%2218.942%22%20y%3D%2215.424%22%20fill%3D%22%23FFFFFF%22%20stroke%3D%22%23000000%22%20stroke-width%3D%223%22%20stroke-miterlimit%3D%2210%22%20width%3D%2221.096%22%20height%3D%2224.953%22%2F%3E%0D%0A%3C%2Fsvg%3E%0D%0A)}.enlighter-default .enlighter-toolbar .enlighter-btn-window{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3C!DOCTYPE%20svg%20PUBLIC%20%22-%2F%2FW3C%2F%2FDTD%20SVG%201.1%2F%2FEN%22%20%22http%3A%2F%2Fwww.w3.org%2FGraphics%2FSVG%2F1.1%2FDTD%2Fsvg11.dtd%22%3E%0D%0A%3Csvg%20version%3D%221.1%22%20id%3D%22Ebene_2%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20x%3D%220px%22%20y%3D%220px%22%0D%0A%09%20width%3D%2246px%22%20height%3D%2246px%22%20viewBox%3D%220%200%2046%2046%22%20enable-background%3D%22new%200%200%2046%2046%22%20xml%3Aspace%3D%22preserve%22%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%227.125%22%20y1%3D%229.25%22%20x2%3D%2239.75%22%20y2%3D%229.25%22%2F%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%227.125%22%20y1%3D%2218.167%22%20x2%3D%2239.75%22%20y2%3D%2218.167%22%2F%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%227.125%22%20y1%3D%2227.083%22%20x2%3D%2239.75%22%20y2%3D%2227.083%22%2F%3E%0D%0A%3Cline%20fill%3D%22none%22%20stroke%3D%22%23000000%22%20stroke-width%3D%224%22%20stroke-miterlimit%3D%2210%22%20x1%3D%227.125%22%20y1%3D%2236%22%20x2%3D%2229.809%22%20y2%3D%2236%22%2F%3E%0D%0A%3C%2Fsvg%3E%0D%0A)}.enlighter-default .enlighter-toolbar .enlighter-btn-website{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3C!DOCTYPE%20svg%20PUBLIC%20%22-%2F%2FW3C%2F%2FDTD%20SVG%201.1%2F%2FEN%22%20%22http%3A%2F%2Fwww.w3.org%2FGraphics%2FSVG%2F1.1%2FDTD%2Fsvg11.dtd%22%3E%0D%0A%3Csvg%20version%3D%221.1%22%20id%3D%22E%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20x%3D%220px%22%20y%3D%220px%22%0D%0A%09%20width%3D%2246px%22%20height%3D%2246px%22%20viewBox%3D%220%200%2046%2046%22%20enable-background%3D%22new%200%200%2046%2046%22%20xml%3Aspace%3D%22preserve%22%3E%0D%0A%3Cg%3E%0D%0A%09%3Cpath%20fill%3D%22%23202F65%22%20d%3D%22M32.48%2C25.614H19.64l-4.933%2C9.826l17.746%2C0.037l-6.173%2C5.358L8.167%2C40.912L16.29%2C6.055h22.974l-5.734%2C5.354%0D%0A%09%09l-13.306-0.027l0.672%2C8.797h12.841L32.48%2C25.614z%22%2F%3E%0D%0A%3C%2Fg%3E%0D%0A%3C%2Fsvg%3E%0D%0A)}.enlighter-origin{display:none!important}.enlighter-toolbar{display:none;position:absolute;right:10px;top:10px;z-index:10}.enlighter-toolbar-bottom{top:unset;bottom:0}html body{opacity:1!important}@font-face{font-family:proxima-nova;src:url("https://use.typekit.net/af/705e94/00000000000000003b9b3062/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n4&v=3") format("woff2");font-display:block;font-style:normal;font-weight:400}@font-face{font-family:proxima-nova;src:url("https://use.typekit.net/af/576d53/00000000000000003b9b3066/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n6&v=3") format("woff2");font-display:block;font-style:normal;font-weight:600}@font-face{font-family:proxima-nova;src:url("https://use.typekit.net/af/949f99/00000000000000003b9b3068/27/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n7&v=3") format("woff2");font-display:block;font-style:normal;font-weight:700}@font-face{font-family:'Bree Serif';font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/breeserif/v10/4UaHrEJCrhhnVA3DgluA96rp5w.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:300;src:url(https://fonts.gstatic.com/s/opensans/v20/mem5YaGs126MiZpBA-UN_r8OUuhp.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/opensans/v20/mem8YaGs126MiZpBA-UFVZ0b.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/opensans/v20/mem5YaGs126MiZpBA-UN7rgOUuhp.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:Muli;font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/muli/v22/7Auwp_0qiz-afTLGLQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:Roboto;font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmWUlfBBc4.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:Roboto;font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fBBc4.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:Roboto;font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu4mxK.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}.nav-mobile{float:right;width:auto}</style><style id="avlabs-rocket-critical-css">:root{--wp-admin-theme-color:#007cba;--wp-admin-theme-color-darker-10:#006ba1;--wp-admin-theme-color-darker-20:#005a87}.sticky{position:relative;z-index:0;-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0)}.sticky.is-anchored{position:relative;right:auto;left:auto}#pyis-cta-modal-sticky-bar{margin:1.25rem 0}#pyis-cta-modal-sticky-bar .grid-container{padding-right:.625rem;padding-left:.625rem;max-width:75rem;margin-left:auto;margin-right:auto}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-container{padding-right:.9375rem;padding-left:.9375rem}}#pyis-cta-modal-sticky-bar .grid-x{display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-flow:row wrap;-ms-flex-flow:row wrap;flex-flow:row wrap}#pyis-cta-modal-sticky-bar .cell{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;min-height:0;min-width:0;width:100%}#pyis-cta-modal-sticky-bar .grid-margin-x{margin-left:-.625rem;margin-right:-.625rem}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-margin-x{margin-left:-.9375rem;margin-right:-.9375rem}}#pyis-cta-modal-sticky-bar .grid-margin-x>.cell{width:calc(100% - 1.25rem);margin-left:.625rem;margin-right:.625rem}@media print,screen and (min-width:40em){#pyis-cta-modal-sticky-bar .grid-margin-x>.cell{width:calc(100% - 1.875rem);margin-left:.9375rem;margin-right:.9375rem}}#pyis-cta-modal-sticky-bar .text-center{text-align:center}#pyis-cta-modal-sticky-bar .sticky{background-color:#051e50;color:#fefefe;padding:1.625rem 1rem 1.25rem 1.625rem}#pyis-cta-modal-sticky-bar .sticky a{background:0 0;outline:0;font-size:1.2rem;padding:0;border-bottom:none;color:#fefefe;text-decoration:underline;position:relative}#pyis-cta-modal-sticky-bar .sticky a:before{position:absolute;top:-.5625rem;left:-3.75rem;display:block;width:2.5rem;height:2.5rem;content:'';background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/source_code_mini_image.png);background-size:contain}#pyis-cta-modal .modal-content{margin-top:1.5rem}#pyis-cta-modal .optin-modal-content .pyuni-logo{padding-bottom:20px;max-width:400px}#pyis-cta-modal .optin-modal-content h3{margin-bottom:20px;font-size:24px}#pyis-cta-modal .optin-modal-content .is-style-list-checks li{font-weight:400}button,input{overflow:visible}html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{margin:0.67em 0;font-size:2em}a{background-color:transparent}strong{font-weight:bolder}img{border-style:none}button,input{margin:0;font-family:inherit;font-size:100%;line-height:1.15}button{text-transform:none}[type='submit'],button{-webkit-appearance:button}[type='submit']::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}[type='submit']:-moz-focusring,button:-moz-focusring{outline:ButtonText dotted 1px}[type='search']{outline-offset:-2px;-webkit-appearance:textfield}[type='search']::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}html{box-sizing:border-box}*,*,*:after{box-sizing:inherit}.entry::before,.entry-content::before,.nav-primary::before,.nav-secondary::before,.site-container::before,.site-header::before,.site-inner::before,.widget::before,.wrap::before{display:table;content:" "}.entry::after,.entry-content::after,.nav-primary::after,.nav-secondary::after,.site-container::after,.site-header::after,.site-inner::after,.widget::after,.wrap::after{display:table;clear:both;content:""}html,input[type='search']{box-sizing:border-box}*,*:before,*:after{box-sizing:inherit}html{overflow-y:scroll;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}body{margin:0;font-family:proxima-nova,sans-serif;font-weight:400;line-height:1.472;color:#051e50;font-size:17px}@media (min-width:640px){body{line-height:1.52}}@media (min-width:880px){body{line-height:1.568}}@media (min-width:1200px){body{line-height:1.6}}@media (min-width:640px){body{font-size:19px}}@media (min-width:880px){body{font-size:20px}}a{font-weight:700;color:#169fe6;text-decoration:none}.entry-content a{border-bottom:1px solid #169fe6}:focus{outline:none}ul{padding:0;margin:0}li{list-style-type:none}em{font-style:italic}cite{font-style:normal}img{max-width:100%}img{display:block;height:auto}p{padding:0;margin:0 0 24px}@media (min-width:640px){p{margin:0 0 32px}}h1,h2,h3,h4{margin:0 0 30px;font-family:proxima-nova,sans-serif;font-weight:700}h4 a{color:#169fe6}h1{line-height:1.06;letter-spacing:-0.5px;font-size:40px}@media (min-width:640px){h1{font-size:48px}}@media (min-width:880px){h1{font-size:54px}}@media (min-width:1200px){h1{font-size:62px}}@media (min-width:880px){h1{letter-spacing:-1.5px}}@media (min-width:1200px){h1{letter-spacing:-2.5px}}h2{line-height:1.5;letter-spacing:-0.5px;font-size:28px}@media (min-width:640px){h2{font-size:32px}}@media (min-width:880px){h2{font-size:36px}}@media (min-width:1200px){h2{font-size:40px}}@media (min-width:880px){h2{letter-spacing:-1px}}h3{line-height:1.25;font-size:26px}@media (min-width:640px){h3{font-size:28px}}@media (min-width:880px){h3{font-size:30px}}@media (min-width:1200px){h3{font-size:32px}}h4{line-height:1.25;font-size:20px}@media (min-width:640px){h4{font-size:22px}}@media (min-width:880px){h4{font-size:22px}}@media (min-width:1200px){h4{font-size:24px}}.site-container{overflow-x:hidden;word-wrap:break-word}.site-inner{padding:24px 0;margin:0 auto;clear:both}@media (min-width:640px){.site-inner{padding:30px 0}}@media (min-width:880px){.site-inner{padding:48px 0}}@media (min-width:1200px){.site-inner{padding:60px 0}}.wrap{width:auto;max-width:100%;margin:0 16px}.wrap::before{display:table;content:" "}.wrap::after{display:table;clear:both;content:""}@media (min-width:640px){.wrap{margin:0 24px}}@media (min-width:880px){.wrap{margin:0 50px}}@media (min-width:1200px){.wrap{max-width:1110px;margin:0 auto}}@media (min-width:920px){.site-header{width:100%;padding:20px 0 10px}}@media (max-width:920px){.site-header>.wrap{margin:0 10px}}.title-area{position:relative;z-index:99999;float:left;padding:14px 0}@media (min-width:880px){.title-area{padding:8px 0}}.site-title{margin-bottom:0;font-weight:900;line-height:1;text-indent:-9999px;text-transform:uppercase;letter-spacing:2px;font-size:24px}@media (min-width:640px){.site-title{font-size:24px}}@media (min-width:880px){.site-title{font-size:30px}}@media (min-width:1200px){.site-title{font-size:30px}}.site-title a{display:block;width:140px;height:30px;background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/logo-mobile.png) no-repeat center center;background-size:contain}@media (min-width:400px){.site-title a{width:173px;height:36px}}@media (min-width:920px){.site-title a{width:220px;height:47px;margin-top:21px}}@media (min-width:1058px){.site-title a{width:348px;height:64px;margin-top:0;background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/logo.png) no-repeat center center;background-size:contain}}.site-title a{color:#484848;text-decoration:none}.site-description{position:absolute!important;width:1px;height:1px;overflow:hidden;clip:rect(0,0,0,0);word-wrap:normal!important;border:0}.content{max-width:100%;margin:0 auto}@media (min-width:880px){.content{float:left;width:72%;max-width:730px}}.sidebar{max-width:730px;margin:0 auto}@media (min-width:880px){.sidebar{float:right;width:25%}}.sidebar{font-size:16px;line-height:1.5}.sidebar p{margin-bottom:20px}.sidebar__block-title{font-size:20px;line-height:28px}.sidebar__block-content{margin-top:10px;margin-bottom:10px;font-size:14px;line-height:24px}.sidebar .widget{padding:24px;margin-bottom:10px;background-color:#f4f6fa}.sidebar__block{display:flex;flex-direction:column;align-items:center;justify-content:center;text-align:center}.sidebar__block h4{padding:0;margin:0}.sidebar__block h4 a{font-weight:700;color:#051e50;text-decoration:none}.sidebar__block img{margin-bottom:22px;box-shadow:0 15px 30px rgba(0,0,0,0.08),0 10px 15px rgba(0,0,0,0.12)}.sidebar__block a img{margin-bottom:0}.sidebar__block>:first-child{margin-bottom:20px}.entry-content>*{max-width:100%;margin:16px 0}@media (min-width:880px){.entry-content>*{margin:22px 0}}@media (min-width:1200px){.entry-content>*{margin:24px 0}}.entry-content>*:first-child{margin-top:0}.pyi-page-hero{position:relative;padding:20px 0 50px}@media (min-width:880px){.pyi-page-hero{padding:60px 0 80px}}.pyi-page-hero::after{position:absolute;bottom:0;width:100%;height:100px;content:'';background-image:url(https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/wave.png?lossy=1&strip=1&webp=1);background-repeat:repeat-x;background-position:top center;background-size:cover}.single-post .pyi-page-hero::after{display:none;content:none}.pyi-page-hero>.wrap{position:relative}.pyi-page-hero .pyi-hero-left{position:absolute;top:20px;left:-290px;z-index:-1;width:250px;height:250px;background-image:url(https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/hero_bg_left.png?lossy=1&strip=1&webp=1);background-repeat:no-repeat;background-position:top center;background-size:contain}.pyi-page-hero .pyi-hero-right{position:absolute;top:-80px;right:-200px;z-index:-1;z-index:-1;width:400px;height:500px;background-image:url(https://929687.smushcdn.com/2633864/wp-content/themes/pyi/assets/images/hero_bg_right.png?lossy=1&strip=1&webp=1);background-repeat:no-repeat;background-position:top center;background-size:contain}@media (max-width:879px){.pyi-page-hero .pyi-hero-right{display:none}}.pyi-page-hero .entry-title{max-width:730px}@media (min-width:640px){.footer-cta{display:flex;align-items:center}}.footer-cta input{width:100%;margin-bottom:5px;line-height:1.5;text-align:center;border:2px #6dc713 solid}@media (min-width:640px){.footer-cta input{width:52%;margin-bottom:0;line-height:1.15;text-align:left}}.footer-cta button{width:100%;padding:16px 14px 14px;font-weight:600;line-height:30px;color:#fff;text-align:center;text-transform:uppercase;letter-spacing:1.5px;background-color:#6dc713;border:none;font-size:16px}@media (min-width:640px){.footer-cta button{width:48%}}@media (min-width:1023px){.footer-cta button{padding:17px 14px 16px}}@media (min-width:640px){.footer-cta button{font-size:18px}}@media (min-width:880px){.footer-cta button{font-size:16px}}@media (min-width:1200px){.footer-cta button{font-size:16px}}::-moz-placeholder{color:#4d5a75;opacity:1}::-webkit-input-placeholder{color:#4d5a75}input{width:100%;padding:20px 24px 16px;font-weight:400;color:#051e50;background-color:#fff;border:2px solid #f4f6fa;font-size:16px}@media (min-width:640px){input{font-size:18px}}@media (min-width:880px){input{font-size:20px}}@media (min-width:1200px){input{font-size:20px}}input[type='search']::-webkit-search-cancel-button,input[type='search']::-webkit-search-results-button{display:none}.search-form{position:relative;max-width:400px;overflow:hidden;border:1px solid #f4f6fa}.search-form .search-field{padding-right:32px;border:none}.search-form .search-submit{position:absolute;top:51%;right:32px;width:24px;min-width:0;height:24px;padding:0;margin:0;margin-top:-12px;text-align:center;background:transparent;border:none}.search-form .search-submit svg{fill:#169fe6}.nav-primary ul{width:100%;margin:0;clear:both;line-height:1}.nav-primary .menu-item{position:relative;float:left;list-style:none}.nav-primary .menu-item a{position:relative;display:block;font-weight:600;line-height:1;color:#051e50;text-decoration:none;border:none;font-size:18px}@media (min-width:640px){.nav-primary .menu-item a{font-size:18px}}@media (min-width:880px){.nav-primary .menu-item a{font-size:14px}}@media (min-width:1200px){.nav-primary .menu-item a{font-size:16px}}@media (max-width:920px){.nav-primary{position:absolute;right:10px;left:10px;z-index:999999;display:none;width:calc(100% - 20px);height:100%;padding:0;clear:both;background:#f4f6fa}.nav-primary .menu-primary{background-color:#051e50}}@media (min-width:921px){.nav-primary{float:right;width:auto}.nav-primary .menu>.menu-item.menu-item-has-children>a{padding-right:26px}.nav-primary .menu>.menu-item>a{padding:24px 12px;border-bottom:2px solid transparent}.nav-primary .menu>.menu-item>a span{padding-bottom:10px;border-bottom:2px solid transparent}.nav-primary .submenu-expand{position:absolute;top:50%;right:8px;margin-top:-5px;line-height:0}.nav-primary .submenu-expand svg{width:10px;height:10px}.nav-primary .sub-menu{position:absolute;left:-9999px;z-index:99;width:180px;background:#fff;box-shadow:0 15px 30px rgba(0,0,0,0.08),0 10px 15px rgba(0,0,0,0.12);opacity:0}.nav-primary .sub-menu .menu-item{float:none}.nav-primary .sub-menu .menu-item>a{padding:18px 16px 14px 16px;font-size:14px;border-bottom:1px solid #eceff5}}@media (min-width:1200px){.nav-primary .menu>.menu-item>a{padding:24px 16px}}.main-nav-wrap{display:block;float:right;width:auto}@media (min-width:920px){.main-nav-wrap{display:flex}}.nav-primary .is-topics>.sub-menu{width:auto;margin:0 32px 0 42px}@media (min-width:920px){.nav-primary .is-topics>.sub-menu{width:335px;margin-left:16px}}.nav-primary .is-topics .has-icon a{position:relative;padding-left:0px}@media (min-width:920px){.nav-primary .is-topics .has-icon a{padding-left:42px}}.nav-primary .is-topics .has-icon a::before{position:absolute;top:13px;left:0;width:16px;height:16px;content:'';filter:brightness(0) invert(1)}@media (min-width:920px){.nav-primary .is-topics .has-icon a::before{top:16px;left:12px;width:16px;height:16px;filter:grayscale(1)}}.nav-primary .is-topics .has-icon.has-icon--deep-learning a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-deeplearning.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--dlib a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-dlib.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--iot a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-iot.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--face a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-face.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--image a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-image.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--interviews a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-interviews.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--keras a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-keras.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--ml a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-ml.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--medical a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-medical.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--ocr a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-ocr.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--object-detection a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-object_detection.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--object-tracking a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-object_tracking.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--opencv a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-opencv.png) no-repeat center center;background-size:contain}.nav-primary .is-topics .has-icon.has-icon--pi a::before{background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/menu-icons/icon-pi.png) no-repeat center center;background-size:contain}.nav-secondary{display:none;float:right;margin-top:10px}@media (min-width:920px){.nav-secondary{display:block}}.nav-secondary .wrap{margin:0}.nav-secondary ul{width:100%;margin:0;clear:both;line-height:1}.nav-secondary .menu-item{position:relative;float:left;margin-left:28px;list-style:none}@media (min-width:1200px){.nav-secondary .menu-item{margin-left:36px}}.nav-secondary .menu-item a{position:relative;display:block;font-size:16px;font-weight:400;color:#4d5a75;text-decoration:none;border:none;font-size:14px}@media (min-width:640px){.nav-secondary .menu-item a{font-size:14px}}@media (min-width:880px){.nav-secondary .menu-item a{font-size:15px 16px}}.nav-mobile{float:right;width:auto}@media (min-width:921px){.nav-mobile{display:none}}.mobile-menu-toggle{display:block;width:100%;padding:12px 20px 10px;margin-top:14px;font-size:13px;font-weight:700;text-transform:uppercase;letter-spacing:1px;background-color:#eceff5;border:none}.mobile-menu-toggle svg{margin:-2px 10px 0 0;fill:#051e50}.mobile-menu-toggle svg{vertical-align:middle}.mobile-menu-toggle .menu-close,.mobile-menu-toggle .mobile-menu-close{display:none}.header-search{position:relative;display:block;float:right;width:auto;margin:0 auto}@media (max-width:919px){.header-search ::-moz-placeholder{color:#4d5a75;opacity:1}.header-search ::-webkit-input-placeholder{color:#4d5a75}}.header-search input{margin-bottom:0}.header-search ::-moz-placeholder{color:#4d5a75;opacity:1}.header-search ::-webkit-input-placeholder{color:#4d5a75}.header-search .search-form{position:relative;z-index:99999;display:none;display:none;width:100%;margin:0 auto}.header-search .search-submit svg{fill:#169fe6}@media (min-width:920px){.header-search .search-submit svg{fill:#169fe6}}.header-search .mobile-search-toggle{display:block;padding:8px 11px 8px;margin:14px 0 0 4px;background-color:#169fe6;border:none;opacity:1}@media (min-width:920px){.header-search .mobile-search-toggle{position:relative;display:block;float:right;padding:11px 14px 7px;margin:6px -6px 0 16px;background-color:#169fe6}}@media (min-width:1200px){.header-search .mobile-search-toggle{padding:10px 19px 5px 17px;margin:12px 0 0 16px}}.header-search .mobile-search-toggle svg{fill:#fff;width:14px;height:14px;margin-top:calc((14px - 14px) / 2)}@media (min-width:920px){.header-search .mobile-search-toggle svg{fill:#fff;width:16px;height:16px;margin-top:calc((16px - 16px) / 2)}}.header-search .mobile-search-toggle .search-close{display:none}.nav-primary .mobile-only{display:block}@media (min-width:920px){.nav-primary .mobile-only{display:none}}blockquote{font-style:italic;text-align:left;background:transparent}blockquote p{font-weight:400;line-height:1.5;color:#051e50}blockquote cite{display:block;margin-top:20px;font-weight:700;color:#4d5a75;font-size:16px}@media (min-width:640px){blockquote cite{font-size:18px}}blockquote cite .cite-title{display:block;font-weight:400}blockquote p:last-of-type{margin-bottom:0}blockquote::before{position:relative;top:-37px;left:-51px;display:block;height:0;font-size:90px;color:#169fe6;content:'\201C'}@media (min-width:640px){blockquote::before{top:-48px;left:-61px;font-size:110px}}@media (min-width:880px){blockquote::before{top:-48px;left:-55px;font-size:110px}}@media (min-width:1200px){blockquote::before{top:-58px;left:-71px;font-size:120px}}p.entry-meta{margin-bottom:0;font-size:14px}@media (min-width:640px){p.entry-meta{font-size:15px}}@media (min-width:880px){p.entry-meta{font-size:16px}}@media (min-width:1200px){p.entry-meta{font-size:16px}}.entry-categories{display:block}.widget{margin-bottom:60px}.widget a{font-weight:400;color:#4d5a75;text-decoration:underline}.modal{position:relative;z-index:2;box-sizing:border-box;display:none;width:90%;max-width:500px;padding:15px 30px;text-align:left;vertical-align:middle;background:#fff;border-radius:8px;box-shadow:0 0 10px #000;-webkit-border-radius:8px;-moz-border-radius:8px;-o-border-radius:8px;-ms-border-radius:8px;-webkit-box-shadow:0 0 10px #000;-moz-box-shadow:0 0 10px #000;-o-box-shadow:0 0 10px #000;-ms-box-shadow:0 0 10px #000}.modal a.close-modal{position:absolute;top:-12.5px;right:-12.5px;display:block;width:30px;height:30px;text-indent:-9999px;background-repeat:no-repeat;background-position:center center;background-size:contain}.front-page-modal.modal{width:96%;max-width:1110px;padding:20px 20px;border-radius:0}@media (min-width:640px){.front-page-modal.modal{padding:40px 40px}}@media (min-width:880px){.front-page-modal.modal{padding:50px 60px}}@media (min-width:1200px){.front-page-modal.modal{padding:60px 80px}}.front-page-modal.modal p{margin-bottom:24px;font-size:16px}@media (min-width:640px){.front-page-modal.modal p{font-size:18px}}@media (min-width:880px){.front-page-modal.modal p{font-size:18px}}.front-page-modal.modal .front-modal-top{text-align:center}.front-page-modal.modal .front-modal-top h3{margin-bottom:20px;line-height:1.4;font-size:24px}@media (min-width:640px){.front-page-modal.modal .front-modal-top h3{font-size:28px}}@media (min-width:880px){.front-page-modal.modal .front-modal-top h3{font-size:32px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-top h3{font-size:40px}}@media (min-width:880px){.front-page-modal.modal .front-modal-top h3{margin-bottom:40px}}.front-page-modal.modal .front-modal-action{max-width:730px;margin:20px auto}@media (min-width:880px){.front-page-modal.modal .front-modal-action{margin:40px auto}}.front-page-modal.modal .front-modal-action .footer-cta{display:block}@media (min-width:880px){.front-page-modal.modal .front-modal-action .footer-cta{display:flex}}@media (max-width:879px){.front-page-modal.modal .front-modal-action .footer-cta input,.front-page-modal.modal .front-modal-action .footer-cta button{width:100%;margin-bottom:4px;text-align:center}}.front-page-modal.modal .front-modal-video{display:grid;margin:30px auto 30px;grid-gap:30px;grid-template-columns:1fr}@media (min-width:880px){.front-page-modal.modal .front-modal-video{max-width:920px;margin:50px auto 60px;grid-template-columns:1fr 1fr;grid-gap:50px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-video{margin:60px auto 80px;grid-gap:80px}}.front-page-modal.modal .front-modal-testimonial{padding:24px 30px;margin:0 -20px -24px -20px;background-color:#f4f6fa}@media (min-width:640px){.front-page-modal.modal .front-modal-testimonial{padding:40px 50px;margin:0 -40px -40px -40px}}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial{padding:50px 60px;margin:0 -60px -50px -60px}}@media (min-width:1200px){.front-page-modal.modal .front-modal-testimonial{padding:66px 80px;margin:0 -80px -60px -80px}}.front-page-modal.modal .front-modal-testimonial blockquote{max-width:730px;margin:0 auto 0 40px}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial blockquote{margin:0 auto}}.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:16px}@media (min-width:640px){.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:18px}}@media (min-width:880px){.front-page-modal.modal .front-modal-testimonial blockquote p{font-size:18px}}.front-page-modal.modal .front-modal-testimonial blockquote cite{margin-top:30px}.front-page-modal ul.is-style-list-checks li{position:relative;padding-left:40px;margin-bottom:15px;font-size:18px;font-weight:600;list-style-type:none}.front-page-modal ul.is-style-list-checks li::before{position:absolute;top:4px;left:0;width:20px;height:20px;content:'';background:url(https://pyimagesearch.com/wp-content/themes/pyi/assets/images/checks_blue.png) no-repeat center center;background-size:contain}.front-page-modal a.close-modal{background-color:#000}.single-post .pyi-page-hero .entry-meta{font-style:italic;color:#4d5a75}.single-post .pyi-page-hero .entry-meta .entry-author,.single-post .pyi-page-hero .entry-meta .entry-time{font-style:normal;font-weight:600}.single-post .pyi-page-hero .entry-meta .entry-categories{font-style:normal}.single-post .pyi-page-hero{padding-bottom:0}.single-post .pyi-page-hero .entry-title{max-width:730px;margin-bottom:20px}.single-post .entry-categories{margin-bottom:20px}.single-post .entry-categories a{display:inline-block;padding:6px 8px;margin-bottom:4px;font-size:13px;line-height:1;color:#4d5a75;text-transform:uppercase;letter-spacing:1px;background-color:#f4f6fa}@media (min-width:880px){.single-post .entry-categories a{margin-bottom:0}}.single-post .site-inner{padding-top:30px}.screen-reader-shortcut,.screen-reader-text{position:absolute!important;width:1px;height:1px;overflow:hidden;clip:rect(0,0,0,0);word-wrap:normal!important;border:0}.genesis-skip-link{margin:0}.genesis-skip-link li{width:0;height:0;list-style:none}</style><link rel="stylesheet" href="./Instance segmentation with OpenCV - PyImageSearch_files/eef0bf32586d57e4ed24eb224ecbaf2f.css" media="all" type="text/css"><style id="avlabs-custom-critical-css-after-rocket">.aligncenter,img.centered{display:block;margin:0 auto}#loader-wrapper{display:none}.pyi-top-bar{position:sticky;top:0;z-index:999999;width:100%;padding:16px 0 14px;font-weight:600;color:#fff;text-align:center;background-color:#051e50;font-size:14px}

#release_bar {
    height: 69px;
}

</style>
	<meta name="description" content="This guide will teach how you to perform instance segmentation using OpenCV, Python, and Deep Learning.">
	<link rel="canonical" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/">
	<meta property="og:locale" content="en_US">
	<meta property="og:type" content="article">
	<meta property="og:title" content="Instance segmentation with OpenCV - PyImageSearch">
	<meta property="og:description" content="This guide will teach how you to perform instance segmentation using OpenCV, Python, and Deep Learning.">
	<meta property="og:url" content="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/">
	<meta property="og:site_name" content="PyImageSearch">
	<meta property="article:published_time" content="2018-11-26T15:00:12+00:00">
	<meta property="article:modified_time" content="2021-04-17T18:08:50+00:00">
	<meta property="og:image" content="https://pyimagesearch.com/wp-content/uploads/2018/11/instance_segmentation_featured.png">
	<meta property="og:image:width" content="448">
	<meta property="og:image:height" content="288">
	<meta property="og:image:type" content="image/png">
	<meta name="author" content="Adrian Rosebrock">
	<meta name="twitter:label1" content="Written by">
	<meta name="twitter:data1" content="Adrian Rosebrock">
	<meta name="twitter:label2" content="Est. reading time">
	<meta name="twitter:data2" content="16 minutes">
	<script type="text/javascript" async="" src="./Instance segmentation with OpenCV - PyImageSearch_files/4768429.js.download"></script><script type="text/javascript" async="" src="./Instance segmentation with OpenCV - PyImageSearch_files/1871593262.js.download"></script><script type="text/javascript" async="" src="./Instance segmentation with OpenCV - PyImageSearch_files/recaptcha__en.js.download" crossorigin="anonymous" integrity="sha384-ALtiHf0DOZRoBKnCKTk/SlH3koiTb5V8tXxijiVbKfgMusXfsD91H2zPixteloxy"></script><script type="application/ld+json" class="yoast-schema-graph">{"@context":"https://schema.org","@graph":[{"@type":"WebPage","@id":"https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/","url":"https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/","name":"Instance segmentation with OpenCV - PyImageSearch","isPartOf":{"@id":"https://pyimagesearch.com/#website"},"primaryImageOfPage":{"@id":"https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#primaryimage"},"image":{"@id":"https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#primaryimage"},"thumbnailUrl":"https://pyimagesearch.com/wp-content/uploads/2018/11/instance_segmentation_featured.png","datePublished":"2018-11-26T15:00:12+00:00","dateModified":"2021-04-17T18:08:50+00:00","author":{"@id":"https://pyimagesearch.com/#/schema/person/5901b399e2f20b986362a00636181cca"},"description":"This guide will teach how you to perform instance segmentation using OpenCV, Python, and Deep Learning.","breadcrumb":{"@id":"https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/"]}]},{"@type":"ImageObject","inLanguage":"en-US","@id":"https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#primaryimage","url":"https://pyimagesearch.com/wp-content/uploads/2018/11/instance_segmentation_featured.png","contentUrl":"https://pyimagesearch.com/wp-content/uploads/2018/11/instance_segmentation_featured.png","width":448,"height":288},{"@type":"BreadcrumbList","@id":"https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://pyimagesearch.com/"},{"@type":"ListItem","position":2,"name":"Blog","item":"https://pyimagesearch.com/blog/"},{"@type":"ListItem","position":3,"name":"Instance segmentation with OpenCV"}]},{"@type":"WebSite","@id":"https://pyimagesearch.com/#website","url":"https://pyimagesearch.com/","name":"PyImageSearch","description":"You can master Computer Vision, Deep Learning, and OpenCV - PyImageSearch","potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://pyimagesearch.com/?s={search_term_string}"},"query-input":"required name=search_term_string"}],"inLanguage":"en-US"},{"@type":"Person","@id":"https://pyimagesearch.com/#/schema/person/5901b399e2f20b986362a00636181cca","name":"Adrian Rosebrock","image":{"@type":"ImageObject","inLanguage":"en-US","@id":"https://pyimagesearch.com/#/schema/person/image/","url":"https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g","contentUrl":"https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&d=mm&r=g","caption":"Adrian Rosebrock"},"description":"Hi there, I’m Adrian Rosebrock, PhD. All too often I see developers, students, and researchers wasting their time, studying the wrong things, and generally struggling to get started with Computer Vision, Deep Learning, and OpenCV. I created this website to show you what I believe is the best possible way to get your start.","url":"https://pyimagesearch.com/author/adrian/"}]}</script>
	<!-- / Yoast SEO plugin. -->


<link rel="dns-prefetch" href="https://pyimagesearch.com/">
<link rel="dns-prefetch" href="https://www.google.com/">
<link rel="dns-prefetch" href="https://a.omappapi.com/">
<link rel="dns-prefetch" href="https://use.typekit.net/">
<link rel="dns-prefetch" href="https://929687.smushcdn.com/">

<link rel="alternate" type="application/rss+xml" title="PyImageSearch » Feed" href="https://pyimagesearch.com/feed/">
<link rel="alternate" type="application/rss+xml" title="PyImageSearch » Comments Feed" href="https://pyimagesearch.com/comments/feed/">
<link rel="alternate" type="application/rss+xml" title="PyImageSearch » Instance segmentation with OpenCV Comments Feed" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/feed/">

<style id="global-styles-inline-css" type="text/css">
body{--wp--preset--color--black: #051e50;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--color--green: #6dc713;--wp--preset--color--blue: #169fe6;--wp--preset--color--dark-blue: #051e50;--wp--preset--color--dark-grey: #4d5a75;--wp--preset--color--grey: #eceff5;--wp--preset--color--light-grey: #f4f6fa;--wp--preset--color--blue-soft: #F4F6FA;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--duotone--dark-grayscale: url('#wp-duotone-dark-grayscale');--wp--preset--duotone--grayscale: url('#wp-duotone-grayscale');--wp--preset--duotone--purple-yellow: url('#wp-duotone-purple-yellow');--wp--preset--duotone--blue-red: url('#wp-duotone-blue-red');--wp--preset--duotone--midnight: url('#wp-duotone-midnight');--wp--preset--duotone--magenta-yellow: url('#wp-duotone-magenta-yellow');--wp--preset--duotone--purple-green: url('#wp-duotone-purple-green');--wp--preset--duotone--blue-orange: url('#wp-duotone-blue-orange');--wp--preset--font-size--small: 16px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 24px;--wp--preset--font-size--x-large: 42px;--wp--preset--font-size--regular: 20px;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
</style>









<style id="rocket-lazyload-inline-css" type="text/css">
.rll-youtube-player{position:relative;padding-bottom:56.23%;height:0;overflow:hidden;max-width:100%;}.rll-youtube-player:focus-within{outline: 2px solid currentColor;outline-offset: 5px;}.rll-youtube-player iframe{position:absolute;top:0;left:0;width:100%;height:100%;z-index:100;background:0 0}.rll-youtube-player img{bottom:0;display:block;left:0;margin:auto;max-width:100%;width:100%;position:absolute;right:0;top:0;border:none;height:auto;-webkit-transition:.4s all;-moz-transition:.4s all;transition:.4s all}.rll-youtube-player img:hover{-webkit-filter:brightness(75%)}.rll-youtube-player .play{height:100%;width:100%;left:0;top:0;position:absolute;background:url(https://pyimagesearch.com/wp-content/plugins/wp-rocket/assets/img/youtube.png) no-repeat center;background-color: transparent !important;cursor:pointer;border:none;}.wp-embed-responsive .wp-has-aspect-ratio .rll-youtube-player{position:absolute;padding-bottom:0;width:100%;height:100%;top:0;bottom:0;left:0;right:0}
</style>






<link rel="https://api.w.org/" href="https://pyimagesearch.com/wp-json/"><link rel="alternate" type="application/json" href="https://pyimagesearch.com/wp-json/wp/v2/posts/9061"><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://pyimagesearch.com/xmlrpc.php?rsd">
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://pyimagesearch.com/wp-includes/wlwmanifest.xml"> 
<meta name="generator" content="WordPress 6.0.3">
<link rel="shortlink" href="https://pyimagesearch.com/?p=9061">
<link rel="alternate" type="application/json+oembed" href="https://pyimagesearch.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fpyimagesearch.com%2F2018%2F11%2F26%2Finstance-segmentation-with-opencv%2F">
<link rel="alternate" type="text/xml+oembed" href="https://pyimagesearch.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fpyimagesearch.com%2F2018%2F11%2F26%2Finstance-segmentation-with-opencv%2F&amp;format=xml">
    
    

<link rel="preload" as="font" href="https://pyimagesearch.com/wp-content/plugins/ultimate-faqs/assets/fonts/ewd-toggle-icon.woff2" crossorigin=""><link rel="pingback" href="https://pyimagesearch.com/xmlrpc.php">
<style type="text/css">
/* <![CDATA[ */
img.latex { vertical-align: middle; border: none; }
/* ]]> */
</style>
		<style type="text/css" id="wp-custom-css">
			.grecaptcha-badge {  
    display: none !important;
}

img.latex {
	margin: 0!important;
	display: inline!important;
}

.entry-content > .aligncenter {
	margin-left: auto;
	margin-right: auto;
} 

.page-template-page_success_stories .success-story-all .success-story-item {
	break-inside: avoid;
	float: none;
}
.site-title a {
    width: 160px;
	height: 50px;align-content}
@media (min-width: 1058px){
.site-title a {
	width: 300px;
  height: 90px;
}}		</style>
		<noscript><style id="rocket-lazyload-nojs-css">.rll-youtube-player, [data-lazy-src]{display:none !important;}</style></noscript><script>
/*! loadCSS rel=preload polyfill. [c]2017 Filament Group, Inc. MIT License */
(function(w){"use strict";if(!w.loadCSS){w.loadCSS=function(){}}
var rp=loadCSS.relpreload={};rp.support=(function(){var ret;try{ret=w.document.createElement("link").relList.supports("preload")}catch(e){ret=!1}
return function(){return ret}})();rp.bindMediaToggle=function(link){var finalMedia=link.media||"all";function enableStylesheet(){link.media=finalMedia}
if(link.addEventListener){link.addEventListener("load",enableStylesheet)}else if(link.attachEvent){link.attachEvent("onload",enableStylesheet)}
setTimeout(function(){link.rel="stylesheet";link.media="only x"});setTimeout(enableStylesheet,3000)};rp.poly=function(){if(rp.support()){return}
var links=w.document.getElementsByTagName("link");for(var i=0;i<links.length;i++){var link=links[i];if(link.rel==="preload"&&link.getAttribute("as")==="style"&&!link.getAttribute("data-loadcss")){link.setAttribute("data-loadcss",!0);rp.bindMediaToggle(link)}}};if(!rp.support()){rp.poly();var run=w.setInterval(rp.poly,500);if(w.addEventListener){w.addEventListener("load",function(){rp.poly();w.clearInterval(run)})}else if(w.attachEvent){w.attachEvent("onload",function(){rp.poly();w.clearInterval(run)})}}
if(typeof exports!=="undefined"){exports.loadCSS=loadCSS}
else{w.loadCSS=loadCSS}}(typeof global!=="undefined"?global:this))
</script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/j.php" type="text/javascript"></script><style>@import url(https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&family=Plus+Jakarta+Sans:wght@300;400;500;600;700;800&display=swap);</style><style>.MuiTooltip-popper{z-index:10000000 !important}
</style><style>@font-face {
	font-family: "wticons";
	src: url("data:font/woff2;charset=utf-8;base64,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") format("woff2");
}

.wticons {
	line-height: 1;
}

.wticons:before {
	font-family: wticons !important;
	font-style: normal;
	font-weight: normal !important;
	vertical-align: top;
}

.wticon-account:before {
	content: "\f101";
}
.wticon-add:before {
	content: "\f102";
}
.wticon-cardResizeDrag:before {
	content: "\f103";
}
.wticon-casual:before {
	content: "\f104";
}
.wticon-check:before {
	content: "\f105";
}
.wticon-checkSmall:before {
	content: "\f106";
}
.wticon-chevron:before {
	content: "\f107";
}
.wticon-copy:before {
	content: "\f108";
}
.wticon-copySmall:before {
	content: "\f109";
}
.wticon-dismiss:before {
	content: "\f10a";
}
.wticon-downChevron:before {
	content: "\f10b";
}
.wticon-error:before {
	content: "\f10c";
}
.wticon-expand:before {
	content: "\f10d";
}
.wticon-feedback:before {
	content: "\f10e";
}
.wticon-filledDownArrow:before {
	content: "\f10f";
}
.wticon-find:before {
	content: "\f110";
}
.wticon-formal:before {
	content: "\f111";
}
.wticon-gift:before {
	content: "\f112";
}
.wticon-grayLogo:before {
	content: "\f113";
}
.wticon-ignore:before {
	content: "\f114";
}
.wticon-info:before {
	content: "\f115";
}
.wticon-leftChevron:before {
	content: "\f116";
}
.wticon-logo:before {
	content: "\f117";
}
.wticon-love:before {
	content: "\f118";
}
.wticon-noRecommendations:before {
	content: "\f119";
}
.wticon-paragraphRewrite:before {
	content: "\f11a";
}
.wticon-paste:before {
	content: "\f11b";
}
.wticon-pin:before {
	content: "\f11c";
}
.wticon-premium:before {
	content: "\f11d";
}
.wticon-premiumDetail:before {
	content: "\f11e";
}
.wticon-premiumFull:before {
	content: "\f11f";
}
.wticon-recommendationLight:before {
	content: "\f120";
}
.wticon-recommendationLightCard:before {
	content: "\f121";
}
.wticon-recommendationLightNoSuggestions:before {
	content: "\f122";
}
.wticon-refine:before {
	content: "\f123";
}
.wticon-rewrite:before {
	content: "\f124";
}
.wticon-rightChevron:before {
	content: "\f125";
}
.wticon-rocket:before {
	content: "\f126";
}
.wticon-sentenceExamples:before {
	content: "\f127";
}
.wticon-settings:before {
	content: "\f128";
}
.wticon-shorten:before {
	content: "\f129";
}
.wticon-tutorial:before {
	content: "\f12a";
}
.wticon-unlock:before {
	content: "\f12b";
}
.wticon-warn:before {
	content: "\f12c";
}
.wticon-WordtuneButton:before {
	content: "\f12d";
}
.wticon-x:before {
	content: "\f12e";
}

/*# sourceMappingURL=data:application/json;base64,{"version":3,"sources":["webpack://src/shared/Icons.font.js"],"names":[],"mappings":"AAAA;CACC,sBAAsB;CACtB,63SAA63S;AAC93S;;AAEA;CACC,cAAc;AACf;;AAEA;CACC,+BAA+B;CAC/B,kBAAkB;CAClB,8BAA8B;CAC9B,mBAAmB;AACpB;;AAEA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB","sourcesContent":["@font-face {\n\tfont-family: \"wticons\";\n\tsrc: url(\"data:font/woff2;charset=utf-8;base64,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\") format(\"woff2\");\n}\n\n.wticons {\n\tline-height: 1;\n}\n\n.wticons:before {\n\tfont-family: wticons !important;\n\tfont-style: normal;\n\tfont-weight: normal !important;\n\tvertical-align: top;\n}\n\n.wticon-account:before {\n\tcontent: \"\\f101\";\n}\n.wticon-add:before {\n\tcontent: \"\\f102\";\n}\n.wticon-cardResizeDrag:before {\n\tcontent: \"\\f103\";\n}\n.wticon-casual:before {\n\tcontent: \"\\f104\";\n}\n.wticon-check:before {\n\tcontent: \"\\f105\";\n}\n.wticon-checkSmall:before {\n\tcontent: \"\\f106\";\n}\n.wticon-chevron:before {\n\tcontent: \"\\f107\";\n}\n.wticon-copy:before {\n\tcontent: \"\\f108\";\n}\n.wticon-copySmall:before {\n\tcontent: \"\\f109\";\n}\n.wticon-dismiss:before {\n\tcontent: \"\\f10a\";\n}\n.wticon-downChevron:before {\n\tcontent: \"\\f10b\";\n}\n.wticon-error:before {\n\tcontent: \"\\f10c\";\n}\n.wticon-expand:before {\n\tcontent: \"\\f10d\";\n}\n.wticon-feedback:before {\n\tcontent: \"\\f10e\";\n}\n.wticon-filledDownArrow:before {\n\tcontent: \"\\f10f\";\n}\n.wticon-find:before {\n\tcontent: \"\\f110\";\n}\n.wticon-formal:before {\n\tcontent: \"\\f111\";\n}\n.wticon-gift:before {\n\tcontent: \"\\f112\";\n}\n.wticon-grayLogo:before {\n\tcontent: \"\\f113\";\n}\n.wticon-ignore:before {\n\tcontent: \"\\f114\";\n}\n.wticon-info:before {\n\tcontent: \"\\f115\";\n}\n.wticon-leftChevron:before {\n\tcontent: \"\\f116\";\n}\n.wticon-logo:before {\n\tcontent: \"\\f117\";\n}\n.wticon-love:before {\n\tcontent: \"\\f118\";\n}\n.wticon-noRecommendations:before {\n\tcontent: \"\\f119\";\n}\n.wticon-paragraphRewrite:before {\n\tcontent: \"\\f11a\";\n}\n.wticon-paste:before {\n\tcontent: \"\\f11b\";\n}\n.wticon-pin:before {\n\tcontent: \"\\f11c\";\n}\n.wticon-premium:before {\n\tcontent: \"\\f11d\";\n}\n.wticon-premiumDetail:before {\n\tcontent: \"\\f11e\";\n}\n.wticon-premiumFull:before {\n\tcontent: \"\\f11f\";\n}\n.wticon-recommendationLight:before {\n\tcontent: \"\\f120\";\n}\n.wticon-recommendationLightCard:before {\n\tcontent: \"\\f121\";\n}\n.wticon-recommendationLightNoSuggestions:before {\n\tcontent: \"\\f122\";\n}\n.wticon-refine:before {\n\tcontent: \"\\f123\";\n}\n.wticon-rewrite:before {\n\tcontent: \"\\f124\";\n}\n.wticon-rightChevron:before {\n\tcontent: \"\\f125\";\n}\n.wticon-rocket:before {\n\tcontent: \"\\f126\";\n}\n.wticon-sentenceExamples:before {\n\tcontent: \"\\f127\";\n}\n.wticon-settings:before {\n\tcontent: \"\\f128\";\n}\n.wticon-shorten:before {\n\tcontent: \"\\f129\";\n}\n.wticon-tutorial:before {\n\tcontent: \"\\f12a\";\n}\n.wticon-unlock:before {\n\tcontent: \"\\f12b\";\n}\n.wticon-warn:before {\n\tcontent: \"\\f12c\";\n}\n.wticon-WordtuneButton:before {\n\tcontent: \"\\f12d\";\n}\n.wticon-x:before {\n\tcontent: \"\\f12e\";\n}\n"],"sourceRoot":""} */</style><script src="./Instance segmentation with OpenCV - PyImageSearch_files/jquery.js.download"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/f67da8ef1bb72583a9be2d03590e071d_avlabs_primary_script.js.download"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/avlabs-mobile-menu.js.download"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/avlabs-preloader.js.download"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/stickykit.min.js.download"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/kno0cmko2z.jsonp"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/8ggk996ods.jsonp"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/api.js.download"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/js"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/enlighterjs.min.js.download"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/5f56163b05bae797fe59e9425270e15c.js.download"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/skip-links.min.js.download"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/modal-min.js.download"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/avlabs-lazy-load.js.download"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/jquery.flexslider.min.js.download"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/global-min.js.download"></script><script src="./Instance segmentation with OpenCV - PyImageSearch_files/lazyload.min.js.download"></script><script type="text/javascript" src="./Instance segmentation with OpenCV - PyImageSearch_files/api.min.js.download" async="" data-user="18464" data-campaign="vksgrjuaic5dopynajjn"></script><meta class="foundation-mq"><script type="text/javascript" src="./Instance segmentation with OpenCV - PyImageSearch_files/api.min.js.download" async="" id="omapi-script"></script><style data-jss="" data-meta="MuiSnackbar">
.MuiSnackbar-root {
  left: 8px;
  right: 8px;
  display: flex;
  z-index: 1400;
  position: fixed;
  align-items: center;
  justify-content: center;
}
.MuiSnackbar-anchorOriginTopCenter {
  top: 8px;
}
@media (min-width:600px) {
  .MuiSnackbar-anchorOriginTopCenter {
    top: 24px;
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginBottomCenter {
  bottom: 8px;
}
@media (min-width:600px) {
  .MuiSnackbar-anchorOriginBottomCenter {
    left: 50%;
    right: auto;
    bottom: 24px;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginTopRight {
  top: 8px;
  justify-content: flex-end;
}
@media (min-width:600px) {
  .MuiSnackbar-anchorOriginTopRight {
    top: 24px;
    left: auto;
    right: 24px;
  }
}
.MuiSnackbar-anchorOriginBottomRight {
  bottom: 8px;
  justify-content: flex-end;
}
@media (min-width:600px) {
  .MuiSnackbar-anchorOriginBottomRight {
    left: auto;
    right: 24px;
    bottom: 24px;
  }
}
.MuiSnackbar-anchorOriginTopLeft {
  top: 8px;
  justify-content: flex-start;
}
@media (min-width:600px) {
  .MuiSnackbar-anchorOriginTopLeft {
    top: 24px;
    left: 24px;
    right: auto;
  }
}
.MuiSnackbar-anchorOriginBottomLeft {
  bottom: 8px;
  justify-content: flex-start;
}
@media (min-width:600px) {
  .MuiSnackbar-anchorOriginBottomLeft {
    left: 24px;
    right: auto;
    bottom: 24px;
  }
}
</style><style data-emotion="css" data-s=""></style><style type="text/css">.rm-c,.rm-c a,.rm-c abbr,.rm-c acronym,.rm-c address,.rm-c applet,.rm-c area,.rm-c article,.rm-c aside,.rm-c audio,.rm-c b,.rm-c big,.rm-c blockquote,.rm-c button,.rm-c canvas,.rm-c caption,.rm-c cite,.rm-c code,.rm-c col,.rm-c colgroup,.rm-c datalist,.rm-c dd,.rm-c del,.rm-c dfn,.rm-c div,.rm-c dl,.rm-c dt,.rm-c em,.rm-c fieldset,.rm-c figcaption,.rm-c figure,.rm-c footer,.rm-c form,.rm-c h1,.rm-c h2,.rm-c h3,.rm-c h4,.rm-c h5,.rm-c h6,.rm-c header,.rm-c hr,.rm-c i,.rm-c iframe,.rm-c img,.rm-c input,.rm-c ins,.rm-c kbd,.rm-c label,.rm-c legend,.rm-c li,.rm-c main,.rm-c map,.rm-c mark,.rm-c menu,.rm-c meta,.rm-c nav,.rm-c object,.rm-c ol,.rm-c optgroup,.rm-c option,.rm-c output,.rm-c p,.rm-c pre,.rm-c progress,.rm-c q,.rm-c samp,.rm-c section,.rm-c select,.rm-c small,.rm-c span,.rm-c strike,.rm-c strong,.rm-c sub,.rm-c summary,.rm-c sup,.rm-c svg,.rm-c table,.rm-c tbody,.rm-c td,.rm-c textarea,.rm-c tfoot,.rm-c th,.rm-c thead,.rm-c time,.rm-c tr,.rm-c tt,.rm-c ul,.rm-c var,.rm-c video{background-attachment:scroll!important;background-color:transparent!important;background-image:none!important;background-position:0 0!important;background-repeat:repeat!important;border-color:#000!important;border:medium none currentColor!important;bottom:auto!important;clear:none!important;clip:auto!important;color:inherit!important;counter-increment:none!important;counter-reset:none!important;cursor:auto!important;direction:inherit!important;display:inline!important;float:none!important;font-family:inherit!important;font-size:inherit!important;font-style:inherit!important;font-variant:normal!important;font-weight:inherit!important;height:auto!important;left:auto!important;letter-spacing:normal!important;line-height:inherit!important;list-style-type:inherit!important;list-style-position:outside!important;list-style-image:none!important;margin:0!important;max-height:none!important;max-width:none!important;min-height:0!important;min-width:0!important;opacity:1;outline:medium none invert!important;overflow:visible!important;padding:0!important;position:static!important;quotes:"" ""!important;right:auto!important;table-layout:auto!important;text-align:inherit!important;text-decoration:inherit!important;text-indent:0!important;text-transform:none!important;top:auto!important;unicode-bidi:normal!important;vertical-align:baseline!important;visibility:inherit!important;white-space:normal!important;width:auto!important;word-spacing:normal!important;z-index:auto!important;-webkit-background-origin:padding-box!important;background-origin:padding-box!important;-webkit-background-clip:border-box!important;background-clip:border-box!important;-webkit-background-size:auto!important;-moz-background-size:auto!important;background-size:auto!important;-webkit-border-image:none!important;-moz-border-image:none!important;-o-border-image:none!important;border-image:none!important;-webkit-border-radius:0!important;-moz-border-radius:0!important;border-radius:0!important;-webkit-box-shadow:none!important;box-shadow:none!important;-webkit-box-sizing:content-box!important;-moz-box-sizing:content-box!important;box-sizing:content-box!important;-webkit-column-count:auto!important;-moz-column-count:auto!important;column-count:auto!important;-webkit-column-gap:normal!important;-moz-column-gap:normal!important;column-gap:normal!important;-webkit-column-rule:medium none #000!important;-moz-column-rule:medium none #000!important;column-rule:medium none #000!important;-webkit-column-span:1!important;-moz-column-span:1!important;column-span:1!important;-webkit-column-width:auto!important;-moz-column-width:auto!important;column-width:auto!important;font-feature-settings:normal!important;overflow-x:visible!important;overflow-y:visible!important;-webkit-hyphens:manual!important;-moz-hyphens:manual!important;hyphens:manual!important;-webkit-perspective:none!important;-moz-perspective:none!important;-ms-perspective:none!important;-o-perspective:none!important;perspective:none!important;-webkit-perspective-origin:50% 50%!important;-moz-perspective-origin:50% 50%!important;-ms-perspective-origin:50% 50%!important;-o-perspective-origin:50% 50%!important;perspective-origin:50% 50%!important;-webkit-backface-visibility:visible!important;-moz-backface-visibility:visible!important;-ms-backface-visibility:visible!important;-o-backface-visibility:visible!important;backface-visibility:visible!important;text-shadow:none!important;-webkit-transition:all 0s ease 0s!important;transition:all 0s ease 0s!important;-webkit-transform:none!important;-moz-transform:none!important;-ms-transform:none!important;-o-transform:none!important;transform:none!important;-webkit-transform-origin:50% 50%!important;-moz-transform-origin:50% 50%!important;-ms-transform-origin:50% 50%!important;-o-transform-origin:50% 50%!important;transform-origin:50% 50%!important;-webkit-transform-style:flat!important;-moz-transform-style:flat!important;-ms-transform-style:flat!important;-o-transform-style:flat!important;transform-style:flat!important;word-break:normal!important}.rm-c,.rm-c address,.rm-c article,.rm-c audio,.rm-c blockquote,.rm-c caption,.rm-c colgroup,.rm-c dd,.rm-c dialog,.rm-c div,.rm-c dl,.rm-c dt,.rm-c fieldset,.rm-c figure,.rm-c footer,.rm-c form,.rm-c h1,.rm-c h2,.rm-c h3,.rm-c h4,.rm-c h5,.rm-c h6,.rm-c header,.rm-c hgroup,.rm-c hr,.rm-c main,.rm-c menu,.rm-c nav,.rm-c ol,.rm-c option,.rm-c p,.rm-c pre,.rm-c progress,.rm-c section,.rm-c summary,.rm-c ul,.rm-c video{display:block!important}.rm-c h1,.rm-c h2,.rm-c h3,.rm-c h4,.rm-c h5,.rm-c h6{font-weight:700!important}.rm-c h1{font-size:2em!important;padding:.67em 0!important}.rm-c h2{font-size:1.5em!important}.rm-c h2,.rm-c h3{padding:.83em 0!important}.rm-c h3{font-size:1.17em!important}.rm-c h4{font-size:1em!important}.rm-c h5{font-size:.83em!important}.rm-c p{margin:1em 0!important}.rm-c table{display:table!important}.rm-c thead{display:table-header-group!important}.rm-c tbody{display:table-row-group!important}.rm-c tfoot{display:table-footer-group!important}.rm-c tr{display:table-row!important}.rm-c td,.rm-c th{display:table-cell!important;padding:2px!important}.rm-c ol,.rm-c ul{margin:1em 0!important}.rm-c ol li,.rm-c ol ol li,.rm-c ol ol ol li,.rm-c ol ol ul li,.rm-c ol ul ul li,.rm-c ul li,.rm-c ul ol ol li,.rm-c ul ul li,.rm-c ul ul ol li,.rm-c ul ul ul li{list-style-position:inside!important;margin-top:.08em!important}.rm-c ol ol,.rm-c ol ol ol,.rm-c ol ol ul,.rm-c ol ul,.rm-c ol ul ul,.rm-c ul ol,.rm-c ul ol ol,.rm-c ul ul,.rm-c ul ul ol,.rm-c ul ul ul{padding-left:40px!important;margin:0!important}.rm-c nav ol,.rm-c nav ul{list-style-type:none!important}.rm-c menu,.rm-c ul{list-style-type:disc!important}.rm-c ol{list-style-type:decimal!important}.rm-c menu menu,.rm-c menu ul,.rm-c ol menu,.rm-c ol ul,.rm-c ul menu,.rm-c ul ul{list-style-type:circle!important}.rm-c menu menu menu,.rm-c menu menu ul,.rm-c menu ol menu,.rm-c menu ol ul,.rm-c menu ul menu,.rm-c menu ul ul,.rm-c ol menu menu,.rm-c ol menu ul,.rm-c ol ol menu,.rm-c ol ol ul,.rm-c ol ul menu,.rm-c ol ul ul,.rm-c ul menu menu,.rm-c ul menu ul,.rm-c ul ol menu,.rm-c ul ol ul,.rm-c ul ul menu,.rm-c ul ul ul{list-style-type:square!important}.rm-c li{display:list-item!important;min-height:auto!important;min-width:auto!important;padding-left:20px!important}.rm-c strong{font-weight:700!important}.rm-c em{font-style:italic!important}.rm-c code,.rm-c kbd,.rm-c pre,.rm-c samp{font-family:monospace!important}.rm-c a,.rm-c a *,.rm-c button,.rm-c button *,.rm-c input[type=button],.rm-c input[type=checkbox],.rm-c input[type=radio],.rm-c input[type=submit],.rm-c select{cursor:pointer!important}.rm-c button,.rm-c input[type=submit]{font-family:inherit!important;outline:initial!important}.rm-c input[type=hidden]{display:none!important}.rm-c textarea{-webkit-appearance:textarea!important;background:#fff!important;padding:2px!important;margin-left:4px!important;word-wrap:break-word!important;white-space:pre-wrap!important;font-size:11px!important;font-family:inherit!important;line-height:13px!important;resize:both!important}.rm-c input,.rm-c select,.rm-c textarea{border:1px solid #ccc!important}.rm-c select{font-size:11px!important;font-family:inherit!important;display:inline-block}.rm-c input:focus,.rm-c textarea:focus{outline:5px auto -webkit-focus-ring-color!important;outline:initial!important}.rm-c input[type=email],.rm-c input[type=text]{background:#fff!important;padding:1px!important;font-family:inherit!important;font-size:small!important}.rm-c input[type=checkbox],.rm-c input[type=radio]{border:1px solid #2b2b2b!important;border-radius:4px!important;outline:initial!important}.rm-c input[type=radio]{margin:2px 2px 3px!important}.rm-c abbr[title],.rm-c acronym[title],.rm-c dfn[title]{cursor:help!important;border-bottom-width:1px!important;border-bottom-style:dotted!important}.rm-c ins{background-color:#ff9!important;color:#000!important}.rm-c del{text-decoration:line-through!important}.rm-c blockquote,.rm-c q{quotes:none!important}.rm-c blockquote:after,.rm-c blockquote:before,.rm-c li:after,.rm-c li:before,.rm-c q:after,.rm-c q:before{content:""!important}.rm-c input,.rm-c select{vertical-align:middle!important}.rm-c table{border-collapse:collapse!important;border-spacing:0!important}.rm-c hr{display:block!important;height:1px!important;border:0!important;border-top:1px solid #ccc!important;margin:1em 0!important}.rm-c [dir=rtl]{direction:rtl!important}.rm-c mark{background-color:#ff9!important;color:#000!important;font-style:italic!important;font-weight:700!important}.rm-c menu{padding-left:40px!important;padding-top:8px!important}.rm-c [hidden],.rm-c template{display:none!important}.rm-c abbr[title]{border-bottom:1px dotted!important}.rm-c sub,.rm-c sup{font-size:75%!important;line-height:0!important;position:relative!important;vertical-align:baseline!important}.rm-c sup{top:-.5em!important}.rm-c sub{bottom:-.25em!important}.rm-c img{border:0!important}.rm-c figure{margin:0!important}.rm-c textarea{overflow:auto!important;vertical-align:top!important}.rm-c{font-size:medium!important;line-height:1!important;text-align:left!important;text-align:start!important;color:#000!important;font-style:normal!important;font-weight:400!important;text-decoration:none!important;list-style-type:disc!important}.rm-c pre{white-space:pre!important}</style><style type="text/css">.rm-animated{animation-duration:1s;animation-fill-mode:both}.rm-animated.infinite{animation-iteration-count:infinite}.rm-animated.delay-1s{animation-delay:1s}.rm-animated.delay-2s{animation-delay:2s}.rm-animated.delay-3s{animation-delay:3s}.rm-animated.delay-4s{animation-delay:4s}.rm-animated.delay-5s{animation-delay:5s}.rm-animated.fast{animation-duration:.8s}.rm-animated.faster{animation-duration:.5s}.rm-animated.slow{animation-duration:2s}.rm-animated.slower{animation-duration:3s}@media (prefers-reduced-motion),(print){.rm-animated{animation:unset!important;transition:none!important}}@keyframes rm-tada{0%{transform:scaleX(1)}2%,4%{transform:scale3d(.9,.9,.9) rotate(-3deg)}6%,10%,14%,18%{transform:scale3d(1.1,1.1,1.1) rotate(3deg)}8%,12%,16%{transform:scale3d(1.1,1.1,1.1) rotate(-3deg)}20%{transform:scaleX(1)}}.rm-tada{animation-duration:5s;animation-name:rm-tada}</style><style>.rmtempinvisible { visibility: visible !important; }</style></head>
<body data-rsssl="1" class="post-template-default single single-post postid-9061 single-format-standard wp-embed-responsive header-full-width content-sidebar genesis-breadcrumbs-hidden genesis-footer-widgets-visible" data-new-gr-c-s-check-loaded="14.1085.0" data-gr-ext-installed=""><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-dark-grayscale"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0 0.49803921568627"></fefuncr><fefuncg type="table" tableValues="0 0.49803921568627"></fefuncg><fefuncb type="table" tableValues="0 0.49803921568627"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-grayscale"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0 1"></fefuncr><fefuncg type="table" tableValues="0 1"></fefuncg><fefuncb type="table" tableValues="0 1"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-purple-yellow"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0.54901960784314 0.98823529411765"></fefuncr><fefuncg type="table" tableValues="0 1"></fefuncg><fefuncb type="table" tableValues="0.71764705882353 0.25490196078431"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-blue-red"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0 1"></fefuncr><fefuncg type="table" tableValues="0 0.27843137254902"></fefuncg><fefuncb type="table" tableValues="0.5921568627451 0.27843137254902"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-midnight"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0 0"></fefuncr><fefuncg type="table" tableValues="0 0.64705882352941"></fefuncg><fefuncb type="table" tableValues="0 1"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-magenta-yellow"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0.78039215686275 1"></fefuncr><fefuncg type="table" tableValues="0 0.94901960784314"></fefuncg><fefuncb type="table" tableValues="0.35294117647059 0.47058823529412"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-purple-green"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0.65098039215686 0.40392156862745"></fefuncr><fefuncg type="table" tableValues="0 1"></fefuncg><fefuncb type="table" tableValues="0.44705882352941 0.4"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;"><defs><filter id="wp-duotone-blue-orange"><fecolormatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 "></fecolormatrix><fecomponenttransfer color-interpolation-filters="sRGB"><fefuncr type="table" tableValues="0.098039215686275 1"></fefuncr><fefuncg type="table" tableValues="0 0.66274509803922"></fefuncg><fefuncb type="table" tableValues="0.84705882352941 0.41960784313725"></fefuncb><fefunca type="table" tableValues="1 1"></fefunca></fecomponenttransfer><fecomposite in2="SourceGraphic" operator="in"></fecomposite></filter></defs></svg><div class="site-container"><ul class="genesis-skip-link"><li><a href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#genesis-nav-primary" class="screen-reader-shortcut"> Skip to primary navigation</a></li><li><a href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#genesis-content" class="screen-reader-shortcut"> Skip to main content</a></li><li><a href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#genesis-sidebar-primary" class="screen-reader-shortcut"> Skip to primary sidebar</a></li><li><a href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#genesis-footer-widgets" class="screen-reader-shortcut"> Skip to footer</a></li></ul><header class="site-header"><div class="wrap"><div class="title-area"><p class="site-title"><a href="https://pyimagesearch.com/">PyImageSearch</a></p><p class="site-description">You can master Computer Vision, Deep Learning, and OpenCV - PyImageSearch</p></div><nav class="nav-secondary" aria-label="Secondary"><div class="wrap"><ul id="menu-header-secondary" class="menu genesis-nav-menu menu-secondary"><li id="menu-item-29226" class="menu-item"><a href="https://pyimagesearch.com/consulting-2/"><span>Consulting</span></a></li>
<li id="menu-item-15978" class="menu-item"><a href="https://pyimagesearch.com/opencv-tutorials-resources-guides/"><span>OpenCV Install Guides</span></a></li>
<li id="menu-item-12816" class="menu-item"><a href="https://pyimagesearch.com/about/"><span>About</span></a></li>
<li id="menu-item-12817" class="menu-item"><a href="https://pyimagesearch.com/faqs/"><span>FAQ</span></a></li>
<li id="menu-item-12818" class="menu-item"><a href="https://pyimagesearch.com/contact/"><span>Contact</span></a></li>
<li id="menu-item-31245" class="menu-item"><a href="https://pyimagesearch.com/consult-adrian/"><span>Coaching</span></a></li>
</ul></div></nav><div class="main-nav-wrap"><nav class="nav-primary" aria-label="Main" id="genesis-nav-primary"><ul id="menu-main-menu" class="menu genesis-nav-menu menu-primary"><li id="menu-item-11459" class="menu-item"><a href="https://pyimagesearch.com/start-here/"><span>Get Started</span></a></li>
<li id="menu-item-10696" class="is-topics menu-item menu-item-has-children"><a href="https://pyimagesearch.com/topics/"><span>Topics</span></a><span class="submenu-expand" tabindex="-1"><svg class="svg-icon" width="16" height="16" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M151.5 347.8L3.5 201c-4.7-4.7-4.7-12.3 0-17l19.8-19.8c4.7-4.7 12.3-4.7 17 0L160 282.7l119.7-118.5c4.7-4.7 12.3-4.7 17 0l19.8 19.8c4.7 4.7 4.7 12.3 0 17l-148 146.8c-4.7 4.7-12.3 4.7-17 0z"></path></svg></span>
<ul class="sub-menu">
	<li id="menu-item-10698" class="has-icon has-icon--deep-learning menu-item current-post-ancestor current-menu-parent current-post-parent"><a href="https://pyimagesearch.com/category/deep-learning/"><span>Deep Learning</span></a></li>
	<li id="menu-item-10699" class="has-icon has-icon--dlib menu-item"><a href="https://pyimagesearch.com/category/dlib/"><span>Dlib Library</span></a></li>
	<li id="menu-item-10700" class="has-icon has-icon--iot menu-item"><a href="https://pyimagesearch.com/category/embedded/"><span>Embedded/IoT and Computer Vision</span></a></li>
	<li id="menu-item-10701" class="has-icon has-icon--face menu-item"><a href="https://pyimagesearch.com/category/faces/"><span>Face Applications</span></a></li>
	<li id="menu-item-10702" class="has-icon has-icon--image menu-item"><a href="https://pyimagesearch.com/category/image-processing/"><span>Image Processing</span></a></li>
	<li id="menu-item-10703" class="has-icon has-icon--interviews menu-item"><a href="https://pyimagesearch.com/category/interviews/"><span>Interviews</span></a></li>
	<li id="menu-item-10704" class="has-icon has-icon--keras menu-item"><a href="https://pyimagesearch.com/category/keras-and-tensorflow/"><span>Keras and TensorFlow</span></a></li>
	<li id="menu-item-10705" class="has-icon has-icon--ml menu-item"><a href="https://pyimagesearch.com/category/machine-learning/"><span>Machine Learning and Computer Vision</span></a></li>
	<li id="menu-item-10706" class="has-icon has-icon--medical menu-item"><a href="https://pyimagesearch.com/category/medical/"><span>Medical Computer Vision</span></a></li>
	<li id="menu-item-10707" class="has-icon has-icon--ocr menu-item"><a href="https://pyimagesearch.com/category/optical-character-recognition-ocr/"><span>Optical Character Recognition (OCR)</span></a></li>
	<li id="menu-item-10708" class="has-icon has-icon--object-detection menu-item"><a href="https://pyimagesearch.com/category/object-detection/"><span>Object Detection</span></a></li>
	<li id="menu-item-10709" class="has-icon has-icon--object-tracking menu-item"><a href="https://pyimagesearch.com/category/object-tracking/"><span>Object Tracking</span></a></li>
	<li id="menu-item-10711" class="has-icon has-icon--opencv menu-item"><a href="https://pyimagesearch.com/category/opencv/"><span>OpenCV Tutorials</span></a></li>
	<li id="menu-item-10710" class="has-icon has-icon--pi menu-item"><a href="https://pyimagesearch.com/category/raspberry-pi/"><span>Raspberry Pi</span></a></li>
</ul>
</li>
<li id="menu-item-12831" class="menu-item"><a href="https://pyimagesearch.com/books-and-courses/"><span>Books and Courses</span></a></li>
<li id="menu-item-15979" class="menu-item"><a href="https://pyimagesearch.com/pyimagesearch-reviews-testimonials/"><span>Student Success Stories</span></a></li>
<li id="menu-item-12845" class="menu-item current_page_parent"><a href="https://pyimagesearch.com/blog/"><span>Blog</span></a></li>
<li id="menu-item-29296" class="mobile-only menu-item"><a href="https://pyimagesearch.com/consulting-2/"><span>Consulting</span></a></li>
<li id="menu-item-2619" class="mobile-only menu-item"><a href="https://pyimagesearch.com/about/"><span>About</span></a></li>
<li id="menu-item-10258" class="mobile-only menu-item"><a href="https://pyimagesearch.com/faqs/"><span>FAQ</span></a></li>
<li id="menu-item-6744" class="mobile-only menu-item"><a href="https://pyimagesearch.com/contact/"><span>Contact</span></a></li>
</ul></nav><div class="header-search"><button class="mobile-search-toggle"><svg class="svg-icon search-icon" width="28" height="28" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M508.5 468.9L387.1 347.5c-2.3-2.3-5.3-3.5-8.5-3.5h-13.2c31.5-36.5 50.6-84 50.6-136C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c52 0 99.5-19.1 136-50.6v13.2c0 3.2 1.3 6.2 3.5 8.5l121.4 121.4c4.7 4.7 12.3 4.7 17 0l22.6-22.6c4.7-4.7 4.7-12.3 0-17zM208 368c-88.4 0-160-71.6-160-160S119.6 48 208 48s160 71.6 160 160-71.6 160-160 160z"></path></svg><svg class="svg-icon search-close" width="28" height="28" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M207.6 256l107.72-107.72c6.23-6.23 6.23-16.34 0-22.58l-25.03-25.03c-6.23-6.23-16.34-6.23-22.58 0L160 208.4 52.28 100.68c-6.23-6.23-16.34-6.23-22.58 0L4.68 125.7c-6.23 6.23-6.23 16.34 0 22.58L112.4 256 4.68 363.72c-6.23 6.23-6.23 16.34 0 22.58l25.03 25.03c6.23 6.23 16.34 6.23 22.58 0L160 303.6l107.72 107.72c6.23 6.23 16.34 6.23 22.58 0l25.03-25.03c6.23-6.23 6.23-16.34 0-22.58L207.6 256z"></path></svg><span class="screen-reader-text">Search</span></button>
<form role="search" method="get" class="search-form" action="https://pyimagesearch.com/">
	<label>
		<span class="screen-reader-text">Search...</span>
		<input type="search" class="search-field" placeholder="Search articles..." value="" name="s" title="Search for">
	</label>
	<button type="submit" class="search-submit"><svg class="svg-icon search" width="20" height="20" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M508.5 468.9L387.1 347.5c-2.3-2.3-5.3-3.5-8.5-3.5h-13.2c31.5-36.5 50.6-84 50.6-136C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c52 0 99.5-19.1 136-50.6v13.2c0 3.2 1.3 6.2 3.5 8.5l121.4 121.4c4.7 4.7 12.3 4.7 17 0l22.6-22.6c4.7-4.7 4.7-12.3 0-17zM208 368c-88.4 0-160-71.6-160-160S119.6 48 208 48s160 71.6 160 160-71.6 160-160 160z"></path></svg><span class="screen-reader-text">Submit</span></button>
</form>
</div><nav class="nav-mobile"><button class="mobile-menu-toggle"><span class="mobile-menu-open"><svg class="svg-icon menu-open" width="13" height="13" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg>Menu</span><span class="mobile-menu-close"><svg class="svg-icon menu-close" width="13" height="13" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M207.6 256l107.72-107.72c6.23-6.23 6.23-16.34 0-22.58l-25.03-25.03c-6.23-6.23-16.34-6.23-22.58 0L160 208.4 52.28 100.68c-6.23-6.23-16.34-6.23-22.58 0L4.68 125.7c-6.23 6.23-6.23 16.34 0 22.58L112.4 256 4.68 363.72c-6.23 6.23-6.23 16.34 0 22.58l25.03 25.03c6.23 6.23 16.34 6.23 22.58 0L160 303.6l107.72 107.72c6.23 6.23 16.34 6.23 22.58 0l25.03-25.03c6.23-6.23 6.23-16.34 0-22.58L207.6 256z"></path></svg>Close</span><span class="screen-reader-text">Menu</span></button></nav></div></div></header><div class="pyi-page-hero"><div class="wrap"><p class="entry-meta"><span class="entry-categories"><a href="https://pyimagesearch.com/category/deep-learning/" rel="category tag">Deep Learning</a> <a href="https://pyimagesearch.com/category/semantic-segmentation/" rel="category tag">Semantic Segmentation</a> <a href="https://pyimagesearch.com/category/tutorials/" rel="category tag">Tutorials</a></span></p><header class="entry-header"><h1 class="entry-title">Instance segmentation with OpenCV</h1>
</header><p class="entry-meta">by <span class="entry-author"><a href="https://pyimagesearch.com/author/adrian/" class="entry-author-link" rel="author"><span class="entry-author-name">Adrian Rosebrock</span></a></span> on <time class="entry-time">November 26, 2018</time></p><div class="pyi-hero-left"></div><div class="pyi-hero-right"></div></div></div><div class="site-inner"><div class="wrap"><div class="content-sidebar-wrap"><main class="content" id="genesis-content"><article class="post-9061 post type-post status-publish format-standard has-post-thumbnail category-deep-learning category-semantic-segmentation category-tutorials tag-deep-learning tag-instance-segmentation tag-mask-r-cnn tag-masks tag-object-detection tag-segmentation tag-semantic-segmentation entry" aria-label="Instance segmentation with OpenCV"><div class="entry-content">
<div id="pyis-cta-modal-sticky-top-anchor"></div>

<div id="pyis-cta-modal-sticky-bar" data-sticky-container="" class="sticky-container" style="height: 75.175px;">

	<div class="sticky is-at-top is-stuck" data-sticky="oh2zc2-sticky" data-top-anchor="pyis-cta-modal-sticky-top-anchor:top" data-btm-anchor="pyis-cta-modal-sticky-bottom-anchor:bottom" data-margin-top="0" data-sticky-on="small" data-resize="qny88v-sticky" data-mutate="qny88v-sticky" style="max-width: 702.4px; margin-top: 0em; bottom: auto; top: 0px;" data-events="mutate">

		<div class="grid-container">
			<div class="grid-x grid-margin-x">
				<div class="cell text-center">
		
					<a href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" class="pyis-cta-modal-open-modal">
						
						Click here to download the source code to this post						
					</a>

				</div>
			</div>
		</div>
		
	</div>

</div><p><img class="aligncenter size-full entered exited" width="500" data-lazy-src="https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/opencv-instance-segmentation/instance_segmentation_animation.gif" src="./Instance segmentation with OpenCV - PyImageSearch_files/instance_segmentation_animation.gif"><noscript><img class="aligncenter size-full" src="https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/opencv-instance-segmentation/instance_segmentation_animation.gif" width="500"></noscript></p>
<p>In this tutorial, you will learn how to perform instance segmentation with OpenCV, Python, and Deep Learning.</p>
<p>Back in September, I saw Microsoft release a really neat feature to their Office 365 platform — <strong>the ability to be on a video conference call, <em>blur the background</em>, and have your colleagues only see you (and not whatever is behind you).</strong></p>
<p>The GIF at the top of this post demonstrates a similar feature that I have implemented for the purposes of today’s tutorial.</p>
<p>Whether you’re taking the call from a hotel room, working from a downright ugly office building, or simply don’t want to clean up around the home office, the conference call blurring feature can keep the meeting attendees focused on you (and not the mess in the background).</p>
<p><strong>Such a feature would be <em>especially helpful</em> for people working from home and wanting to preserve the privacy of their family members.</strong></p>
<p>Imagine your workstation being in clear view of your kitchen — you wouldn’t want your colleagues watching your kids eating dinner or doing their homework! <strong>Instead, just pop on the blurring feature and you’re all set.</strong></p>
<p>In order to build such a feature, Microsoft leveraged computer vision, deep learning, and most notably, <em><strong>instance segmentation.</strong></em></p>
<p>We covered Mask R-CNNs for instance segmentation in <a href="https://pyimagesearch.com/2018/11/19/mask-r-cnn-with-opencv/" target="_blank" rel="noopener noreferrer">last week’s blog post</a> — today we are going to take our Mask R-CNN implementation and use it to build a Microsoft Office 365-like video blurring feature.</p>
<p><strong>To learn how to perform instance segmentation with OpenCV, <em>just keep reading!</em></strong></p>
<div id="pyi-source-code-block" class="source-code-wrap"><div class="gpd-source-code">
    <div class="gpd-source-code-content">
        <img src="./Instance segmentation with OpenCV - PyImageSearch_files/source-code-icon.png" alt="" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/source-code-icon.png?lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" class="entered lazyloaded"><noscript><img src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/source-code-icon.png?lossy=1&strip=1&webp=1" alt=""></noscript>
        <h4>Looking for the source code to this post?</h4>
                    <a href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" class="pyis-cta-modal-open-modal">Jump Right To The Downloads Section <svg class="svg-icon arrow-right" width="12" height="12" aria-hidden="true" role="img" focusable="false" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.8125 0.1875C6.875 0.125 6.96875 0.09375 7.09375 0.09375C7.1875 0.09375 7.28125 0.125 7.34375 0.1875L13.875 6.75C13.9375 6.8125 14 6.90625 14 7C14 7.125 13.9375 7.1875 13.875 7.25L7.34375 13.8125C7.28125 13.875 7.1875 13.9062 7.09375 13.9062C6.96875 13.9062 6.875 13.875 6.8125 13.8125L6.1875 13.1875C6.125 13.125 6.09375 13.0625 6.09375 12.9375C6.09375 12.8438 6.125 12.75 6.1875 12.6562L11.0312 7.8125H0.375C0.25 7.8125 0.15625 7.78125 0.09375 7.71875C0.03125 7.65625 0 7.5625 0 7.4375V6.5625C0 6.46875 0.03125 6.375 0.09375 6.3125C0.15625 6.25 0.25 6.1875 0.375 6.1875H11.0312L6.1875 1.34375C6.125 1.28125 6.09375 1.1875 6.09375 1.0625C6.09375 0.96875 6.125 0.875 6.1875 0.8125L6.8125 0.1875Z" fill="#169FE6"></path></svg></a>
            </div>
</div>
</div>
<h2>Instance segmentation with OpenCV</h2>
<p></p><div class="rll-youtube-player" data-src="https://www.youtube.com/embed/puSN8Dg-bdI" data-id="puSN8Dg-bdI" data-query="feature=oembed"><div data-id="puSN8Dg-bdI" data-query="feature=oembed" data-src="https://www.youtube.com/embed/puSN8Dg-bdI"><img data-lazy-src="https://i.ytimg.com/vi/puSN8Dg-bdI/hqdefault.jpg" alt="" width="480" height="360" data-ll-status="loaded" class="entered lazyloaded" src="./Instance segmentation with OpenCV - PyImageSearch_files/hqdefault.jpg"><noscript><img src="https://i.ytimg.com/vi/ID/hqdefault.jpg" alt="" width="480" height="360"></noscript><button class="play" aria-label="play Youtube video"></button></div></div><noscript><iframe title="Instance Segmentation with OpenCV Demo" width="630" height="473" src="https://www.youtube.com/embed/puSN8Dg-bdI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></noscript><p></p>
<p>Today’s tutorial is inspired by both (1) <a href="https://blogs.technet.microsoft.com/skypehybridguy/2018/09/09/microsoft-teams-blur-my-background-please/" target="_blank" rel="noopener noreferrer">Microsoft’s Office 365 video call blurring feature</a> and (2) PyImageSearch reader Zubair Ahmed. Zubair implemented a similar blurring feature using Google’s DeepLab (you can find his implementation <a href="http://zubairahmed.net/2018/07/17/background-blurring-with-semantic-image-segmentation-using-deeplabv3/" target="_blank" rel="noopener noreferrer">on his blog</a>).</p>
<p>Since we covered instance segmentation in <a href="https://pyimagesearch.com/2018/11/19/mask-r-cnn-with-opencv/" target="_blank" rel="noopener noreferrer">last week’s blog post</a>, I thought it was the perfect time to demonstrate how we can mimic the call blurring feature using OpenCV.</p>
<p>In the first part of this tutorial, we’ll briefly cover instance segmentation. From there we’ll use instance segmentation and OpenCV to:</p>
<ol>
<li>Detect and segment the user from the video stream</li>
<li>Blur the background</li>
<li>And then add the user back to the stream itself.</li>
</ol>
<p>From there we’ll look at the results of our OpenCV instance segmentation algorithm, including some of the limitations and drawbacks.</p>
<h3>What is instance segmentation?</h3>
<figure id="attachment_9070" aria-describedby="caption-attachment-9070" style="width: 600px" class="wp-caption aligncenter"><a href="https://pyimagesearch.com/wp-content/uploads/2018/11/instance_segmentation_example.jpg"><img class="size-full wp-image-9070 entered lazyloaded" src="./Instance segmentation with OpenCV - PyImageSearch_files/instance_segmentation_example.jpg" alt="" width="600" height="362" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?size=126x76&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example-300x181.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?size=378x228&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?size=504x304&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" data-lazy-sizes="(max-width: 600px) 100vw, 600px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" sizes="(max-width: 600px) 100vw, 600px" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?size=126x76&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example-300x181.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?size=378x228&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?size=504x304&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?lossy=1&amp;strip=1&amp;webp=1 600w"><noscript><img class="size-full wp-image-9070" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?lossy=1&strip=1&webp=1" alt="" width="600" height="362" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?size=126x76&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example-300x181.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?size=378x228&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?size=504x304&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/instance_segmentation_example.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" sizes="(max-width: 600px) 100vw, 600px" /></noscript></a><figcaption id="caption-attachment-9070" class="wp-caption-text"><strong>Figure 1:</strong> The difference between <strong>object detection</strong> and <strong>instance segmentation</strong>. For object detection (<em>left</em>), a box is drawn around the individual objects. In the case of instance segmentation (<em>right</em>), an attempt is made to determine which pixels belong to each object. (<a href="https://medium.com/weightsandbiases/car-image-segmentation-using-convolutional-neural-nets-7642448028f6" target="_blank" rel="noopener noreferrer">source</a>)</figcaption></figure>
<p>Explaining instance segmentation is best done with a visual example — refer to <strong>Figure 1</strong> above where we have an example of <strong>object detection</strong> on the <em>left</em> and <em><strong>instance segmentation</strong></em> on the <em>right</em>.</p>
<p>Looking at these two examples we can clearly see a difference between the two.</p>
<p>When performing object detection we are:</p>
<ol>
<li>Computing the bounding box <em>(x, y)</em>-coordinates for each object</li>
<li>And then associating a class label with each bounding box as well.</li>
</ol>
<p>The problem is that object detection tells us nothing regarding the shape of the object <em>itself</em> — all we have is a set of bounding box coordinates. <strong>Instance segmentation, on the other hand, computes a <em>pixel-wise mask</em> for <em>each object in the image</em>.</strong></p>
<p>Even if the objects are of the same class label, such as the two dogs in the above image, our instance segmentation algorithm still reports a total of <em>three unique objects</em>: two dogs and one cat.</p>
<p>Using instance segmentation we now have a more granular understanding of the object in the image — we know <em>specifically</em> which <em>(x, y)</em>-coordinates the object exists in.</p>
<p><strong>Furthermore, by using instance segmentation we can easily segment our foreground objects from the background.</strong></p>
<p>We’ll be using a Mask R-CNN for instance segmentation in this post.</p>
<p>For a more detailed review of instance segmentation, including comparing and contrasting <em>image classification, object detection, semantic segmentation, </em>and<em> instance segmentation,</em> <strong>please refer to <a href="https://pyimagesearch.com/2018/11/19/mask-r-cnn-with-opencv/" target="_blank" rel="noopener noreferrer">last week’s blog post</a>.</strong></p>
<h3>Project structure</h3>
<p>You can grab the source code and trained Mask R-CNN model from the <em><strong>“Downloads”</strong></em> section of today’s post.</p>
<p>Once you’ve extracted the archive and navigated into it, simply take advantage of the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">tree</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">tree</code>  command to view the directory structure in your terminal:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Instance segmentation with OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-text">$ tree --dirsfirst</span></div></div><div class=""><div><span class="enlighter-text">.</span></div></div><div class=""><div><span class="enlighter-text">├── mask-rcnn-coco</span></div></div><div class=""><div><span class="enlighter-text">│   ├── frozen_inference_graph.pb</span></div></div><div class=""><div><span class="enlighter-text">│   ├── mask_rcnn_inception_v2_coco_2018_01_28.pbtxt</span></div></div><div class=""><div><span class="enlighter-text">│   └── object_detection_classes_coco.txt</span></div></div><div class=""><div><span class="enlighter-text">└── instance_segmentation.py</span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-n1">1</span><span class="enlighter-text"> directory, </span><span class="enlighter-n1">4</span><span class="enlighter-text"> files</span></div></div></div><div class="enlighter-raw">$ tree --dirsfirst
.
├── mask-rcnn-coco
│   ├── frozen_inference_graph.pb
│   ├── mask_rcnn_inception_v2_coco_2018_01_28.pbtxt
│   └── object_detection_classes_coco.txt
└── instance_segmentation.py

1 directory, 4 files</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Instance segmentation with OpenCV" data-enlighter-group="1">$ tree --dirsfirst
.
├── mask-rcnn-coco
│&nbsp;&nbsp; ├── frozen_inference_graph.pb
│&nbsp;&nbsp; ├── mask_rcnn_inception_v2_coco_2018_01_28.pbtxt
│&nbsp;&nbsp; └── object_detection_classes_coco.txt
└── instance_segmentation.py

1 directory, 4 files
</pre>


<p>Our project includes one directory (consisting of three files) and one Python script:</p>
<ul>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">mask-rcnn-coco/</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">mask-rcnn-coco/</code> : The Mask R-CNN model directory contains three files:
<ul>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">frozen_inference_graph.pb</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">frozen_inference_graph.pb</code> : The Mask R-CNN model weights. The weights are pre-trained on the COCO dataset.</li>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">mask_rcnn_inception_v2_coco_2018_01_28.pbtxt</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">mask_rcnn_inception_v2_coco_2018_01_28.pbtxt</code> : The Mask R-CNN model configuration. If you’d like to build + train your own model on your own annotated data, refer to <em><a href="https://pyimagesearch.com/deep-learning-computer-vision-python-book/" target="_blank" rel="noopener noreferrer">Deep Learning for Computer Vision with Python</a>.</em></li>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">object_detection_classes_coco.txt</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">object_detection_classes_coco.txt</code> : All 90 classes are listed in this text file, one per line. Open it in a text editor to see what objects our model can recognize.</li>
</ul>
</li>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">instance_segmentation.py</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">instance_segmentation.py</code> : We’ll be reviewing this background blur script today. Then we’ll put it to use and evaluate the results.</li>
</ul>
<h3>Implementing instance segmentation with OpenCV</h3>
<p>Let’s get started implementing instance segmentation with OpenCV.</p>
<p>Open up the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">instance_segmentation.py</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">instance_segmentation.py</code>  file and insert the following code:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Instance segmentation with OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-c0"># import the necessary packages</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">from </span><span class="enlighter-k10">imutils.video</span><span class="enlighter-k0"> import</span><span class="enlighter-text"> VideoStream</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> numpy </span><span class="enlighter-k0">as</span><span class="enlighter-text"> np</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> argparse</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> imutils</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> time</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> cv2</span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k0">import</span><span class="enlighter-text"> os</span></div></div></div><div class="enlighter-raw"># import the necessary packages
from imutils.video import VideoStream
import numpy as np
import argparse
import imutils
import time
import cv2
import os</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Instance segmentation with OpenCV" data-enlighter-group="8"># import the necessary packages
from imutils.video import VideoStream
import numpy as np
import argparse
import imutils
import time
import cv2
import os
</pre>


<p>We’ll start off the script by importing our necessary packages. You need the following installed in your environment (virtual environments are highly recommended):</p>
<ul>
<li><a href="https://opencv.org/" target="_blank" rel="noopener noreferrer">OpenCV</a> 3.4.2+ — If you don’t have OpenCV installed, head over to my <a href="https://pyimagesearch.com/opencv-tutorials-resources-guides/" target="_blank" rel="noopener noreferrer">installation tutorials page</a>. The fastest method for installing on most systems is <a href="https://pyimagesearch.com/2018/09/19/pip-install-opencv/" target="_blank" rel="noopener noreferrer">via pip</a> which will install OpenCV 3.4.3 at the time of this writing.</li>
<li><a href="https://github.com/jrosebr1/imutils" target="_blank" rel="noopener noreferrer">imutils</a> — This is my personal package of computer vision convenience functions. You may install imutils via: <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">pip install --upgrade imutils</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell">pip install --upgrade imutils</code> .</li>
</ul>
<p>Again, I highly recommend that you place this software in an isolated virtual environment as you may need to accommodate for different versions for other projects.</p>
<p>Let’s parse our <a href="https://pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/" target="_blank" rel="noopener noreferrer">command line arguments</a>:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Instance segmentation with OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 9"><div class=""><div><span class="enlighter-c0"># construct the argument parse and parse the arguments</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap = argparse.</span><span class="enlighter-m1">ArgumentParser</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap.</span><span class="enlighter-m1">add_argument</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"-m"</span><span class="enlighter-text">, </span><span class="enlighter-s0">"--mask-rcnn"</span><span class="enlighter-text">, required=</span><span class="enlighter-e0">True</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">	help=</span><span class="enlighter-s0">"base path to mask-rcnn directory"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap.</span><span class="enlighter-m1">add_argument</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"-c"</span><span class="enlighter-text">, </span><span class="enlighter-s0">"--confidence"</span><span class="enlighter-text">, type=float, default=</span><span class="enlighter-n0">0.5</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">	help=</span><span class="enlighter-s0">"minimum probability to filter weak detections"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap.</span><span class="enlighter-m1">add_argument</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"-t"</span><span class="enlighter-text">, </span><span class="enlighter-s0">"--threshold"</span><span class="enlighter-text">, type=float, default=</span><span class="enlighter-n0">0.3</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">	help=</span><span class="enlighter-s0">"minimum threshold for pixel-wise mask segmentation"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">ap.</span><span class="enlighter-m1">add_argument</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"-k"</span><span class="enlighter-text">, </span><span class="enlighter-s0">"--kernel"</span><span class="enlighter-text">, type=int, default=</span><span class="enlighter-n1">41</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">	help=</span><span class="enlighter-s0">"size of gaussian blur kernel"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">args = </span><span class="enlighter-m0">vars</span><span class="enlighter-g1">(</span><span class="enlighter-text">ap.</span><span class="enlighter-m1">parse_args</span><span class="enlighter-g1">())</span></div></div></div><div class="enlighter-raw"># construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-m", "--mask-rcnn", required=True,
	help="base path to mask-rcnn directory")
ap.add_argument("-c", "--confidence", type=float, default=0.5,
	help="minimum probability to filter weak detections")
ap.add_argument("-t", "--threshold", type=float, default=0.3,
	help="minimum threshold for pixel-wise mask segmentation")
ap.add_argument("-k", "--kernel", type=int, default=41,
	help="size of gaussian blur kernel")
args = vars(ap.parse_args())</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="10" data-enlighter-title="Instance segmentation with OpenCV" data-enlighter-group="10"># construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-m", "--mask-rcnn", required=True,
	help="base path to mask-rcnn directory")
ap.add_argument("-c", "--confidence", type=float, default=0.5,
	help="minimum probability to filter weak detections")
ap.add_argument("-t", "--threshold", type=float, default=0.3,
	help="minimum threshold for pixel-wise mask segmentation")
ap.add_argument("-k", "--kernel", type=int, default=41,
	help="size of gaussian blur kernel")
args = vars(ap.parse_args())
</pre>


<p>Descriptions of each command line argument can be found below:</p>
<ul>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">--mask-rcnn</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">--mask-rcnn</code> : The base path to the Mask R-CNN directory. We reviewed the three files in this directory in the <em>“Project structure”</em> section above.</li>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">--confidence</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">--confidence</code> : The minimum probability to filter out weak detections. I’ve set this value to a default of <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">0.</span><span class="enlighter-n1">5</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">0.5</code> , but you can easily pass different values via the command line.</li>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">--threshold</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">--threshold</code> : Our minimum threshold for the pixel-wise mask segmentation. The default is set to <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">0.</span><span class="enlighter-n1">3</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">0.3</code> .</li>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">--kernel</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">--kernel</code> : The size of the Gaussian blur kernel. I found that a <em>41 x 41</em> kernel looks pretty good, so a default of <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">41</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">41</code>  is set.</li>
</ul>
<p>For a review on how command line arguments work, be sure to <a href="https://pyimagesearch.com/2018/03/12/python-argparse-command-line-arguments/" target="_blank" rel="noopener noreferrer">read this guide</a>.</p>
<p>Let’s load our labels and our OpenCV instance segmentation model:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Instance segmentation with OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 21"><div class=""><div><span class="enlighter-c0"># load the COCO class labels our Mask R-CNN was trained on</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">labelsPath = os.path.sep.</span><span class="enlighter-m1">join</span><span class="enlighter-g1">([</span><span class="enlighter-text">args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"mask_rcnn"</span><span class="enlighter-g1">]</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-s0">"object_detection_classes_coco.txt"</span><span class="enlighter-g1">])</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">LABELS = </span><span class="enlighter-m0">open</span><span class="enlighter-g1">(</span><span class="enlighter-text">labelsPath</span><span class="enlighter-g1">)</span><span class="enlighter-text">.</span><span class="enlighter-m1">read</span><span class="enlighter-g1">()</span><span class="enlighter-text">.</span><span class="enlighter-m1">strip</span><span class="enlighter-g1">()</span><span class="enlighter-text">.</span><span class="enlighter-m1">split</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"\n"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># derive the paths to the Mask R-CNN weights and model configuration</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">weightsPath = os.path.sep.</span><span class="enlighter-m1">join</span><span class="enlighter-g1">([</span><span class="enlighter-text">args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"mask_rcnn"</span><span class="enlighter-g1">]</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-s0">"frozen_inference_graph.pb"</span><span class="enlighter-g1">])</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">configPath = os.path.sep.</span><span class="enlighter-m1">join</span><span class="enlighter-g1">([</span><span class="enlighter-text">args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"mask_rcnn"</span><span class="enlighter-g1">]</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-s0">"mask_rcnn_inception_v2_coco_2018_01_28.pbtxt"</span><span class="enlighter-g1">])</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># load our Mask R-CNN trained on the COCO dataset (90 classes)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># from disk</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-m0">print</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"[INFO] loading Mask R-CNN from disk..."</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">net = cv2.dnn.</span><span class="enlighter-m1">readNetFromTensorflow</span><span class="enlighter-g1">(</span><span class="enlighter-text">weightsPath, configPath</span><span class="enlighter-g1">)</span></div></div></div><div class="enlighter-raw"># load the COCO class labels our Mask R-CNN was trained on
labelsPath = os.path.sep.join([args["mask_rcnn"],
	"object_detection_classes_coco.txt"])
LABELS = open(labelsPath).read().strip().split("\n")

# derive the paths to the Mask R-CNN weights and model configuration
weightsPath = os.path.sep.join([args["mask_rcnn"],
	"frozen_inference_graph.pb"])
configPath = os.path.sep.join([args["mask_rcnn"],
	"mask_rcnn_inception_v2_coco_2018_01_28.pbtxt"])

# load our Mask R-CNN trained on the COCO dataset (90 classes)
# from disk
print("[INFO] loading Mask R-CNN from disk...")
net = cv2.dnn.readNetFromTensorflow(weightsPath, configPath)</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="22" data-enlighter-title="Instance segmentation with OpenCV" data-enlighter-group="18"># load the COCO class labels our Mask R-CNN was trained on
labelsPath = os.path.sep.join([args["mask_rcnn"],
	"object_detection_classes_coco.txt"])
LABELS = open(labelsPath).read().strip().split("\n")

# derive the paths to the Mask R-CNN weights and model configuration
weightsPath = os.path.sep.join([args["mask_rcnn"],
	"frozen_inference_graph.pb"])
configPath = os.path.sep.join([args["mask_rcnn"],
	"mask_rcnn_inception_v2_coco_2018_01_28.pbtxt"])

# load our Mask R-CNN trained on the COCO dataset (90 classes)
# from disk
print("[INFO] loading Mask R-CNN from disk...")
net = cv2.dnn.readNetFromTensorflow(weightsPath, configPath)
</pre>


<p>Our labels file needs to be located in the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">mask-rcnn-coco/</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">mask-rcnn-coco/</code>  directory — the directory specified via command line argument. <strong>Lines 23 and 24</strong> build the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">labelsPath</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">labelsPath</code>  and then <strong>Line 25</strong> reads the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">LABELS</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">LABELS</code>  into a list.</p>
<p>The same goes for our <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">weightsPath</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">weightsPath</code>  and <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">configPath</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">configPath</code>  which are built on <strong>Lines 28-</strong><strong>31</strong>.</p>
<p>Using these two paths, we take advantage of the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">dnn</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">dnn</code>  module to initialize the neural <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">net</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">net</code>  (<strong>Line 36</strong>). This call loads the Mask R-CNN into memory before we start processing frames (we only need to load it once).</p>
<p>Let’s construct our blur kernel and start our webcam video stream:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Instance segmentation with OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 37"><div class=""><div><span class="enlighter-c0"># construct the kernel for the Gaussian blur and initialize whether</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># or not we are in "privacy mode"</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">K = </span><span class="enlighter-g1">(</span><span class="enlighter-text">args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"kernel"</span><span class="enlighter-g1">]</span><span class="enlighter-text">, args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"kernel"</span><span class="enlighter-g1">])</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">privacy = </span><span class="enlighter-e0">False</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># initialize the video stream, then allow the camera sensor to warm up</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-m0">print</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"[INFO] starting video stream..."</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">vs = </span><span class="enlighter-m0">VideoStream</span><span class="enlighter-g1">(</span><span class="enlighter-text">src=</span><span class="enlighter-n1">0</span><span class="enlighter-g1">)</span><span class="enlighter-text">.</span><span class="enlighter-m1">start</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">time.</span><span class="enlighter-m1">sleep</span><span class="enlighter-g1">(</span><span class="enlighter-n0">2.0</span><span class="enlighter-g1">)</span></div></div></div><div class="enlighter-raw"># construct the kernel for the Gaussian blur and initialize whether
# or not we are in "privacy mode"
K = (args["kernel"], args["kernel"])
privacy = False

# initialize the video stream, then allow the camera sensor to warm up
print("[INFO] starting video stream...")
vs = VideoStream(src=0).start()
time.sleep(2.0)</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="38" data-enlighter-title="Instance segmentation with OpenCV" data-enlighter-group="26"># construct the kernel for the Gaussian blur and initialize whether
# or not we are in "privacy mode"
K = (args["kernel"], args["kernel"])
privacy = False

# initialize the video stream, then allow the camera sensor to warm up
print("[INFO] starting video stream...")
vs = VideoStream(src=0).start()
time.sleep(2.0)
</pre>


<p>The blur kernel tuple is defined on <strong>Line 40</strong>.</p>
<p>Our project has two modes: “normal mode” and “privacy mode”. Thus, a <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">privacy</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">privacy</code>  boolean is used for the mode logic. It is initialized to <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-e0">False</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">False</code>  on <strong>Line 41</strong>.</p>
<p>Our webcam video stream is started on <strong>Line 45</strong> where we pause for two seconds to allow the sensor to warm up (<strong>Line 46</strong>).</p>
<p>Now that all of our variables and objects are initialized, let’s start processing frames from the webcam:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Instance segmentation with OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 47"><div class=""><div><span class="enlighter-c0"># loop over frames from the video file stream</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-k1">while</span><span class="enlighter-text"> </span><span class="enlighter-e0">True</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># grab the frame from the threaded video stream</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	frame = vs.</span><span class="enlighter-m1">read</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># resize the frame to have a width of 600 pixels (while</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># maintaining the aspect ratio), and then grab the image</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># dimensions</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	frame = imutils.</span><span class="enlighter-m1">resize</span><span class="enlighter-g1">(</span><span class="enlighter-text">frame, width=</span><span class="enlighter-n1">600</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-g1">(</span><span class="enlighter-text">H, W</span><span class="enlighter-g1">)</span><span class="enlighter-text"> = frame.shape</span><span class="enlighter-g1">[</span><span class="enlighter-text">:</span><span class="enlighter-n1">2</span><span class="enlighter-g1">]</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># construct a blob from the input image and then perform a</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># forward pass of the Mask R-CNN, giving us (1) the bounding</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># box coordinates of the objects in the image along with (2)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># the pixel-wise segmentation for each specific object</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	blob = cv2.dnn.</span><span class="enlighter-m1">blobFromImage</span><span class="enlighter-g1">(</span><span class="enlighter-text">frame, swapRB=</span><span class="enlighter-e0">True</span><span class="enlighter-text">, crop=</span><span class="enlighter-e0">False</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	net.</span><span class="enlighter-m1">setInput</span><span class="enlighter-g1">(</span><span class="enlighter-text">blob</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-g1">(</span><span class="enlighter-text">boxes, masks</span><span class="enlighter-g1">)</span><span class="enlighter-text"> = net.</span><span class="enlighter-m1">forward</span><span class="enlighter-g1">([</span><span class="enlighter-s0">"detection_out_final"</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-s0">"detection_masks"</span><span class="enlighter-g1">])</span></div></div></div><div class="enlighter-raw"># loop over frames from the video file stream
while True:
	# grab the frame from the threaded video stream
	frame = vs.read()

	# resize the frame to have a width of 600 pixels (while
	# maintaining the aspect ratio), and then grab the image
	# dimensions
	frame = imutils.resize(frame, width=600)
	(H, W) = frame.shape[:2]

	# construct a blob from the input image and then perform a
	# forward pass of the Mask R-CNN, giving us (1) the bounding
	# box coordinates of the objects in the image along with (2)
	# the pixel-wise segmentation for each specific object
	blob = cv2.dnn.blobFromImage(frame, swapRB=True, crop=False)
	net.setInput(blob)
	(boxes, masks) = net.forward(["detection_out_final",
		"detection_masks"])</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="48" data-enlighter-title="Instance segmentation with OpenCV" data-enlighter-group="29"># loop over frames from the video file stream
while True:
	# grab the frame from the threaded video stream
	frame = vs.read()

	# resize the frame to have a width of 600 pixels (while
	# maintaining the aspect ratio), and then grab the image
	# dimensions
	frame = imutils.resize(frame, width=600)
	(H, W) = frame.shape[:2]

	# construct a blob from the input image and then perform a
	# forward pass of the Mask R-CNN, giving us (1) the bounding
	# box coordinates of the objects in the image along with (2)
	# the pixel-wise segmentation for each specific object
	blob = cv2.dnn.blobFromImage(frame, swapRB=True, crop=False)
	net.setInput(blob)
	(boxes, masks) = net.forward(["detection_out_final",
		"detection_masks"])
</pre>


<p>Our frame processing loop begins on <strong>Line 49</strong>.</p>
<p>At each iteration, we’ll grab a <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">frame</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">frame</code>  (<strong>Line 51</strong>) and <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">resize</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">resize</code>  it to a known width, maintaining aspect ratio (<strong>Line 56</strong>).</p>
<p>For scaling purposes later, we go ahead and extract the dimensions of the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">frame</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">frame</code>  (<strong>Line 57</strong>).</p>
<p>Then, we construct a <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">blob</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">blob</code>  and complete a forward pass through the network (<strong>Lines 63-66</strong>). You can read more about how this process works in this <a href="https://pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/" target="_blank" rel="noopener noreferrer">previous blog post</a>.</p>
<p>The result is both <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">boxes</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">boxes</code>  and <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">masks</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">masks</code> . We’ll be taking advantage of the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">masks</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">masks</code> , but we also need to use the data contained in <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">boxes</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">boxes</code> .</p>
<p>Let’s sort the indexes and initialize variables:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Instance segmentation with OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 67"><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># sort the indexes of the bounding boxes in by their corresponding</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># prediction probability (in descending order)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	idxs = np.</span><span class="enlighter-m1">argsort</span><span class="enlighter-g1">(</span><span class="enlighter-text">boxes</span><span class="enlighter-g1">[</span><span class="enlighter-n1">0</span><span class="enlighter-text">, </span><span class="enlighter-n1">0</span><span class="enlighter-text">, :, </span><span class="enlighter-n1">2</span><span class="enlighter-g1">])[</span><span class="enlighter-text">::</span><span class="enlighter-n1">-1</span><span class="enlighter-g1">]</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># initialize the mask, ROI, and coordinates of the person for the</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># current frame</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	mask = </span><span class="enlighter-e1">None</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	roi = </span><span class="enlighter-e1">None</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	coords = </span><span class="enlighter-e1">None</span></div></div></div><div class="enlighter-raw">	# sort the indexes of the bounding boxes in by their corresponding
	# prediction probability (in descending order)
	idxs = np.argsort(boxes[0, 0, :, 2])[::-1]

	# initialize the mask, ROI, and coordinates of the person for the
	# current frame
	mask = None
	roi = None
	coords = None</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="68" data-enlighter-title="Instance segmentation with OpenCV" data-enlighter-group="38">	# sort the indexes of the bounding boxes in by their corresponding
	# prediction probability (in descending order)
	idxs = np.argsort(boxes[0, 0, :, 2])[::-1]

	# initialize the mask, ROI, and coordinates of the person for the
	# current frame
	mask = None
	roi = None
	coords = None
</pre>


<p><strong>Line 70 </strong>sorts the indexes of the bounding boxes by their corresponding prediction probability. We’ll be making the assumption that the person with the largest corresponding detection probability is our user.</p>
<p>We then initialize the  <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">mask</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">mask</code> , <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">roi</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">roi</code> , and bounding box <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">coords</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">coords</code>  (<strong>Lines 74-76</strong>).</p>
<p>Let’s loop over the indexes and filter the results:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Instance segmentation with OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 77"><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># loop over the indexes</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-k1">for</span><span class="enlighter-text"> i </span><span class="enlighter-k0">in</span><span class="enlighter-text"> idxs:</span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># extract the class ID of the detection along with the</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># confidence (i.e., probability) associated with the</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># prediction</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		classID = </span><span class="enlighter-m0">int</span><span class="enlighter-g1">(</span><span class="enlighter-text">boxes</span><span class="enlighter-g1">[</span><span class="enlighter-n1">0</span><span class="enlighter-text">, </span><span class="enlighter-n1">0</span><span class="enlighter-text">, i, </span><span class="enlighter-n1">1</span><span class="enlighter-g1">])</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		confidence = boxes</span><span class="enlighter-g1">[</span><span class="enlighter-n1">0</span><span class="enlighter-text">, </span><span class="enlighter-n1">0</span><span class="enlighter-text">, i, </span><span class="enlighter-n1">2</span><span class="enlighter-g1">]</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># if the detection is not the 'person' class, ignore it</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-k1">if</span><span class="enlighter-text"> LABELS</span><span class="enlighter-g1">[</span><span class="enlighter-text">classID</span><span class="enlighter-g1">]</span><span class="enlighter-text"> != </span><span class="enlighter-s0">"person"</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-k1">continue</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># filter out weak predictions by ensuring the detected</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># probability is greater than the minimum probability</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-k1">if</span><span class="enlighter-text"> confidence </span><span class="enlighter-g1">&gt;</span><span class="enlighter-text"> args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"confidence"</span><span class="enlighter-g1">]</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># scale the bounding box coordinates back relative to the</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># size of the image and then compute the width and the</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># height of the bounding box</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			box = boxes</span><span class="enlighter-g1">[</span><span class="enlighter-n1">0</span><span class="enlighter-text">, </span><span class="enlighter-n1">0</span><span class="enlighter-text">, i, </span><span class="enlighter-n1">3</span><span class="enlighter-text">:</span><span class="enlighter-n1">7</span><span class="enlighter-g1">]</span><span class="enlighter-text"> * np.</span><span class="enlighter-m1">array</span><span class="enlighter-g1">([</span><span class="enlighter-text">W, H, W, H</span><span class="enlighter-g1">])</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-g1">(</span><span class="enlighter-text">startX, startY, endX, endY</span><span class="enlighter-g1">)</span><span class="enlighter-text"> = box.</span><span class="enlighter-m1">astype</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"int"</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			coords = </span><span class="enlighter-g1">(</span><span class="enlighter-text">startX, startY, endX, endY</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			boxW = endX - startX</span></div></div><div class=""><div><span class="enlighter-text">			boxH = endY - startY</span></div></div></div><div class="enlighter-raw">	# loop over the indexes
	for i in idxs:
		# extract the class ID of the detection along with the
		# confidence (i.e., probability) associated with the
		# prediction
		classID = int(boxes[0, 0, i, 1])
		confidence = boxes[0, 0, i, 2]

		# if the detection is not the 'person' class, ignore it
		if LABELS[classID] != "person":
			continue

		# filter out weak predictions by ensuring the detected
		# probability is greater than the minimum probability
		if confidence &gt; args["confidence"]:
			# scale the bounding box coordinates back relative to the
			# size of the image and then compute the width and the
			# height of the bounding box
			box = boxes[0, 0, i, 3:7] * np.array([W, H, W, H])
			(startX, startY, endX, endY) = box.astype("int")
			coords = (startX, startY, endX, endY)
			boxW = endX - startX
			boxH = endY - startY</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="78" data-enlighter-title="Instance segmentation with OpenCV" data-enlighter-group="42">	# loop over the indexes
	for i in idxs:
		# extract the class ID of the detection along with the
		# confidence (i.e., probability) associated with the
		# prediction
		classID = int(boxes[0, 0, i, 1])
		confidence = boxes[0, 0, i, 2]

		# if the detection is not the 'person' class, ignore it
		if LABELS[classID] != "person":
			continue

		# filter out weak predictions by ensuring the detected
		# probability is greater than the minimum probability
		if confidence &gt; args["confidence"]:
			# scale the bounding box coordinates back relative to the
			# size of the image and then compute the width and the
			# height of the bounding box
			box = boxes[0, 0, i, 3:7] * np.array([W, H, W, H])
			(startX, startY, endX, endY) = box.astype("int")
			coords = (startX, startY, endX, endY)
			boxW = endX - startX
			boxH = endY - startY
</pre>


<p>We begin looping over the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">idxs</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">idxs</code>  on <strong>Line 79</strong>.</p>
<p>We then extract the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">classID</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">classID</code>  and <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">confidence</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">confidence</code>  using <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">boxes</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">boxes</code>  and the current index (<strong>Lines 83 and 84</strong>).</p>
<p>Subsequently, we’ll perform our first filter — we only care about the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-s0">"person"</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">"person"</code>  class. If any other object class is encountered, we’ll continue to the next index (<strong>Lines 87 and 88</strong>).</p>
<p>Our next filter ensures the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">confidence</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">confidence</code>  of the prediction exceeds the threshold set via command line arguments (<strong>Line 92</strong>).</p>
<p>If we pass that test, then we’ll scale the bounding <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">box</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">box</code>  coordinates back to the relative dimensions of the image (<strong>Lines 96</strong>). We then extract the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">coords</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">coords</code>  and object width/height (<strong>Lines 97-100</strong>).</p>
<p>Let’s compute our mask and extract the ROI:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Instance segmentation with OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 101"><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># extract the pixel-wise segmentation for the object,</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># resize the mask such that it's the same dimensions of</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># the bounding box, and then finally threshold to create</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># a *binary* mask</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			mask = masks</span><span class="enlighter-g1">[</span><span class="enlighter-text">i, classID</span><span class="enlighter-g1">]</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			mask = cv2.</span><span class="enlighter-m1">resize</span><span class="enlighter-g1">(</span><span class="enlighter-text">mask, </span><span class="enlighter-g1">(</span><span class="enlighter-text">boxW, boxH</span><span class="enlighter-g1">)</span><span class="enlighter-text">,</span></div></div><div class=""><div><span class="enlighter-text">				interpolation=cv2.INTER_NEAREST</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			mask = </span><span class="enlighter-g1">(</span><span class="enlighter-text">mask </span><span class="enlighter-g1">&gt;</span><span class="enlighter-text"> args</span><span class="enlighter-g1">[</span><span class="enlighter-s0">"threshold"</span><span class="enlighter-g1">])</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># extract the ROI and break from the loop (since we make</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># the assumption there is only *one* person in the frame</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># who is also the person with the highest prediction</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-c0"># confidence)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			roi = frame</span><span class="enlighter-g1">[</span><span class="enlighter-text">startY:endY, startX:endX</span><span class="enlighter-g1">][</span><span class="enlighter-text">mask</span><span class="enlighter-g1">]</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">			</span><span class="enlighter-k1">break</span></div></div></div><div class="enlighter-raw">			# extract the pixel-wise segmentation for the object,
			# resize the mask such that it's the same dimensions of
			# the bounding box, and then finally threshold to create
			# a *binary* mask
			mask = masks[i, classID]
			mask = cv2.resize(mask, (boxW, boxH),
				interpolation=cv2.INTER_NEAREST)
			mask = (mask &gt; args["threshold"])

			# extract the ROI and break from the loop (since we make
			# the assumption there is only *one* person in the frame
			# who is also the person with the highest prediction
			# confidence)
			roi = frame[startY:endY, startX:endX][mask]
			break</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="102" data-enlighter-title="Instance segmentation with OpenCV" data-enlighter-group="51">			# extract the pixel-wise segmentation for the object,
			# resize the mask such that it's the same dimensions of
			# the bounding box, and then finally threshold to create
			# a *binary* mask
			mask = masks[i, classID]
			mask = cv2.resize(mask, (boxW, boxH),
				interpolation=cv2.INTER_NEAREST)
			mask = (mask &gt; args["threshold"])

			# extract the ROI and break from the loop (since we make
			# the assumption there is only *one* person in the frame
			# who is also the person with the highest prediction
			# confidence)
			roi = frame[startY:endY, startX:endX][mask]
			break
</pre>


<p><strong>Lines 106-109</strong> extract the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">mask</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">mask</code> , resize it, and apply the threshold to create the binary mask itself. An example mask is shown in <strong>Figure 2</strong><strong>:</strong></p>
<figure id="attachment_9076" aria-describedby="caption-attachment-9076" style="width: 277px" class="wp-caption aligncenter"><a href="https://pyimagesearch.com/wp-content/uploads/2018/11/mask.png"><img class="size-full wp-image-9076 entered lazyloaded" src="./Instance segmentation with OpenCV - PyImageSearch_files/mask.png" alt="" width="277" height="323" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask.png?size=126x147&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask-257x300.png?lossy=1&amp;strip=1&amp;webp=1 257w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask.png?lossy=1&amp;strip=1&amp;webp=1 277w" data-lazy-sizes="(max-width: 277px) 100vw, 277px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask.png?lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" sizes="(max-width: 277px) 100vw, 277px" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask.png?size=126x147&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask-257x300.png?lossy=1&amp;strip=1&amp;webp=1 257w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask.png?lossy=1&amp;strip=1&amp;webp=1 277w"><noscript><img class="size-full wp-image-9076" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask.png?lossy=1&strip=1&webp=1" alt="" width="277" height="323" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask.png?size=126x147&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask-257x300.png?lossy=1&amp;strip=1&amp;webp=1 257w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask.png?lossy=1&amp;strip=1&amp;webp=1 277w" sizes="(max-width: 277px) 100vw, 277px" /></noscript></a><figcaption id="caption-attachment-9076" class="wp-caption-text"><strong>Figure 2:</strong> The binary mask computed via instance segmentation of me in front of my webcam using OpenCV and instance segmentation. Computing the mask is part of the privacy filter pipeline.</figcaption></figure>
<p>In <strong>Figure 2</strong> above all white pixels are assumed to be a <em>person</em> (i.e., the foreground) while all black pixels are the <em>background.</em></p>
<p>With the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">mask</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">mask</code> , we’ll also compute the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">roi</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">roi</code>  (<strong>Line 115</strong>) via NumPy array slicing.</p>
<p>We then <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-k1">break</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">break</code>  from the loop on <strong>Line 116</strong> (since we have found the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-s0">"person"</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">"person"</code>  with the largest probability).</p>
<p>Let’s initialize our output frame and compute our blur if we are in “privacy mode”:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Instance segmentation with OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 117"><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># initialize our output frame</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	output = frame.</span><span class="enlighter-m1">copy</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># if the mask is not None *and* we are in privacy mode, then we</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># know we can apply the mask and ROI to the output image</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-k1">if</span><span class="enlighter-text"> mask </span><span class="enlighter-k0">is</span><span class="enlighter-text"> </span><span class="enlighter-k3">not</span><span class="enlighter-text"> </span><span class="enlighter-e1">None</span><span class="enlighter-text"> </span><span class="enlighter-k3">and</span><span class="enlighter-text"> privacy:</span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># blur the output frame</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		output = cv2.</span><span class="enlighter-m1">GaussianBlur</span><span class="enlighter-g1">(</span><span class="enlighter-text">output, K, </span><span class="enlighter-n1">0</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-c0"># add the ROI to the output frame for only the masked region</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-g1">(</span><span class="enlighter-text">startX, startY, endX, endY</span><span class="enlighter-g1">)</span><span class="enlighter-text"> = coords</span></div></div><div class=""><div><span class="enlighter-text">		output</span><span class="enlighter-g1">[</span><span class="enlighter-text">startY:endY, startX:endX</span><span class="enlighter-g1">][</span><span class="enlighter-text">mask</span><span class="enlighter-g1">]</span><span class="enlighter-text"> = roi</span></div></div></div><div class="enlighter-raw">	# initialize our output frame
	output = frame.copy()

	# if the mask is not None *and* we are in privacy mode, then we
	# know we can apply the mask and ROI to the output image
	if mask is not None and privacy:
		# blur the output frame
		output = cv2.GaussianBlur(output, K, 0)

		# add the ROI to the output frame for only the masked region
		(startX, startY, endX, endY) = coords
		output[startY:endY, startX:endX][mask] = roi</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="118" data-enlighter-title="Instance segmentation with OpenCV" data-enlighter-group="57">	# initialize our output frame
	output = frame.copy()

	# if the mask is not None *and* we are in privacy mode, then we
	# know we can apply the mask and ROI to the output image
	if mask is not None and privacy:
		# blur the output frame
		output = cv2.GaussianBlur(output, K, 0)

		# add the ROI to the output frame for only the masked region
		(startX, startY, endX, endY) = coords
		output[startY:endY, startX:endX][mask] = roi
</pre>


<p>Our <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">output</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">output</code>  frame is simply a <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">copy</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">copy</code>  of the original <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">frame</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">frame</code>  (<strong>Line 119</strong>).</p>
<p>If we both:</p>
<ol>
<li>Have a <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">mask</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">mask</code>  that is not empty</li>
<li>And we are in ” <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">privacy</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">privacy</code>  mode”…</li>
</ol>
<p>…then we’ll blur the background (using our kernel) and apply the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">mask</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">mask</code>  to the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">output</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">output</code>  frame (<strong>Lines 123-129</strong>).</p>
<p>Now let’s display the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">output</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">output</code>  image and handle keypresses:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Instance segmentation with OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style="counter-reset: enlighter 130"><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># show the output frame</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	cv2.</span><span class="enlighter-m1">imshow</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"Video Call"</span><span class="enlighter-text">, output</span><span class="enlighter-g1">)</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	key = cv2.</span><span class="enlighter-m1">waitKey</span><span class="enlighter-g1">(</span><span class="enlighter-n1">1</span><span class="enlighter-g1">)</span><span class="enlighter-text"> &amp; </span><span class="enlighter-n2">0xFF</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># if the `p` key was pressed, toggle privacy mode</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-k1">if</span><span class="enlighter-text"> key == </span><span class="enlighter-m0">ord</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"p"</span><span class="enlighter-g1">)</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text">		privacy = </span><span class="enlighter-k3">not</span><span class="enlighter-text"> privacy</span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-c0"># if the `q` key was pressed, break from the loop</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">	</span><span class="enlighter-k1">elif</span><span class="enlighter-text"> key == </span><span class="enlighter-m0">ord</span><span class="enlighter-g1">(</span><span class="enlighter-s0">"q"</span><span class="enlighter-g1">)</span><span class="enlighter-text">:</span></div></div><div class=""><div><span class="enlighter-text">		</span><span class="enlighter-k1">break</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text"></span><span class="enlighter-c0"># do a bit of cleanup</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">cv2.</span><span class="enlighter-m1">destroyAllWindows</span><span class="enlighter-g1">()</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">vs.</span><span class="enlighter-m1">stop</span><span class="enlighter-g1">()</span></div></div></div><div class="enlighter-raw">	# show the output frame
	cv2.imshow("Video Call", output)
	key = cv2.waitKey(1) &amp; 0xFF

	# if the `p` key was pressed, toggle privacy mode
	if key == ord("p"):
		privacy = not privacy

	# if the `q` key was pressed, break from the loop
	elif key == ord("q"):
		break

# do a bit of cleanup
cv2.destroyAllWindows()
vs.stop()</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="131" data-enlighter-title="Instance segmentation with OpenCV" data-enlighter-group="66">	# show the output frame
	cv2.imshow("Video Call", output)
	key = cv2.waitKey(1) &amp; 0xFF

	# if the `p` key was pressed, toggle privacy mode
	if key == ord("p"):
		privacy = not privacy

	# if the `q` key was pressed, break from the loop
	elif key == ord("q"):
		break

# do a bit of cleanup
cv2.destroyAllWindows()
vs.stop()
</pre>


<p>Our <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">output</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">output</code>  frame is displayed via <strong>Line 132</strong>.</p>
<p>Keypresses are captured (<strong>Line 133</strong>). Two keys cause different behaviors (<strong>Lines 136-141</strong>):</p>
<ul>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-s0">"p"</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">"p"</code> : When this key is pressed, “<div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">privacy</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">privacy</code>  mode” is toggled either on or off.</li>
<li><div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-s0">"q"</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">"q"</code> : If this key is pressed, we’ll break out of the loop and “quit” the script.</li>
</ul>
<p>Whenever we do quit, <strong>Lines 144</strong><strong> and 145</strong> close the open window and stop the video stream.</p>
<h3>Instance segmentation results</h3>
<p>Now that we’ve implemented our OpenCV instance segmentation algorithm, let’s see it in action!</p>
<p>Be sure to use the <em><strong>“Downloads”</strong></em> section of this blog post to download the code and Mask R-CNN model.</p>
<p>From there, open up a terminal and execute the following command:</p>


<a class="run-on-colab pyis-cta-modal-open-modal" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#download-the-code" style="color: #FFFFFF;">                     → <span>Launch Jupyter Notebook on Google Colab</span>                 </a><div class="enlighter-default enlighter-v-codegroup enlighter-t-pyis-enlighter-theme enlighter-linenumbers "><div class="enlighter-codegroup-switch"><div class="enlighter-btn enlighter-active">Instance segmentation with OpenCV</div></div><div class="enlighter-codegroup-wrapper"><div class="enlighter-toolbar-top enlighter-toolbar"><div class="enlighter-btn enlighter-btn-raw" title="Plain text"></div><div class="enlighter-btn enlighter-btn-copy" title="Copy to clipboard"></div><div class="enlighter-btn enlighter-btn-window" title="Open code in new window"></div><div class="enlighter-btn enlighter-btn-website" title="EnlighterJS 3 Syntax Highlighter"></div></div><div style="display: block;"><div class="enlighter" style=""><div class=""><div><span class="enlighter-text">$ python instance_segmentation.py --mask-rcnn mask-rcnn-coco --kernel </span><span class="enlighter-n1">41</span><span class="enlighter-text"></span></div></div><div class=""><div><span class="enlighter-text">[INFO] loading Mask R-CNN from disk...</span></div></div><div class=""><div><span class="enlighter-text">[INFO] starting video stream...</span></div></div></div><div class="enlighter-raw">$ python instance_segmentation.py --mask-rcnn mask-rcnn-coco --kernel 41
[INFO] loading Mask R-CNN from disk...
[INFO] starting video stream...</div></div><div class="enlighter-toolbar-bottom enlighter-toolbar"></div></div></div><pre class="EnlighterJSRAW enlighter-origin" data-enlighter-language="shell" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="true" data-enlighter-lineoffset="" data-enlighter-title="Instance segmentation with OpenCV" data-enlighter-group="71">$ python instance_segmentation.py --mask-rcnn mask-rcnn-coco --kernel 41
[INFO] loading Mask R-CNN from disk...
[INFO] starting video stream...
</pre>


<figure style="width: 400px" class="wp-caption aligncenter"><img src="./Instance segmentation with OpenCV - PyImageSearch_files/instance_segmentation_animation.gif" alt="" width="400" height="272" data-lazy-src="https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/opencv-instance-segmentation/instance_segmentation_animation.gif" data-ll-status="error" class="entered error"><noscript><img src="https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/opencv-instance-segmentation/instance_segmentation_animation.gif" alt="" width="400" height="272" /></noscript><figcaption class="wp-caption-text"><strong>Figure 3:</strong>&nbsp;My demonstration of a “privacy filter” for web chatting. I’ve used OpenCV and Python to perform instance segmentation to find the prominent person (me), and then applied blurring to the background.</figcaption></figure>
<p>Here you can see a short GIF of me demoing our instance segmentation pipeline.</p>
<p>In this image, I am meant to be the “conference call attendee”. Trisha, my wife, is working in the background.</p>
<p>By enabling “privacy mode” I can:</p>
<ol>
<li>Use OpenCV instance segmentation to find the person detection with the largest corresponding probability (most likely that will be the person closest to the camera).</li>
<li>Blur the background of the video stream.</li>
<li>Overlay the segmented, non-blurry person back onto the video stream.</li>
</ol>
<p>I have included a video demo, including my commentary, below:</p>
<p></p><div class="rll-youtube-player" data-src="https://www.youtube.com/embed/puSN8Dg-bdI" data-id="puSN8Dg-bdI" data-query="feature=oembed"><div data-id="puSN8Dg-bdI" data-query="feature=oembed" data-src="https://www.youtube.com/embed/puSN8Dg-bdI"><img data-lazy-src="https://i.ytimg.com/vi/puSN8Dg-bdI/hqdefault.jpg" alt="" width="480" height="360" data-ll-status="loaded" class="entered lazyloaded" src="./Instance segmentation with OpenCV - PyImageSearch_files/hqdefault.jpg"><noscript><img src="https://i.ytimg.com/vi/ID/hqdefault.jpg" alt="" width="480" height="360"></noscript><button class="play" aria-label="play Youtube video"></button></div></div><noscript><iframe title="Instance Segmentation with OpenCV Demo" width="630" height="473" src="https://www.youtube.com/embed/puSN8Dg-bdI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></noscript><p></p>
<p>You’ll immediately notice that we are not obtaining true real-time performance though — we’re only processing a few frames per second. Why is this?</p>
<p>How come our OpenCV instance segmentation pipeline isn’t faster?</p>
<p>To answer those questions, be sure to refer to the section below.</p>
<h3>Limitations, drawbacks, and potential improvements</h3>
<p>The first limitation is the most obvious one — <strong>our OpenCV instance segmentation implementation is too slow to run in real-time.</strong></p>
<p>On my Intel Xeon W we’re only processing a few frames per second.</p>
<p><strong>In order to obtain true real-time instance segmentation performance, we would need to leverage our GPU.</strong></p>
<p>But therein lies the problem:</p>
<p>OpenCV’s GPU support for its <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">dnn</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">dnn</code>&nbsp; module is fairly limited.</p>
<p>Currently, it mainly supports Intel GPUs.</p>
<p><strong>NVIDIA CUDA GPU support is in development, <em>but is currently not available.</em></strong></p>
<p>Once OpenCV officially supports NVIDIA GPUs for the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">dnn</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">dnn</code>&nbsp; module we’ll be more easily able to build real-time (and even super real-time) deep learning applications.</p>
<p>But for now, this OpenCV instance segmentation tutorial serves as an educational demo of:</p>
<ol>
<li>What’s <em>currently</em> possible</li>
<li>And what <em>will</em> be possible in a few months</li>
</ol>
<p>Another improvement we can make is related to the overlaying of the segmented person back on the blurred background.</p>
<p>When you compare our implementation to Microsoft’s Office 365 video blurring feature, you’ll see that Microsoft’s is much more “smooth”.</p>
<p>We can mimic this feature by utilizing a bit of alpha blending.</p>
<p>A simple yet effective update to our instance segmentation pipeline would be to potentially:</p>
<ol>
<li>Use morphological operations to increase the size of our mask</li>
<li>Apply a small amount of Gaussian blurring to the mask itself, helping smooth the mask</li>
<li>Scale the mask values to the range <em>[0, 1]</em></li>
<li>Create an alpha layer using the scaled mask</li>
<li>Overlay the smoothed mask + person ROI on the blurred background</li>
</ol>
<p>Alternatively, you could compute the contours of the mask itself and then apply contour approximation to help create a “more smoothed” mask.</p>
<p><strong>Please note that I have not tried this algorithm — it’s just something I thought of off the top of my head that I thought could give visually pleasing results.</strong></p>
<p>If you wish to implement this instance segmentation update I would suggest <a href="https://pyimagesearch.com/2018/11/05/creating-gifs-with-opencv/" target="_blank" rel="noopener noreferrer">reading this post</a> where I discuss alpha blending in more detail.</p>
<div id="pitch" style="padding: 40px; width: 100%; background-color: #F4F6FA;">
	<h3>What's next? I recommend <a target="_blank" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&amp;utm_medium=bottomBanner&amp;utm_campaign=What%27s%20next%3F%20I%20recommend">PyImageSearch University</a>.</h3>

	<div class="wistia_responsive_padding" style="padding:56.25% 0 0 0;position:relative;"><div class="wistia_responsive_wrapper" style="height:100%;left:0;position:absolute;top:0;width:100%;"><div class="wistia_video_foam_dummy" data-source-container-id="wistia-kno0cmko2z-1" style="border: 0px; display: block; height: 0px; margin: 0px; padding: 0px; position: static; visibility: hidden; width: auto;"></div><div class="wistia_embed wistia_async_kno0cmko2z videoFoam=true wistia_embed_initialized" style="height: 349px; position: relative; width: 622px;" id="wistia-kno0cmko2z-1"><div class="wistia_swatch" style="height: 100%; left: 0px; opacity: 1; overflow: hidden; position: absolute; top: 0px; transition: opacity 200ms ease 0s; width: 100%;"><img src="./Instance segmentation with OpenCV - PyImageSearch_files/swatch" style="filter:blur(5px);height:100%;object-fit:contain;width:100%;" alt="" aria-hidden="true" onload="this.parentNode.style.opacity=1;" data-lazy-src="https://fast.wistia.com/embed/medias/kno0cmko2z/swatch" data-ll-status="loaded" class="entered lazyloaded"><noscript><img src="https://fast.wistia.com/embed/medias/kno0cmko2z/swatch" style="filter:blur(5px);height:100%;object-fit:contain;width:100%;" alt="" aria-hidden="true" onload="this.parentNode.style.opacity=1;" /></noscript></div><div id="wistia_chrome_37" class="w-chrome" tabindex="-1" style="display: inline-block; height: 349px; line-height: normal; margin: 0px; padding: 0px; position: relative; vertical-align: top; width: 622px; zoom: 1; outline: none; overflow: hidden; box-sizing: content-box;"><div id="wistia_grid_46_wrapper" style="display: block; width: 622px; height: 349px;"><div id="wistia_grid_46_above" style="height: 0px; font-size: 0px; line-height: 0px;"> </div><div id="wistia_grid_46_main" style="width: 622px; left: 0px; height: 349px; margin-top: 0px;"><div id="wistia_grid_46_behind"></div><div id="wistia_grid_46_center" style="width: 100%; height: 100%;"><div class="w-video-wrapper w-css-reset" style="height: 100%; position: absolute; top: 0px; width: 100%; opacity: 1; background-color: rgb(0, 0, 0);"><video id="wistia_simple_video_127" crossorigin="anonymous" poster="https://fast.wistia.net/assets/images/blank.gif" aria-label="Video" src="https://embed-fastly.wistia.com/deliveries/b03c3cd4a5cad34b6596ce95b85891f80b1852f3/file.mp4" controlslist="nodownload" playsinline="" preload="none" type="video/mp4" x-webkit-airplay="allow" style="background: transparent; display: block; height: 100%; max-height: none; max-width: none; position: static; visibility: visible; width: 100%; object-fit: fill;"><source src="https://embed-fastly.wistia.com/deliveries/b03c3cd4a5cad34b6596ce95b85891f80b1852f3/file.mp4" type="video/mp4"></video></div><div class="w-ui-container" style="height: 100%; left: 0px; position: absolute; top: 0px; width: 100%; opacity: 1;"><div class="w-vulcan-v2 w-css-reset" id="w-vulcan-v2-45" style="box-sizing: border-box; cursor: default; height: 100%; left: 0px; position: absolute; visibility: visible; top: 0px; width: 100%;"><div class="w-vulcan--background w-css-reset" style="height: 100%; left: 0px; position: absolute; top: 0px; width: 100%;"><div class="w-css-reset" data-handle="statusBar"></div><div class="w-css-reset" data-handle="backgroundFocus"><button aria-label="Play Video" class="w-css-reset w-vulcan-v2-button" tabindex="0" style="width: 0px; height: 0px; pointer-events: none;"></button></div><div class="w-css-reset" data-handle="thumbnail"><div><div class="w-css-reset" style="filter: blur(5px); height: 100%; left: 0px; position: absolute; top: 0px; width: 100%; display: block;"><img class="w-css-reset" srcset="" src="./Instance segmentation with OpenCV - PyImageSearch_files/swatch(1)" alt="Video Thumbnail" aria-hidden="true" style="height: 349px; left: 0px; position: absolute; top: 0px; width: 622px; clip: auto; display: block; border-width: 0px; border-style: solid; border-color: rgb(0, 0, 0); box-sizing: content-box;"></div><div class="w-css-reset" style="height: 100%; left: 0px; opacity: 1; position: absolute; top: 0px; width: 100%; display: block; transition: opacity 3s ease 0s;"><img class="w-css-reset" srcset="https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=640x360 320w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=640x360 640w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=960x540 960w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=1280x720 1280w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=1920x1080 1920w, https://embed-fastly.wistia.com/deliveries/4bda0a1602c8b4d96d63a02617f3069e.webp?image_crop_resized=1920x1080 3840w" src="./Instance segmentation with OpenCV - PyImageSearch_files/4bda0a1602c8b4d96d63a02617f3069e.webp" alt="Video Thumbnail" style="height: 349px; left: 0px; position: absolute; top: 0px; width: 622px; clip: auto; display: block; border-width: 0px; border-style: solid; border-color: rgb(0, 0, 0); box-sizing: content-box;"></div></div></div></div><div aria-live="polite" class="w-vulcan--aria-live w-css-reset" aria-atomic="true" style="position: absolute; left: -99999em;"></div><div class="w-vulcan-overlays-table w-css-reset" style="display: table; pointer-events: none; position: absolute; width: 100%;"><div class="w-vulcan-overlays--left w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 0px;"><div class="w-css-reset" style="height: 316px;"></div></div><div class="w-vulcan-overlays--center w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 100%;"><div class="w-css-reset" style="height: 316px;"><div class="w-css-reset" data-handle="bigPlayButton" style="pointer-events: auto;"><div class="w-bpb-wrapper w-css-reset w-css-reset-tree" style="display: block; left: calc(50%); margin-left: -60.7422px; margin-top: -38.875px; position: absolute; top: calc(50%);"><button class="w-big-play-button w-css-reset-button-important w-vulcan-v2-button" aria-label="Play Video: Pyimagesearch_Sales_page w/out Autoplay" style="cursor: pointer; height: 77.75px; box-shadow: none; width: 121.484px;"><div style="background: rgb(30, 113, 231); display: block; left: 0px; height: 77.75px; mix-blend-mode: darken; position: absolute; top: 0px; width: 121.484px;"></div><div style="background-color: rgba(30, 113, 231, 0.7); height: 77.75px; left: 0px; position: absolute; top: 0px; transition: background-color 150ms ease 0s; width: 121.484px;"></div><svg x="0px" y="0px" viewBox="0 0 125 80" enable-background="new 0 0 125 80" focusable="false" alt="" style="fill: rgb(255, 255, 255); height: 77.75px; left: 0px; stroke-width: 0px; top: 0px; width: 100%; position: absolute;"><rect fill-rule="evenodd" clip-rule="evenodd" fill="none" width="125" height="80"></rect><polygon fill-rule="evenodd" clip-rule="evenodd" fill="#FFFFFF" points="53,22 53,58 79,40"></polygon></svg></button></div></div><div class="w-css-reset" data-handle="clickForSoundButton" style="pointer-events: auto;"><div class="w-css-reset w-css-reset-tree" data-handle="click-for-sound-backdrop" style="display: none; height: 100%; left: 0px; pointer-events: auto; position: absolute; top: 0px; width: 100%;"><button aria-label="Click for sound" class="w-vulcan-v2-button" style="background: rgba(0, 0, 0, 0.8); border: 2px solid transparent; border-radius: 50%; cursor: pointer; height: 51.0234px; width: 51.0234px; line-height: 51.0234px; outline: none; pointer-events: auto; position: absolute; right: 19.8672px; text-align: left; top: 19.8672px;"><svg viewBox="0 0 237 237"><style>
      @keyframes VOLUME_SMALL_WAVE_FLASH {
          0% { opacity: 0; }
         33% { opacity: 1; }
         66% { opacity: 1; }
        100% { opacity: 0; }
      }

      @keyframes VOLUME_LARGE_WAVE_FLASH {
          0% { opacity: 0; }
         33% { opacity: 1; }
         66% { opacity: 1; }
        100% { opacity: 0; }
      }

      .volume__small-wave {
        animation: VOLUME_SMALL_WAVE_FLASH 2s infinite;
        opacity: 0;
      }

      .volume__large-wave {
        animation: VOLUME_LARGE_WAVE_FLASH 2s infinite .3s;
        opacity: 0;
      }
    </style><polygon fill="white" points="88 107 65 107 65 131 89 131 112 154 112 84"></polygon><g fill="none" stroke="white" stroke-width="10" stroke-linecap="round"><path class="volume__small-wave" d="M 142 86 C 151 107 151 130 142 151"></path><path class="volume__large-wave" d="M 165 74 C 178 97 178 140 165 163"></path></g></svg></button></div></div><div class="w-css-reset" data-handle="playPauseNotifier" style="pointer-events: auto;"></div><div class="w-css-reset" data-handle="playPauseLoading" style="pointer-events: auto;"><div class="w-css-reset w-css-reset-tree" style="height: 100%; left: 0px; pointer-events: none; position: absolute; top: 0px; width: 100%;"><button aria-label="Play Video" class="w-vulcan-v2-button" style="background: rgba(0, 0, 0, 0.6); border: 0px; border-radius: 50%; cursor: pointer; display: none; height: 136.062px; left: 50%; margin: 0px; padding: 0px; pointer-events: auto; position: absolute; opacity: 0; outline: none; top: 50%; transform: translate(-50%, -50%) scale(0.8); transition: opacity 200ms ease 0s, transform 600ms ease 0s; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); width: 136.062px;"><div style="box-sizing: border-box; height: 100%; padding: 45.9211px 45.9211px 45.9211px 56.1258px;"><div style="height: 100%; width: 100%;"><div style="display: none; height: 100%; width: 100%;"><svg x="0px" y="0px" viewBox="0 0 11.556 16" enable-background="new 0 0 11.556 16" class="w-css-reset w-css-reset-tree" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><g><rect x="0" y="0" width="3.5" height="12"></rect><rect x="6.5" y="0" width="3.5" height="12"></rect></g></svg></div><div style="display: block; height: 100%; width: 100%;"><svg x="0px" y="0px" viewBox="0 0 11.556 16" enable-background="new 0 0 11.556 16" class="w-css-reset w-css-reset-tree" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><polygon points="11.556,7.5 0,15 0,0"></polygon></svg></div></div></div></button></div></div></div></div><div class="w-vulcan-overlays--right w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 0px;"><div class="w-css-reset" style="height: 316px;"></div></div></div><div class="w-bottom-bar w-css-reset" style="bottom: 0px; border-collapse: collapse; display: table; height: 33px; pointer-events: none; position: absolute; right: 0px; table-layout: auto; width: 100%;"><div class="w-bottom-bar-lower w-css-reset" style="position: relative;"><div style="height: 100%; left: 0px; position: absolute; top: 0px; width: 100%;"><div style="background: rgb(30, 113, 231); display: none; height: 100%; mix-blend-mode: darken; left: 0px; opacity: 1; position: absolute; top: 0px; transition: opacity 0s ease 0s; width: 100%;"></div><div style="background: rgba(30, 113, 231, 0.85); height: 100%; opacity: 1; left: 0px; position: absolute; top: 0px; transition: opacity 0s ease 0s; width: 100%;"></div></div><div style="display: none;"><div style="background: rgb(30, 113, 231); display: none; height: 100%; mix-blend-mode: darken; left: 0px; opacity: 1; position: absolute; top: 0px; transition: opacity 0s ease 0s; width: 100%;"></div><div style="background: rgba(30, 113, 231, 0.85); height: 100%; opacity: 1; left: 0px; position: absolute; top: 0px; transition: opacity 0s ease 0s; width: 100%;"></div></div><div class="w-bottom-bar-left w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 0px; opacity: 1; transition: opacity 0s ease 0s;"><div class="w-bottom-bar-left-inner w-css-reset" style="height: 33px; position: relative; pointer-events: auto; white-space: nowrap;"><div class="w-css-reset" data-handle="smallPlayButton" style="display: inline-block; vertical-align: top;"><div class="w-vulcan-button-wrapper w-css-reset" style="display: inline-block; height: 33px; position: relative; vertical-align: top; width: 38.875px;"><button tagname="button" class="w-vulcan-v2-button w-css-reset w-css-reset-tree w-css-reset-button-important" aria-label="Play Video" title="Play Video" style="background-color: rgba(0, 0, 0, 0); box-shadow: none; cursor: pointer; height: 100%; position: relative; transition: background-color 150ms ease 0s; width: 100%;"><div class="w-vulcan-icon-wrapper" data-handle="smallPlayButton" style="box-sizing: border-box; height: 100%; position: relative; transform: scale(1.001); transition: transform 200ms ease 0s;"><div style="box-sizing: border-box; height: 100%; margin-left: 0.971875px; padding: 9.71875px 0px 8.74688px; position: relative; width: 100%;"><div style="height: 100%; width: 100%;"><div style="display: none; height: 100%; width: 100%;"><svg x="0px" y="0px" viewBox="0 0 11.556 16" enable-background="new 0 0 11.556 16" focusable="false" class="w-css-reset w-css-reset-tree" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%; vertical-align: top;"><g><rect x="0" y="0" width="3.5" height="12"></rect><rect x="6.5" y="0" width="3.5" height="12"></rect></g></svg></div><div style="display: block; height: 100%; width: 100%;"><svg x="0px" y="0px" viewBox="0 0 11.556 16" enable-background="new 0 0 11.556 16" focusable="false" class="w-css-reset w-css-reset-tree" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%; vertical-align: top;"><polygon points="11.556,7.5 0,15 0,0"></polygon></svg></div></div></div></div></button></div></div></div></div><div class="w-bottom-bar-middle w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 100%; opacity: 1; transition: opacity 0s ease 0s;"><div class="w-bottom-bar-middle-inner w-css-reset" style="height: 33px; position: relative; pointer-events: auto; white-space: nowrap; opacity: 1; transform: translateY(0px); transition: opacity 0ms ease 0s, transform 0ms ease 0s;"><div class="w-css-reset" data-handle="playbar" style="height: 100%; position: relative;"><div class="w-playbar-wrapper w-css-reset w-css-reset-tree" style="display: flex; height: 100%; width: 100%;"><div class="w-playbar__time" style="box-sizing: content-box; color: white; font-family: WistiaPlayerInterNumbersSemiBold, Helvetica, sans-serif; font-size: 12.6344px; letter-spacing: 0.485938px; line-height: 33px; padding-left: 4.85938px; pointer-events: none; position: relative; text-align: center; width: 27.2125px;">3:52</div><div aria-label="Playbar" aria-orientation="horizontal" aria-valuemax="231.5" aria-valuemin="0" aria-valuenow="0" aria-valuetext="0:00" role="slider" tabindex="0" style="cursor: pointer; flex: 1 1 0%; height: 33px; outline: none; margin-left: 14.5781px; margin-right: 9.71875px; position: relative;"><canvas height="41" width="543" style="height: 33px; left: -14.5781px; position: absolute; top: 0px; width: 434.428px;"></canvas><div style="border-radius: 50%; height: 10.885px; left: -5.4425px; opacity: 0; position: absolute; top: 11.0575px; width: 10.885px;"></div></div></div></div></div></div><div class="w-bottom-bar-right w-css-reset" style="display: table-cell; vertical-align: top; position: relative; width: 0px; opacity: 1; transition: opacity 0s ease 0s; white-space: nowrap;"><div class="w-bottom-bar-right-inner-anchor w-css-reset" style="height: 33px; position: relative; pointer-events: auto; white-space: nowrap; display: inline-block; right: 0px; top: 0px; vertical-align: top;"><div class="w-bottom-bar-right-inner w-css-reset" style="height: 33px; position: relative; pointer-events: auto; white-space: nowrap; display: inline-block; opacity: 1; right: 0px; top: 0px; transform: translateY(0px); transition: opacity 0ms ease 0s, transform 0ms ease 0s;"><div class="w-css-reset" data-handle="volumeButton" style="display: inline-block; vertical-align: top;"><div class="w-vulcan-button-wrapper w-css-reset" style="display: inline-block; height: 33px; position: relative; vertical-align: top; width: 38.875px;"><button tagname="button" class="w-vulcan-v2-button w-css-reset w-css-reset-tree w-css-reset-button-important" aria-label="Mute" title="Mute" style="background-color: rgba(0, 0, 0, 0); box-shadow: none; cursor: pointer; height: 100%; position: relative; transition: background-color 150ms ease 0s; width: 100%;"><div class="w-vulcan-icon-wrapper" data-handle="volumeButton" style="box-sizing: border-box; height: 100%; position: relative; transform: scale(1.001); transition: transform 200ms ease 0s;"><svg x="0px" y="0px" viewBox="0 0 40 34" enable-background="new 0 0 40 34" focusable="false" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><g style="transform: translateX(1.25px); transition: transform 100ms ease 0s;"><g><path d="M13.8,14.2c-0.5,0.5-1.4,0.8-2,0.8h-1.6C9.5,15,9,15.5,9,16.2v1.6c0,0.7,0.5,1.2,1.2,1.2h1.6c0.7,0,1.6,0.4,2,0.8l2.3,2.3c0.5,0.5,0.8,0.3,0.8-0.4v-9.6c0-0.7-0.4-0.8-0.8-0.4L13.8,14.2z"></path></g><g><path fill="none" stroke="#ffffff" stroke-line-cap="round" stroke-miterlimit="10" stroke-width="2" d="M22,11.7c0,0,1.1,2.5,1.1,5s-1.1,5-1.1,5" style="opacity: 1; transition: opacity 100ms ease 0s;"></path><path fill="none" stroke="#ffffff" stroke-line-cap="round" stroke-miterlimit="10" stroke-width="2" d="M25.8,9.2c0,0,1.7,3.8,1.7,7.5c0,3.7-1.7,7.5-1.7,7.5" style="opacity: 1; transition: opacity 100ms ease 0s;"></path></g><g style="opacity: 0; transition: opacity 100ms ease 0s;"><line fill="none" stroke="#ffffff" stroke-line-cap="round" stroke-miterlimit="10" stroke-width="1.8102" x1="19.2" y1="15" x2="23.2" y2="19"></line><line fill="none" stroke="#ffffff" stroke-line-cap="round" stroke-miterlimit="10" stroke-width="1.8102" x1="19.2" y1="19" x2="23.2" y2="15"></line></g></g></svg></div></button></div></div><div class="w-css-reset" data-handle="settingsButton" style="display: inline-block; vertical-align: top;"><div class="w-vulcan-button-wrapper w-css-reset" style="display: inline-block; height: 33px; position: relative; vertical-align: top; width: 38.875px;"><button tagname="button" class="w-vulcan-v2-button w-css-reset w-css-reset-tree w-css-reset-button-important" aria-expanded="false" aria-label="Show settings menu" title="Show settings menu" style="background-color: rgba(0, 0, 0, 0); box-shadow: none; cursor: pointer; height: 100%; position: relative; transition: background-color 150ms ease 0s; width: 100%;"><div class="w-vulcan-icon-wrapper" data-handle="settingsButton" style="box-sizing: border-box; height: 100%; position: relative; transform: scale(1.001); transition: transform 200ms ease 0s;"><svg x="0px" y="0px" viewBox="0 0 40 34" enable-background="new 0 0 40 34" focusable="false" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><g><g><path d="M28.3,16.4h-1.9c-0.4,0-0.8-0.3-0.9-0.7l-0.4-1.1c-0.2-0.3-0.1-0.8,0.2-1.1l1.3-1.3c0.3-0.3,0.3-0.7,0-1l-0.4-0.4c-0.3-0.3-0.7-0.3-1,0l-1.3,1.3c-0.3,0.3-0.8,0.3-1.1,0.1l-1.1-0.5c-0.4-0.1-0.7-0.5-0.7-0.9V9.1c0-0.4-0.3-0.7-0.7-0.7h-0.6c-0.4,0-0.7,0.3-0.7,0.7v1.7c0,0.4-0.3,0.8-0.7,0.9l-1.2,0.5c-0.3,0.2-0.8,0.1-1.1-0.2l-1.2-1.2c-0.3-0.3-0.7-0.3-1,0l-0.4,0.4c-0.3,0.3-0.3,0.7,0,1l1.2,1.2c0.3,0.3,0.3,0.8,0.1,1.1l-0.5,1.2c-0.1,0.4-0.5,0.7-0.9,0.7h-1.6c-0.4,0-0.7,0.3-0.7,0.7v0.6c0,0.4,0.3,0.7,0.7,0.7h1.6c0.4,0,0.8,0.3,0.9,0.7l0.5,1.2c0.2,0.3,0.1,0.8-0.1,1.1l-1.2,1.2c-0.3,0.3-0.3,0.7,0,1l0.4,0.4c0.3,0.3,0.7,0.3,1,0l1.2-1.2c0.3-0.3,0.8-0.3,1.1-0.2l1.2,0.5c0.4,0.1,0.7,0.5,0.7,0.9v1.7c0,0.4,0.3,0.7,0.7,0.7h0.6c0.4,0,0.7-0.3,0.7-0.7V24c0-0.4,0.3-0.8,0.7-0.9l1.1-0.5c0.3-0.2,0.8-0.1,1.1,0.1l1.3,1.3c0.3,0.3,0.7,0.3,1,0l0.4-0.4c0.3-0.3,0.3-0.7,0-1l-1.3-1.3C25,21,25,20.5,25.1,20.2l0.4-1.1c0.1-0.4,0.5-0.7,0.9-0.7h1.9c0.4,0,0.7-0.3,0.7-0.7v-0.6C29,16.7,28.7,16.4,28.3,16.4z M23.8,17.5c0,2.2-1.8,3.9-3.9,3.9c-2.2,0-3.9-1.8-3.9-3.9s1.7-3.9,3.9-3.9C22.1,13.6,23.8,15.3,23.8,17.5z"></path></g></g></svg></div></button></div></div><div class="w-css-reset" data-handle="fullscreenButton" style="display: inline-block; vertical-align: top;"><div class="w-vulcan-button-wrapper w-css-reset" style="display: inline-block; height: 33px; position: relative; vertical-align: top; width: 38.875px;"><button tagname="button" class="w-vulcan-v2-button w-css-reset w-css-reset-tree w-css-reset-button-important" aria-label="Fullscreen" title="Fullscreen" style="background-color: rgba(0, 0, 0, 0); box-shadow: none; cursor: pointer; height: 100%; position: relative; transition: background-color 150ms ease 0s; width: 100%;"><div class="w-vulcan-icon-wrapper" data-handle="fullscreenButton" style="box-sizing: border-box; height: 100%; position: relative; transform: scale(1.001); transition: transform 200ms ease 0s;"><svg x="0px" y="0px" viewBox="0 0 40 34" enable-background="new 0 0 40 34" focusable="false" style="fill: rgb(255, 255, 255); height: 100%; left: 0px; stroke-width: 0px; top: 0px; width: 100%;"><g><g><polyline fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" points="31.4,12.6 31.4,8.7 25.8,8.7"></polyline><polyline fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" points="14.7,8.7 9.1,8.7 9.1,12.6"></polyline><polyline fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" points="25.8,24.8 31.4,24.8 31.4,20.9"></polyline><polyline fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" points="9.1,20.9 9.1,24.8 14.7,24.8"></polyline></g><rect x="13.7" y="12.3" fill="none" stroke="#ffffff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke-miterlimit="10" enable-background="new" width="13.3" height="8.9"></rect></g></svg></div></button></div></div></div></div><div class="w-ellipsis w-css-reset" style="height: 33px; position: relative; pointer-events: auto; white-space: nowrap; display: none;"></div></div></div></div><div class="w-foreground w-css-reset" style="height: 100%; left: 0px; pointer-events: none; position: absolute; top: 0px; width: 100%;"><div class="w-css-reset" data-handle="contextMenu" style="pointer-events: auto;"></div><div class="w-css-reset" data-handle="loadingHourglass" style="pointer-events: auto;"></div><div class="w-css-reset" data-handle="focusOutline" style="pointer-events: auto;"><div class="w-focus-outline" style="box-shadow: rgb(255, 255, 255) 0px 0px 0px 2px inset; display: none; height: 100%; left: 0px; pointer-events: none; position: absolute; right: 0px; width: 100%;"></div></div></div></div><style id="wistia_52_style" type="text/css" class="wistia_injected_style">
      #wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset{font-size:14px;}
#wistia_chrome_37 #wistia_grid_46_wrapper div.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper span.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper ul.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper li.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper label.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper fieldset.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper button.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper img.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper a.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper svg.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper p.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper a.w-css-reset{border:0;}
#wistia_chrome_37 #wistia_grid_46_wrapper h1.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:2em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper h2.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:1.5em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper h3.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:1.17em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper p.w-css-reset{margin:1.4em 0;}
#wistia_chrome_37 #wistia_grid_46_wrapper a.w-css-reset{display:inline;}
#wistia_chrome_37 #wistia_grid_46_wrapper span.w-css-reset{display:inline;}
#wistia_chrome_37 #wistia_grid_46_wrapper svg.w-css-reset{display:inline;}
#wistia_chrome_37 #wistia_grid_46_wrapper ul.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_46_wrapper ol.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_46_wrapper li.w-css-reset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_46_wrapper ul:before.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper ol:before.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper li:before.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper ul:after.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper ol:after.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper li:after.w-css-reset{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper label.w-css-reset{background-attachment:scroll;background-color:transparent;background-image:none;background-position:0 0;background-repeat:no-repeat;background-size:100% 100%;float:none;outline:none}
#wistia_chrome_37 #wistia_grid_46_wrapper button.w-css-reset{background-attachment:scroll;background-color:transparent;background-image:none;background-position:0 0;background-repeat:no-repeat;background-size:100% 100%;border:0;border-radius:0;outline:none;position:static}
#wistia_chrome_37 #wistia_grid_46_wrapper img.w-css-reset{border:0;display:inline-block;vertical-align:top;border-radius:0;outline:none;position:static}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset button::-moz-focus-inner{border: 0;}
      #wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree {font-size:14px;}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree div{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree span{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ul{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree li{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree label{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree fieldset{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree button{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree img{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree a{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree svg{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree p{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree a{border:0;}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree h1{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:2em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree h2{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:1.5em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree h3{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:1.17em;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree p{margin:1.4em 0;}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree a{display:inline;}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree span{display:inline;}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree svg{display:inline;}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ul{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ol{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree li{box-sizing:inherit;box-shadow:none;color:inherit;display:block;float:none;font:inherit;font-family:inherit;font-style:normal;font-weight:normal;font-size:inherit;letter-spacing:0;line-height:inherit;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;padding:0;position:static;text-decoration:none;text-transform:none;text-shadow:none;transition:none;word-wrap:normal;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-user-select:none;-webkit-font-smoothing:antialiased;list-style-type:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ul:before{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ol:before{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree li:before{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ul:after{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree ol:after{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree li:after{display:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree label{background-attachment:scroll;background-color:transparent;background-image:none;background-position:0 0;background-repeat:no-repeat;background-size:100% 100%;float:none;outline:none}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree button{background-attachment:scroll;background-color:transparent;background-image:none;background-position:0 0;background-repeat:no-repeat;background-size:100% 100%;border:0;border-radius:0;outline:none;position:static}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree img{border:0;display:inline-block;vertical-align:top;border-radius:0;outline:none;position:static}
#wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-tree  button::-moz-focus-inner{border: 0;}
      #wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-max-width-none-important{max-width:none!important}
      #wistia_chrome_37 #wistia_grid_46_wrapper .w-css-reset-button-important{border-radius:0!important;color:#fff!important;}
    </style></div></div><div id="wistia_grid_46_front"></div><div id="wistia_grid_46_top_inside"><div id="wistia_grid_46_top" style="height: 0px; font-size: 0px; line-height: 0px;"> </div></div><div id="wistia_grid_46_bottom_inside"><div id="wistia_grid_46_bottom" style="height: 0px; font-size: 0px; line-height: 0px;"> </div></div><div id="wistia_grid_46_left_inside"><div id="wistia_grid_46_left" style="height: 0px; font-size: 0px; line-height: 0px;"> </div></div><div id="wistia_grid_46_right_inside"><div id="wistia_grid_46_right" style="height: 0px; font-size: 0px; line-height: 0px;"> </div></div></div><div id="wistia_grid_46_below" style="height: 0px; font-size: 0px; line-height: 0px;"> </div><style id="wistia_47_style" type="text/css" class="wistia_injected_style">#wistia_grid_46_wrapper{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;font-family:Arial,sans-serif;font-size:14px;height:100%;position:relative;text-align:left;width:100%;}
#wistia_grid_46_wrapper *{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;}
#wistia_grid_46_above{position:relative;}
#wistia_grid_46_main{display:block;height:100%;position:relative;}
#wistia_grid_46_behind{height:100%;left:0;position:absolute;top:0;width:100%;}
#wistia_grid_46_center{height:100%;overflow:hidden;position:relative;width:100%;}
#wistia_grid_46_front{display:none;height:100%;left:0;position:absolute;top:0;width:100%;}
#wistia_grid_46_top_inside{position:absolute;left:0;top:0;width:100%;}
#wistia_grid_46_top{width:100%;position:absolute;bottom:0;left:0;}
#wistia_grid_46_bottom_inside{position:absolute;left:0;bottom:0;width:100%;}
#wistia_grid_46_bottom{width:100%;position:absolute;top:0;left:0;}
#wistia_grid_46_left_inside{height:100%;position:absolute;left:0;top:0;}
#wistia_grid_46_left{height:100%;position:absolute;right:0;top:0;}
#wistia_grid_46_right_inside{height:100%;right:0;position:absolute;top:0;}
#wistia_grid_46_right{height:100%;left:0;position:absolute;top:0;}
#wistia_grid_46_below{position:relative;}</style></div></div></div></div></div>

	<div style="margin-top: 32px; margin-bottom: 32px; ">
		<strong>Course information:</strong><br>
		53+ total classes • 57+ hours of on-demand code walkthrough videos • Last updated: October 2022<br>
		<span style="color: #169FE6;">★★★★★</span> 4.84 (128 Ratings) • 15,800+ Students Enrolled
	</div>

	<p><strong>I strongly believe that if you had the right teacher you could <em>master</em> computer vision and deep learning.</strong></p>

	<p>Do you think learning computer vision and deep learning has to be time-consuming, overwhelming, and complicated? Or has to involve complex mathematics and equations? Or requires a degree in computer science?</p>

	<p>That’s <em>not</em> the case.</p>

	<p>All you need to master computer vision and deep learning is for someone to explain things to you in <em>simple, intuitive</em> terms. <em>And that’s exactly what I do</em>. My mission is to change education and how complex Artificial Intelligence topics are taught.</p>

	<p>If you're serious about learning computer vision, your next stop should be PyImageSearch University, the most comprehensive computer vision, deep learning, and OpenCV course online today. Here you’ll learn how to <em>successfully</em> and <em>confidently</em> apply computer vision to your work, research, and projects. Join me in computer vision mastery.</p>

	<p><strong>Inside PyImageSearch University you'll find:</strong></p>

	<ul style="margin-left: 0px;">
		<li style="list-style: none;">✓ <strong>53+ courses</strong> on essential computer vision, deep learning, and OpenCV topics</li>
		<li style="list-style: none;">✓ <strong>53+ Certificates</strong> of Completion</li>
		<li style="list-style: none;">✓ <strong>57+ hours</strong> of on-demand video</li>
		<li style="list-style: none;">✓ <strong>Brand new courses released <em>regularly</em></strong>, ensuring you can keep up with state-of-the-art techniques</li>
		<li style="list-style: none;">✓ <strong>Pre-configured Jupyter Notebooks in Google Colab</strong></li>
		<li style="list-style: none;">✓ Run all code examples in your web browser — works on Windows, macOS, and Linux (no dev environment configuration required!)</li>
		<li style="list-style: none;">✓ Access to <strong>centralized code repos for <em>all</em> 450+ tutorials</strong> on PyImageSearch</li>
		<li style="list-style: none;">✓ <strong> Easy one-click downloads</strong> for code, datasets, pre-trained models, etc.</li>
		<li style="list-style: none;">✓ <strong>Access</strong> on mobile, laptop, desktop, etc.</li>
	</ul>

	<p style="text-align: center;">
		<a target="_blank" class="button link" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&amp;utm_medium=bottomBanner&amp;utm_campaign=What%27s%20next%3F%20I%20recommend" style="background-color: #6DC713; border-bottom: none;">Click here to join PyImageSearch University</a>
	</p>
</div>
<h2>Summary</h2>
<p>In today’s blog post you learned how to perform instance segmentation using OpenCV, Deep Learning, and Python.</p>
<p><strong>Instance segmentation is the process of:</strong></p>
<ol>
<li>Detecting each object in an image</li>
<li>Computing a pixel-wise mask for each object</li>
</ol>
<p><strong>Even if objects are of the same class, an instance segmentation should return a unique mask for <em>each</em> object.</strong></p>
<p>In order to apply instance segmentation with OpenCV, we used our <a href="https://pyimagesearch.com/2018/11/19/mask-r-cnn-with-opencv/" target="_blank" rel="noopener noreferrer">Mask R-CNN implementation from last week</a>.</p>
<p>We then used our Mask R-CNN model to build a “video conference call blurring feature”, similar to the feature Microsoft released for Office 365 back in the summer.</p>
<p>Our instance segmentation results were similar to Microsoft’s feature; however, we could not obtain true real-time performance since OpenCV’s GPU support for the <div class="enlighter-default enlighter-v-inline enlighter-t-pyis-enlighter-theme "><span class="enlighter"><span class="enlighter-text">dnn</span></span></div><code class="EnlighterJSRAW enlighter-origin" data-enlighter-language="python">dnn</code>&nbsp; module is currently quite limited.</p>
<p>Therefore, today’s tutorial serves as a demo, highlighting what is <em>currently possible</em> and what <em>will be possible</em> when OpenCV’s GPU support increases.</p>
<p>I hope you enjoyed today’s tutorial!</p>
<p><strong>To download the source code to this post, and be notified when future tutorials are published here on PyImageSearch, <em>just enter your email address in the form below!</em></strong></p>
<div id="download-the-code" class="post-cta-wrap">
<div class="gpd-post-cta">
	<div class="gpd-post-cta-content">
		

			<div class="gpd-post-cta-top">
				<div class="gpd-post-cta-top-image"><img src="./Instance segmentation with OpenCV - PyImageSearch_files/cta-source-guide-1.png" alt="" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?lossy=1&amp;strip=1&amp;webp=1" data-ll-status="loaded" class="entered lazyloaded"><noscript><img src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?lossy=1&strip=1&webp=1" alt="" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?lossy=1&strip=1&webp=1 410w,https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?size=126x174&lossy=1&strip=1&webp=1 126w,https://929687.smushcdn.com/2633864/wp-content/uploads/2020/01/cta-source-guide-1.png?size=252x348&lossy=1&strip=1&webp=1 252w" sizes="(max-width: 410px) 100vw, 410px" /></noscript></div>
				
				<div class="gpd-post-cta-top-title"><h4>Download the Source Code and FREE 17-page Resource Guide</h4></div>
				<div class="gpd-post-cta-top-desc"><p>Enter your email address below to get a .zip of the code and a <strong>FREE 17-page Resource Guide on Computer Vision, OpenCV, and Deep Learning.</strong> Inside you'll find my hand-picked tutorials, books, courses, and libraries to help you master CV and DL!</p></div>


			</div>

			<div class="gpd-post-cta-bottom">
				<form id="footer-cta-code" class="footer-cta" action="https://www.getdrip.com/forms/4130035/submissions" method="post" target="blank" data-drip-embedded-form="4130035">
					<input name="fields[email]" type="email" value="" placeholder="Your email address" class="form-control">

					<button type="submit">Download the code!</button>

					<div style="display: none;" aria-hidden="true"><label for="website">Website</label><br><input type="text" id="website" name="website" tabindex="-1" autocomplete="false" value=""></div>
				</form>
			</div>


		
	</div>

</div>
</div><!-- RightMessage WP -->
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/"
    dc:identifier="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/"
    dc:title="Instance segmentation with OpenCV"
    trackback:ping="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/trackback/" />
</rdf:RDF>-->
</div></article><section class="author-box"><img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c.jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=480&amp;d=mm&amp;r=g 2x" class="avatar avatar-240 photo entered lazyloaded" height="240" width="240" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=240&amp;d=mm&amp;r=g" data-ll-status="loaded" srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=480&amp;d=mm&amp;r=g 2x"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=240&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=480&#038;d=mm&#038;r=g 2x' class='avatar avatar-240 photo' height='240' width='240' /></noscript><h4 class="author-box-title"><strong>About the Author</strong></h4><div class="author-box-content" itemprop="description"><p>Hi there, I’m Adrian Rosebrock, PhD. All too often I see developers, students, and researchers wasting their time, studying the wrong things, and generally struggling to get started with Computer Vision, Deep Learning, and OpenCV. I created this website to show you what I believe is the best possible way to get your start.</p>
</div></section><h2 class="screen-reader-text">Reader Interactions</h2><div class="single-post-nav"><a href="https://pyimagesearch.com/2018/11/19/mask-r-cnn-with-opencv/"><div class="single-post-nav__previous"><p>Previous Article:</p><h3>Mask R-CNN with OpenCV</h3></div></a><a href="https://pyimagesearch.com/2018/12/03/deep-learning-and-medical-image-analysis-with-keras/"><div class="single-post-nav__next"><p>Next Article:</p><h3>Deep Learning and Medical Image Analysis with Keras</h3></div></a></div><div class="entry-comments" id="comments"><h3>24 responses to: Instance segmentation with OpenCV</h3><ol class="comment-list">
	<li class="comment even thread-even depth-1" id="comment-489199">
	<article id="article-comment-489199">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/953fa4ff668b429648ed1817690dfb3a.png" data-lazy-srcset="https://secure.gravatar.com/avatar/953fa4ff668b429648ed1817690dfb3a?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo entered lazyloaded" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/953fa4ff668b429648ed1817690dfb3a?s=48&amp;d=mm&amp;r=g" data-ll-status="loaded" srcset="https://secure.gravatar.com/avatar/953fa4ff668b429648ed1817690dfb3a?s=96&amp;d=mm&amp;r=g 2x"><noscript><img alt='' src='https://secure.gravatar.com/avatar/953fa4ff668b429648ed1817690dfb3a?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/953fa4ff668b429648ed1817690dfb3a?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name"><a href="http://zubairahmed.net/" class="comment-author-link" rel="external nofollow">Zubair Ahmed</a></span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-489199">November 26, 2018 at 10:18 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Adrian,<br>
Wonderful post as always and thanks for the mention 🙂</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-489240">
	<article id="article-comment-489240">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-489240">November 26, 2018 at 2:23 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Thanks Zbuar! 🙂</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment even depth-2" id="comment-489409">
	<article id="article-comment-489409">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/2d78e3d8a128ca7ae1ba1ef0e179a58a.png" data-lazy-srcset="https://secure.gravatar.com/avatar/2d78e3d8a128ca7ae1ba1ef0e179a58a?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/2d78e3d8a128ca7ae1ba1ef0e179a58a?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/2d78e3d8a128ca7ae1ba1ef0e179a58a?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/2d78e3d8a128ca7ae1ba1ef0e179a58a?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">sophia</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-489409">November 27, 2018 at 9:59 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hello Zubair, Is the link to your blog (<a href="http://zubairahmed.net/2018/07/17/background-blurring-with-semantic-image-segmentation-using-deeplabv3/" rel="nofollow ugc">http://zubairahmed.net/2018/07/17/background-blurring-with-semantic-image-segmentation-using-deeplabv3/</a>) correct? I’m getting an Error 403 – This web app is stopped. </p>
<p>Thanks.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-3" id="comment-490035">
	<article id="article-comment-490035">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-490035">November 30, 2018 at 9:30 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>I just checked and it seems to be working for me. Perhaps it was just a temporary hiccup.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-489340">
	<article id="article-comment-489340">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/299d251e3f6ecfcc02fd7ebda9a32dd1.png" data-lazy-srcset="https://secure.gravatar.com/avatar/299d251e3f6ecfcc02fd7ebda9a32dd1?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/299d251e3f6ecfcc02fd7ebda9a32dd1?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/299d251e3f6ecfcc02fd7ebda9a32dd1?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/299d251e3f6ecfcc02fd7ebda9a32dd1?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Arthur Zhang</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-489340">November 27, 2018 at 2:37 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Really practical course!</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-490040">
	<article id="article-comment-490040">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-490040">November 30, 2018 at 9:34 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Thanks so much, Arthur!</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-490985">
	<article id="article-comment-490985">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/79ab9f79813654a94e462ad611739b06.png" data-lazy-srcset="https://secure.gravatar.com/avatar/79ab9f79813654a94e462ad611739b06?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/79ab9f79813654a94e462ad611739b06?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/79ab9f79813654a94e462ad611739b06?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/79ab9f79813654a94e462ad611739b06?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Wilf</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-490985">December 6, 2018 at 9:22 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>This was terrific!!</p>
<p>Question: what is the frame processing speed on your computer.<br>
My laptop does not have a GPU so my processing times are V-E-R-Y slow.<br>
(I read in a video clip and stored the “private” blurred frames to disk to better enjoy the background blurring)</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-490986">
	<article id="article-comment-490986">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-490986">December 6, 2018 at 9:25 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>My CPU is only processing a few frames per second. For true real-time performance using this method you would need a GPU (which OpenCV’s GPU support is currently a bit limited).</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment even depth-3" id="comment-491461">
	<article id="article-comment-491461">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/7cc52bf5b448df4537853a8de6a92d23.png" data-lazy-srcset="https://secure.gravatar.com/avatar/7cc52bf5b448df4537853a8de6a92d23?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/7cc52bf5b448df4537853a8de6a92d23?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/7cc52bf5b448df4537853a8de6a92d23?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/7cc52bf5b448df4537853a8de6a92d23?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">jstumpin</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-491461">December 9, 2018 at 10:38 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Unless someone made a PR to OpenCV repo to optimize the said kernel (<a href="https://github.com/opencv/opencv/issues/12155#issuecomment-445120430" rel="nofollow ugc">https://github.com/opencv/opencv/issues/12155#issuecomment-445120430</a>), CPU will always be faster should anyone decide to use NVIDIA/AMD GPU for DNN inferencing on OpenCV. Otherwise, just stick to CAFFE/TENSORFLOW/TORCH etc.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment odd alt depth-3" id="comment-701403">
	<article id="article-comment-701403">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/4b8953a688e098d2acac7484ec87e84a.png" data-lazy-srcset="https://secure.gravatar.com/avatar/4b8953a688e098d2acac7484ec87e84a?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/4b8953a688e098d2acac7484ec87e84a?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/4b8953a688e098d2acac7484ec87e84a?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/4b8953a688e098d2acac7484ec87e84a?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">suresh</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-701403">February 4, 2020 at 11:50 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>HI Adrian, What is the best way to achieve decent speed on CPU, the current FPS is &lt;1. Please suggest.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor even depth-4" id="comment-703749">
	<article id="article-comment-703749">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-703749">February 5, 2020 at 1:54 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>I would suggest you look into model/weight quantization and optimization. Those methods can help make models run faster on your CPU, but you’ll likely have to sacrifice a bit of accuracy.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-491323">
	<article id="article-comment-491323">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/5981633bc5cb8caf1450c5387d2ea829.png" data-lazy-srcset="https://secure.gravatar.com/avatar/5981633bc5cb8caf1450c5387d2ea829?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/5981633bc5cb8caf1450c5387d2ea829?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/5981633bc5cb8caf1450c5387d2ea829?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/5981633bc5cb8caf1450c5387d2ea829?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name"><a href="http://www.playsis.com.br/" class="comment-author-link" rel="external nofollow">Angelo</a></span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-491323">December 8, 2018 at 5:22 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Too slow to run into raspberry pi, thanks for the info</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-495891">
	<article id="article-comment-495891">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/74271cf4c30ccf4b8e7889d816e299d1.png" data-lazy-srcset="https://secure.gravatar.com/avatar/74271cf4c30ccf4b8e7889d816e299d1?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/74271cf4c30ccf4b8e7889d816e299d1?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/74271cf4c30ccf4b8e7889d816e299d1?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/74271cf4c30ccf4b8e7889d816e299d1?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Muhammad Bilal</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-495891">January 11, 2019 at 6:51 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>hello, Adrian !<br>
an amazingly useful write, like always.<br>
Can you please guide me, I want to run image segmentation on Raspberry Pi 3B+<br>
1. If i train a custom Caffe for different terrains (i.e: grass, Roads, Rocky, water/wet, and different shades of sky)<br>
2. Question: if i reduce the Classes (to just 2 or 3) would i be able to achieve at-least 2-3 Fps on my Raspberry ? </p>
<p>Thanks in advance &lt;3<br>
-big fan to you.</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-495904">
	<article id="article-comment-495904">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-495904">January 11, 2019 at 9:24 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>The Raspberry Pi will be far, far too slow to run a Mask R-CNN network. You will not be able to get 2-3 FPS for instance segmentation on a Pi, it’s just too slow.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-498337">
	<article id="article-comment-498337">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/be48bc3ccfa6ffd24f226aa73f198096.png" data-lazy-srcset="https://secure.gravatar.com/avatar/be48bc3ccfa6ffd24f226aa73f198096?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/be48bc3ccfa6ffd24f226aa73f198096?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/be48bc3ccfa6ffd24f226aa73f198096?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/be48bc3ccfa6ffd24f226aa73f198096?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Sourabh</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-498337">January 29, 2019 at 6:12 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Amazing work ! Thank you</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-498341">
	<article id="article-comment-498341">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-498341">January 29, 2019 at 6:26 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Thanks Sourabh!</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-507734">
	<article id="article-comment-507734">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/678c8f8b3448b7f87fd07b5c79af82ec.jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/678c8f8b3448b7f87fd07b5c79af82ec?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/678c8f8b3448b7f87fd07b5c79af82ec?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/678c8f8b3448b7f87fd07b5c79af82ec?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/678c8f8b3448b7f87fd07b5c79af82ec?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">PRASHANT BANSOD</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-507734">March 19, 2019 at 6:11 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Hi Adrian, thanks for the great tutorial. I would like to know whether I can use this for extracting human silhouette extraction or there is a better approach to tackle it. Thanks</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-507811">
	<article id="article-comment-507811">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-507811">March 19, 2019 at 9:51 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Yes, instance segmentation is the suggested technique to obtain a pixel-wise mask of a person.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-524599">
	<article id="article-comment-524599">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/e9e93f7ccff922835df68e4304e705c2.jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/e9e93f7ccff922835df68e4304e705c2?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/e9e93f7ccff922835df68e4304e705c2?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/e9e93f7ccff922835df68e4304e705c2?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/e9e93f7ccff922835df68e4304e705c2?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">santanu</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-524599">July 5, 2019 at 3:17 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Which one is best for instance segmentation(mask rcnn, segnet and deeplab) ??</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-525197">
	<article id="article-comment-525197">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-525197">July 10, 2019 at 9:57 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>There isn’t one “best” network for instance segmentation. It’s dependent on your dataset, your project requirements, and any computational limitations on the machine you’re either training or deploying to. You need to balance of all these when selecting an architecture.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-even depth-1" id="comment-546766">
	<article id="article-comment-546766">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/a2375a373ee02a466d6734f18a969e88.png" data-lazy-srcset="https://secure.gravatar.com/avatar/a2375a373ee02a466d6734f18a969e88?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/a2375a373ee02a466d6734f18a969e88?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/a2375a373ee02a466d6734f18a969e88?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/a2375a373ee02a466d6734f18a969e88?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">avantika</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-546766">September 4, 2019 at 3:36 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>why did you use Mask R-CNN for this video blurring effect over YOLO or SSD ? They also use deep learning</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-547107">
	<article id="article-comment-547107">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-547107">September 5, 2019 at 10:24 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>Mask R-CNN is an instance segmentation algorithm. It gives you a pixel-wise mask. YOLO and SSDs are object detectors. They only produce bounding boxes.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->

	<li class="comment even thread-odd thread-alt depth-1" id="comment-571532">
	<article id="article-comment-571532">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/ae30da2c22fcacd98c6ea5a88b59aa66.png" data-lazy-srcset="https://secure.gravatar.com/avatar/ae30da2c22fcacd98c6ea5a88b59aa66?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/ae30da2c22fcacd98c6ea5a88b59aa66?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/ae30da2c22fcacd98c6ea5a88b59aa66?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/ae30da2c22fcacd98c6ea5a88b59aa66?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Tony</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-571532">November 9, 2019 at 9:33 pm</a></time></p>		</header>

		<div class="comment-content">
			
			<p>How would you replace the video feed from your camera with a prerecorded video?</p>
		</div>

		
		
	</article>
	<ul class="children">

	<li class="comment byuser comment-author-adrian bypostauthor odd alt depth-2" id="comment-573244">
	<article id="article-comment-573244">

		
		<header class="comment-header">
			<p class="comment-author">
				<img alt="" src="./Instance segmentation with OpenCV - PyImageSearch_files/02743529311d3b8babbaf6935670ec9c(1).jpeg" data-lazy-srcset="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&amp;d=mm&amp;r=g 2x" class="avatar avatar-48 photo" height="48" width="48" data-lazy-src="https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&amp;d=mm&amp;r=g"><noscript><img alt='' src='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=48&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/02743529311d3b8babbaf6935670ec9c?s=96&#038;d=mm&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' /></noscript><span class="comment-author-name">Adrian Rosebrock</span>			</p>

			<p class="comment-meta"><time class="comment-time"><a class="comment-time-link" href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#comment-573244">November 14, 2019 at 9:30 am</a></time></p>		</header>

		<div class="comment-content">
			
			<p>You would use the <code>cv2.VideoCapture</code> function and pass it in the path to the video file. If you’ve never done that before you can refer to <a target="blank" href="https://pyimagesearch.com/practical-python-opencv/">Practical Python and OpenCV</a> which will teach you how to do exactly that.</p>
		</div>

		
		
	</article>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ol></div><div class="comment-policy">  <h3 class="comment-policy__title">Comment section</h3>  <div class="comment-policy__content"><p>Hey, Adrian Rosebrock here, author and creator of PyImageSearch. While I love hearing from readers, a couple years ago I made the tough decision to no longer offer 1:1 help over blog post comments.</p>
<p>At the time I was receiving 200+ emails per day and another 100+ blog post comments. I simply did not have the time to moderate and respond to them all, and the sheer volume of requests was taking a toll on me.</p>
<p>Instead, my goal is to <em>do the most good</em> for the computer vision, deep learning, and OpenCV community at large by focusing my time on authoring high-quality blog posts, tutorials, and books/courses.</p>
<p><strong>If you need help learning computer vision and deep learning, <a href="https://pyimagesearch.com/books-and-courses/" target="_blank" rel="noopener">I suggest you refer to my full catalog of books and courses</a></strong> — they have helped tens of thousands of developers, students, and researchers <em>just like yourself</em> learn Computer Vision, Deep Learning, and OpenCV.</p>
<p><a href="https://pyimagesearch.com/books-and-courses/" target="_blank" rel="noopener">Click here to browse my full catalog.</a></p>
</div></div>
<div id="pyis-cta-modal-sticky-bottom-anchor"></div></main><aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar" id="genesis-sidebar-primary"><h2 class="genesis-sidebar-title screen-reader-text">Primary Sidebar</h2><section id="custom_html-11" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><div class="textwidget custom-html-widget"><section id="custom_html-12" class="widget_text widget widget_custom_html" vwo-el-id="12905566480"><div class="widget_text widget-wrap" vwo-el-id="4379272940"><div class="textwidget custom-html-widget" vwo-el-id="10491450000"><div class="sidebar__block" vwo-el-id="38280549740">
	<h4 class="sidebar__block-title" vwo-el-id="31559285170"><a target="_blank" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&amp;utm_medium=sideBanner&amp;utm_campaign=joinNow" rel="noopener" vwo-el-id="27590303210">PyImageSearch University </a></h4>	
	<a target="_blank" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&amp;utm_medium=sideBanner&amp;utm_campaign=joinNow" rel="noopener" vwo-el-id="42914948080"><img src="./Instance segmentation with OpenCV - PyImageSearch_files/pyuni_full_access_plan_small.png" alt="" class="wp-image-11909" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?size=126x95&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?lossy=1&amp;strip=1&amp;webp=1 200w" data-lazy-sizes="(max-width: 200px) 100vw, 200px" no-resize-detection="" vwo-el-id="32333822360" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?lossy=1&amp;strip=1&amp;webp=1"><noscript><img src="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?lossy=1&amp;strip=1&amp;webp=1" alt="" class="wp-image-11909" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?size=126x95&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2021/04/pyuni_full_access_plan_small.png?lossy=1&amp;strip=1&amp;webp=1 200w" sizes="(max-width: 200px) 100vw, 200px" no-resize-detection="" vwo-el-id="32333822360"></noscript></a>	
	<div class="sidebar__block-content" vwo-el-id="4986532880">
		<p style="font-size: 16px;" vwo-el-id="17980791980">
			<strong vwo-el-id="33978259780">Course information:</strong><br vwo-el-id="9360110700"> 			
			53+ total classes • 57+ hours of on demand video • Last updated: October 2022<br vwo-el-id="9360111010">
			<span style="color: #169FE6;" vwo-el-id="24661359750">★★★★★</span><br vwo-el-id="9360111320">
			4.84 (128 Ratings) • 15,800+ Students Enrolled
		</p>
		<p style="text-align: left; font-size: 16px; line-height: 34px;" vwo-el-id="17980792290">
			✓ <strong vwo-el-id="34288457850">53+ courses</strong> on essential computer vision, deep learning, and OpenCV topics<br vwo-el-id="31929219840">
			✓ <strong>53+ Certificates of Completion </strong><br vwo-el-id="31929220150">
			✓ <strong vwo-el-id="34288458160">57+ hours</strong> of on-demand video<br vwo-el-id="31929220460">
			✓ <strong vwo-el-id="34288458470">Brand new courses released <em vwo-el-id="17816517780">every month</em></strong>, ensuring you can keep up with state-of-the-art techniques<br vwo-el-id="31929220770">
			✓ <strong vwo-el-id="34288458780">Pre-configured Jupyter Notebooks in Google Colab</strong><br vwo-el-id="31929221080">
			✓ Run all code examples in your web browser — works on Windows, macOS, and Linux (no dev environment configuration required!)<br vwo-el-id="31929221390">
			✓ Access to <strong vwo-el-id="34288459090">centralized code repos for <em vwo-el-id="20005064960">all</em> 500+ tutorials</strong> on PyImageSearch<br vwo-el-id="31929221700">
			✓ <strong vwo-el-id="34288459400"> Easy one-click downloads</strong> for code, datasets, pre-trained models, etc.<br vwo-el-id="31929222010">
			✓ Access on mobile, laptop, desktop, etc.

		</p> 

	</div>
	<!-- <p style="text-align: center;">
		<a target="_blank" class="button link" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&utm_medium=sideBanner&utm_campaign=joinNow" style="background-color: #169FE6; color: white; border-bottom: none;" rel="noopener">Learn More</a>
	</p> -->

<a target="_blank" href="https://pyimagesearch.com/pyimagesearch-university/?utm_source=blogPost&amp;utm_medium=sideBanner&amp;utm_campaign=joinNow" class="button sidebar__block-button" rel="noopener" vwo-el-id="14332567680">Join Now</a>

</div></div></div></section></div></div></section>
<section id="related-posts-by-taxonomy-2" class="widget related_posts_by_taxonomy"><div class="widget-wrap">
<h3 class="widgettitle widget-title">Picked For You</h3>
<div id="rpbt-related-gallery-1" class="gallery related-gallery related-galleryid-9061 gallery-columns-1 gallery-size-medium"><figure class="gallery-item" role="group" aria-label="U-Net Image Segmentation in Keras">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2022/02/21/u-net-image-segmentation-in-keras/"><img width="300" height="150" src="./Instance segmentation with OpenCV - PyImageSearch_files/unet_header-do-not-smush-1-300x150.png" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-28344" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1.png?size=126x63&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1-300x150.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1-768x384.png?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1-1024x512.png?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1-1536x768.png?lossy=1&amp;strip=1&amp;webp=1 1536w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1.png?lossy=1&amp;strip=1&amp;webp=1 2000w" data-lazy-sizes="(max-width: 300px) 100vw, 300px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1-300x150.png?size=300x300&amp;lossy=1&amp;strip=1&amp;webp=1"><noscript><img width="300" height="150" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1-300x150.png?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-28344" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1.png?size=126x63&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1-300x150.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1-768x384.png?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1-1024x512.png?lossy=1&amp;strip=1&amp;webp=1 1024w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1-1536x768.png?lossy=1&amp;strip=1&amp;webp=1 1536w, https://929687.smushcdn.com/2633864/wp-content/uploads/2022/02/unet_header-do-not-smush-1.png?lossy=1&amp;strip=1&amp;webp=1 2000w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-28344">
				<a href="https://pyimagesearch.com/2022/02/21/u-net-image-segmentation-in-keras/">U-Net Image Segmentation in Keras</a>
				</figcaption></figure><figure class="gallery-item" role="group" aria-label="Image Segmentation with Mask R-CNN, GrabCut, and OpenCV">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2020/09/28/image-segmentation-with-mask-r-cnn-grabcut-and-opencv/"><img width="300" height="276" src="./Instance segmentation with OpenCV - PyImageSearch_files/maskrcnn_grabcut_header-300x276.png" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-16854" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/09/maskrcnn_grabcut_header.png?size=126x116&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/09/maskrcnn_grabcut_header-300x276.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/09/maskrcnn_grabcut_header.png?lossy=1&amp;strip=1&amp;webp=1 600w" data-lazy-sizes="(max-width: 300px) 100vw, 300px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/09/maskrcnn_grabcut_header-300x276.png?size=300x300&amp;lossy=1&amp;strip=1&amp;webp=1"><noscript><img width="300" height="276" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/09/maskrcnn_grabcut_header-300x276.png?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-16854" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/09/maskrcnn_grabcut_header.png?size=126x116&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/09/maskrcnn_grabcut_header-300x276.png?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/09/maskrcnn_grabcut_header.png?lossy=1&amp;strip=1&amp;webp=1 600w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-16854">
				<a href="https://pyimagesearch.com/2020/09/28/image-segmentation-with-mask-r-cnn-grabcut-and-opencv/">Image Segmentation with Mask R-CNN, GrabCut, and OpenCV</a>
				</figcaption></figure><figure class="gallery-item" role="group" aria-label="OpenCV ‘dnn’ with NVIDIA GPUs: 1549% faster YOLO, SSD, and Mask R-CNN">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2020/02/10/opencv-dnn-with-nvidia-gpus-1549-faster-yolo-ssd-and-mask-r-cnn/"><img width="300" height="226" src="./Instance segmentation with OpenCV - PyImageSearch_files/opencv_dnn_gpu_examples_featured-300x226.jpg" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-12657" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/opencv_dnn_gpu_examples_featured.jpg?size=126x95&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/opencv_dnn_gpu_examples_featured-300x226.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/opencv_dnn_gpu_examples_featured.jpg?lossy=1&amp;strip=1&amp;webp=1 608w" data-lazy-sizes="(max-width: 300px) 100vw, 300px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/opencv_dnn_gpu_examples_featured-300x226.jpg?size=300x300&amp;lossy=1&amp;strip=1&amp;webp=1"><noscript><img width="300" height="226" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/opencv_dnn_gpu_examples_featured-300x226.jpg?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-12657" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/opencv_dnn_gpu_examples_featured.jpg?size=126x95&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/opencv_dnn_gpu_examples_featured-300x226.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/opencv_dnn_gpu_examples_featured.jpg?lossy=1&amp;strip=1&amp;webp=1 608w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-12657">
				<a href="https://pyimagesearch.com/2020/02/10/opencv-dnn-with-nvidia-gpus-1549-faster-yolo-ssd-and-mask-r-cnn/">OpenCV ‘dnn’ with NVIDIA GPUs: 1549% faster YOLO, SSD, and Mask R-CNN</a>
				</figcaption></figure><figure class="gallery-item" role="group" aria-label="Mask R-CNN with OpenCV">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2018/11/19/mask-r-cnn-with-opencv/"><img width="300" height="265" src="./Instance segmentation with OpenCV - PyImageSearch_files/mask_rcnn_featured-300x265.jpg" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-8999" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask_rcnn_featured.jpg?size=126x111&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask_rcnn_featured-300x265.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask_rcnn_featured.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" data-lazy-sizes="(max-width: 300px) 100vw, 300px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask_rcnn_featured-300x265.jpg?size=300x300&amp;lossy=1&amp;strip=1&amp;webp=1"><noscript><img width="300" height="265" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask_rcnn_featured-300x265.jpg?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-8999" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask_rcnn_featured.jpg?size=126x111&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask_rcnn_featured-300x265.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/11/mask_rcnn_featured.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-8999">
				<a href="https://pyimagesearch.com/2018/11/19/mask-r-cnn-with-opencv/">Mask R-CNN with OpenCV</a>
				</figcaption></figure><figure class="gallery-item" role="group" aria-label="Semantic segmentation with OpenCV and deep learning">
			<div class="gallery-icon landscape">
				<a href="https://pyimagesearch.com/2018/09/03/semantic-segmentation-with-opencv-and-deep-learning/"><img width="300" height="203" src="./Instance segmentation with OpenCV - PyImageSearch_files/opencv_semantic_segmentation_result01-300x203.jpg" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-8587" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/08/opencv_semantic_segmentation_result01.jpg?size=126x85&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/08/opencv_semantic_segmentation_result01-300x203.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/08/opencv_semantic_segmentation_result01.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" data-lazy-sizes="(max-width: 300px) 100vw, 300px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/08/opencv_semantic_segmentation_result01-300x203.jpg?size=300x300&amp;lossy=1&amp;strip=1&amp;webp=1"><noscript><img width="300" height="203" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/08/opencv_semantic_segmentation_result01-300x203.jpg?lossy=1&strip=1&webp=1" class="attachment-medium size-medium" alt="" aria-describedby="rpbt-related-gallery-1-8587" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2018/08/opencv_semantic_segmentation_result01.jpg?size=126x85&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/08/opencv_semantic_segmentation_result01-300x203.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2018/08/opencv_semantic_segmentation_result01.jpg?lossy=1&amp;strip=1&amp;webp=1 600w" sizes="(max-width: 300px) 100vw, 300px" /></noscript></a>
			</div>
				<figcaption class="wp-caption-text gallery-caption" id="rpbt-related-gallery-1-8587">
				<a href="https://pyimagesearch.com/2018/09/03/semantic-segmentation-with-opencv-and-deep-learning/">Semantic segmentation with OpenCV and deep learning</a>
				</figcaption></figure>
		</div>
</div></section></aside></div></div></div><div class="similar-articles"><div class="wrap"><h3>Similar articles</h3><div class="gpd-simple-card-group"><article class="post-summary"><a href="https://pyimagesearch.com/2015/10/05/opencv-gamma-correction/" class="post-summary--link"><header class="entry-header"><div class="entry-categories"><div class="entry-category">Image Processing</div><div class="entry-category">Tutorials</div></div><h2 class="entry-title">OpenCV Gamma Correction</h2><div class="entry-date">October 5, 2015</div></header><p class="entry-content-link"><svg class="svg-icon long-arrow" width="14" height="14" aria-hidden="true" role="img" focusable="false" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.8125 0.1875C6.875 0.125 6.96875 0.09375 7.09375 0.09375C7.1875 0.09375 7.28125 0.125 7.34375 0.1875L13.875 6.75C13.9375 6.8125 14 6.90625 14 7C14 7.125 13.9375 7.1875 13.875 7.25L7.34375 13.8125C7.28125 13.875 7.1875 13.9062 7.09375 13.9062C6.96875 13.9062 6.875 13.875 6.8125 13.8125L6.1875 13.1875C6.125 13.125 6.09375 13.0625 6.09375 12.9375C6.09375 12.8438 6.125 12.75 6.1875 12.6562L11.0312 7.8125H0.375C0.25 7.8125 0.15625 7.78125 0.09375 7.71875C0.03125 7.65625 0 7.5625 0 7.4375V6.5625C0 6.46875 0.03125 6.375 0.09375 6.3125C0.15625 6.25 0.25 6.1875 0.375 6.1875H11.0312L6.1875 1.34375C6.125 1.28125 6.09375 1.1875 6.09375 1.0625C6.09375 0.96875 6.125 0.875 6.1875 0.8125L6.8125 0.1875Z" fill="#169FE6"></path></svg></p></a></article><article class="post-summary"><a href="https://pyimagesearch.com/2018/07/09/face-clustering-with-python/" class="post-summary--link"><header class="entry-header"><div class="entry-categories"><div class="entry-category">Deep Learning</div><div class="entry-category">dlib</div><div class="entry-category">Face Applications</div><div class="entry-category">Tutorials</div></div><h2 class="entry-title">Face clustering with Python</h2><div class="entry-date">July 9, 2018</div></header><p class="entry-content-link"><svg class="svg-icon long-arrow" width="14" height="14" aria-hidden="true" role="img" focusable="false" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.8125 0.1875C6.875 0.125 6.96875 0.09375 7.09375 0.09375C7.1875 0.09375 7.28125 0.125 7.34375 0.1875L13.875 6.75C13.9375 6.8125 14 6.90625 14 7C14 7.125 13.9375 7.1875 13.875 7.25L7.34375 13.8125C7.28125 13.875 7.1875 13.9062 7.09375 13.9062C6.96875 13.9062 6.875 13.875 6.8125 13.8125L6.1875 13.1875C6.125 13.125 6.09375 13.0625 6.09375 12.9375C6.09375 12.8438 6.125 12.75 6.1875 12.6562L11.0312 7.8125H0.375C0.25 7.8125 0.15625 7.78125 0.09375 7.71875C0.03125 7.65625 0 7.5625 0 7.4375V6.5625C0 6.46875 0.03125 6.375 0.09375 6.3125C0.15625 6.25 0.25 6.1875 0.375 6.1875H11.0312L6.1875 1.34375C6.125 1.28125 6.09375 1.1875 6.09375 1.0625C6.09375 0.96875 6.125 0.875 6.1875 0.8125L6.8125 0.1875Z" fill="#169FE6"></path></svg></p></a></article><article class="post-summary"><a href="https://pyimagesearch.com/2018/01/08/pyimageconf-2018-practical-hands-computer-vision-deep-learning-conference/" class="post-summary--link"><header class="entry-header"><div class="entry-categories"><div class="entry-category">Announcements</div><div class="entry-category">PyImageConf</div></div><h2 class="entry-title">PyImageConf 2018: The practical, hands-on computer vision and deep learning conference</h2><div class="entry-date">January 8, 2018</div></header><p class="entry-content-link"><svg class="svg-icon long-arrow" width="14" height="14" aria-hidden="true" role="img" focusable="false" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.8125 0.1875C6.875 0.125 6.96875 0.09375 7.09375 0.09375C7.1875 0.09375 7.28125 0.125 7.34375 0.1875L13.875 6.75C13.9375 6.8125 14 6.90625 14 7C14 7.125 13.9375 7.1875 13.875 7.25L7.34375 13.8125C7.28125 13.875 7.1875 13.9062 7.09375 13.9062C6.96875 13.9062 6.875 13.875 6.8125 13.8125L6.1875 13.1875C6.125 13.125 6.09375 13.0625 6.09375 12.9375C6.09375 12.8438 6.125 12.75 6.1875 12.6562L11.0312 7.8125H0.375C0.25 7.8125 0.15625 7.78125 0.09375 7.71875C0.03125 7.65625 0 7.5625 0 7.4375V6.5625C0 6.46875 0.03125 6.375 0.09375 6.3125C0.15625 6.25 0.25 6.1875 0.375 6.1875H11.0312L6.1875 1.34375C6.125 1.28125 6.09375 1.1875 6.09375 1.0625C6.09375 0.96875 6.125 0.875 6.1875 0.8125L6.8125 0.1875Z" fill="#169FE6"></path></svg></p></a></article></div></div></div><div class="gpd-footer-cta"><div class="wrap"><div class="footer-cta-grid"><div class="footer-cta-image"><img width="932" height="833" src="./Instance segmentation with OpenCV - PyImageSearch_files/man-on-sofa-with-laptop-1.jpg" class="attachment-full size-full" alt="" data-lazy-srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=126x113&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1-300x268.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=378x338&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=504x450&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=630x563&amp;lossy=1&amp;strip=1&amp;webp=1 630w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1-768x686.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?lossy=1&amp;strip=1&amp;webp=1 932w" data-lazy-sizes="(max-width: 932px) 100vw, 932px" data-lazy-src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?lossy=1&amp;strip=1&amp;webp=1"><noscript><img width="932" height="833" src="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?lossy=1&strip=1&webp=1" class="attachment-full size-full" alt="" srcset="https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=126x113&amp;lossy=1&amp;strip=1&amp;webp=1 126w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1-300x268.jpg?lossy=1&amp;strip=1&amp;webp=1 300w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=378x338&amp;lossy=1&amp;strip=1&amp;webp=1 378w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=504x450&amp;lossy=1&amp;strip=1&amp;webp=1 504w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?size=630x563&amp;lossy=1&amp;strip=1&amp;webp=1 630w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1-768x686.jpg?lossy=1&amp;strip=1&amp;webp=1 768w, https://929687.smushcdn.com/2633864/wp-content/uploads/2020/02/man-on-sofa-with-laptop-1.jpg?lossy=1&amp;strip=1&amp;webp=1 932w" sizes="(max-width: 932px) 100vw, 932px" /></noscript></div><div class="footer-cta-title"><h3>You can learn Computer Vision, Deep Learning, and OpenCV.</h3></div><div class="footer-cta-content"><div class="footer-cta-content-desc"><p>Get your FREE 17 page Computer Vision, OpenCV, and Deep Learning Resource Guide PDF. Inside you’ll find our hand-picked tutorials, books, courses, and libraries to help you master CV and DL.</p>
</div><div class="footer-cta-content-action"><form class="footer-cta" action="https://www.getdrip.com/forms/657075648/submissions" method="post" target="_blank" data-drip-embedded-form="657075648">
	<input type="email" name="fields[email]" class="form-control" id="email" value="" placeholder="Your email address">
	<button type="submit" data-drip-attribute="sign-up-button">Download for free</button>
	<div style="display: none;" aria-hidden="true"><label for="website">Website</label><br><input type="text" id="website" name="website" tabindex="-1" autocomplete="false" value=""></div>
</form></div></div></div></div></div><div class="footer-widgets" id="genesis-footer-widgets"><h2 class="genesis-sidebar-title screen-reader-text">Footer</h2><div class="wrap"><div class="widget-area footer-widgets-1 footer-widget-area"><section id="custom_html-7" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><h3 class="widgettitle widget-title">Topics</h3>
<div class="textwidget custom-html-widget"><ul>
	<li><a href="https://pyimagesearch.com/category/deep-learning-2/">Deep Learning</a></li>
	<li><a href="https://pyimagesearch.com/category/dlib/">Dlib Library</a></li>
	<li><a href="https://pyimagesearch.com/category/embedded/">Embedded/IoT and Computer Vision</a></li>
	<li><a href="https://pyimagesearch.com/category/faces/">Face Applications</a></li>
	<li><a href="https://pyimagesearch.com/category/image-processing/">Image Processing</a></li>
	<li><a href="https://pyimagesearch.com/category/interviews/">Interviews</a></li>
	<li><a href="https://pyimagesearch.com/category/keras/">Keras</a></li>
</ul>
</div></div></section>
</div><div class="widget-area footer-widgets-2 footer-widget-area"><section id="custom_html-8" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><div class="textwidget custom-html-widget"><ul>
	<li><a href="https://pyimagesearch.com/category/machine-learning-2/">Machine Learning and Computer Vision</a></li>
	<li><a href="https://pyimagesearch.com/category/medical/">Medical Computer Vision</a></li>
	<li><a href="https://pyimagesearch.com/category/optical-character-recognition-ocr/">Optical Character Recognition (OCR)</a></li>
	<li><a href="https://pyimagesearch.com/category/object-detection/">Object Detection</a></li>
	<li><a href="https://pyimagesearch.com/category/object-tracking/">Object Tracking</a></li>
	<li><a href="https://pyimagesearch.com/category/opencv/">OpenCV Tutorials</a></li>
	<li><a href="https://pyimagesearch.com/category/raspberry-pi/">Raspberry Pi</a></li>
</ul></div></div></section>
</div><div class="widget-area footer-widgets-3 footer-widget-area"><section id="custom_html-9" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><h3 class="widgettitle widget-title">Books &amp; Courses</h3>
<div class="textwidget custom-html-widget"><ul>
<li><a href="https://pyimagesearch.com/pyimagesearch-university/">PyImageSearch University</a></li>
<li><a href="https://pyimagesearch.com/free-opencv-computer-vision-deep-learning-crash-course/">FREE CV, DL, and OpenCV Crash Course</a></li>
<li><a href="https://pyimagesearch.com/practical-python-opencv/">Practical Python and OpenCV</a></li>
<li><a href="https://pyimagesearch.com/deep-learning-computer-vision-python-book/">Deep Learning for Computer Vision with Python</a></li>
<li><a href="https://pyimagesearch.com/pyimagesearch-gurus/">PyImageSearch Gurus Course</a></li>
<li><a href="https://pyimagesearch.com/raspberry-pi-for-computer-vision/">Raspberry Pi for Computer Vision</a></li>
</ul></div></div></section>
</div><div class="widget-area footer-widgets-4 footer-widget-area"><section id="custom_html-10" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><h3 class="widgettitle widget-title">PyImageSearch</h3>
<div class="textwidget custom-html-widget"><ul>
		<li><a href="https://pyimagesearch.com/affiliates/">Affiliates</a></li>
	<li><a href="https://pyimagesearch.com/start-here/">Get Started</a></li>
	<li><a href="https://pyimagesearch.com/opencv-tutorials-resources-guides/">OpenCV Install Guides</a></li>
	<li><a href="https://pyimagesearch.com/about/">About</a></li>
	<li><a href="https://pyimagesearch.com/faqs/">FAQ</a></li>
	<li><a href="https://pyimagesearch.com/topics/">Blog</a></li>
	<li><a href="https://pyimagesearch.com/contact/">Contact</a></li>
	<li><a href="https://pyimagesearch.com/privacy-policy/">Privacy Policy</a></li>
</ul></div></div></section>
</div></div></div><footer class="site-footer"><div class="wrap"><div class="footer-logo"><p class="site-title"><a href="https://pyimagesearch.com/"></a></p></div><div class="footer-social"><a target="_blank" href="https://www.facebook.com/pyimagesearch"><svg class="svg-icon social-icon" width="18" height="18" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 264 512"><path d="M215.8 85H264V3.6C255.7 2.5 227.1 0 193.8 0 124.3 0 76.7 42.4 76.7 120.3V192H0v91h76.7v229h94V283h73.6l11.7-91h-85.3v-62.7c0-26.3 7.3-44.3 45.1-44.3z"></path></svg></a><a target="_blank" href="https://twitter.com/PyImageSearch"><svg class="svg-icon social-icon" width="18" height="18" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a target="_blank" href="http://www.linkedin.com/pub/adrian-rosebrock/2a/873/59b"><svg class="svg-icon social-icon" width="18" height="18" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a><a target="_blank" href="https://www.youtube.com/channel/UCoQK7OVcIVy-nV4m-SMCk_Q/videos"><svg class="svg-icon social-icon" width="18" height="18" aria-hidden="true" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a></div><div class="footer-info">© 2022 <a href="https://pyimagesearch.com/">PyImageSearch</a>. All Rights Reserved.</div></div></footer></div><!-- RightMessage WP -->


<div class="front-page-modal modal" id="pyis-cta-modal">

    <div class="modal-content">

        
<div class="optin-modal-content">

    <div style="text-align: center; font-size: 18px; padding-bottom: 20px;">
        <a target="_blank" href="https://pyimagesearch.mykajabi.com/login" style="font-weight: normal; color: #808080;">Already a member of PyImageSearch University? <strong>Click here to login.</strong></a>
    </div>

    <center>
        <img class="pyuni-logo" src="./Instance segmentation with OpenCV - PyImageSearch_files/pyimagesearch_university_logo.png" alt="PyImageSearch University Logo">
    </center>

    <div class="front-modal-top">
        <h3>Access the code to this tutorial and all other 500+ tutorials on PyImageSearch</h3>
    </div>

    <div class="front-modal-video first">
        <div class="front-modal-video-embed">
            <div class="wistia_responsive_padding" style="padding:56.25% 0 0 0;position:relative;"><div class="wistia_responsive_wrapper" style="height:100%;left:0;position:absolute;top:0;width:100%;"><div class="wistia_embed wistia_async_8ggk996ods videoFoam=true wistia_embed_initialized" style="height:100%;position:relative;width:100%" id="wistia-8ggk996ods-1"><div class="wistia_swatch" style="height: 100%; left: 0px; opacity: 1; overflow: hidden; position: absolute; top: 0px; transition: opacity 200ms ease 0s; width: 100%;"><img src="./Instance segmentation with OpenCV - PyImageSearch_files/swatch(2)" style="filter:blur(5px);height:100%;object-fit:contain;width:100%;" alt="" aria-hidden="true" onload="this.parentNode.style.opacity=1;" data-lazy-src="https://fast.wistia.com/embed/medias/8ggk996ods/swatch"><noscript><img src="https://fast.wistia.com/embed/medias/8ggk996ods/swatch" style="filter:blur(5px);height:100%;object-fit:contain;width:100%;" alt="" aria-hidden="true" onload="this.parentNode.style.opacity=1;" /></noscript></div><div id="wistia_chrome_40" class="w-chrome" tabindex="-1" style="display: inline-block; height: 100%; line-height: normal; margin: 0px; padding: 0px; position: relative; vertical-align: top; width: 100%; zoom: 1; outline: none; overflow: hidden; box-sizing: content-box;"><div id="wistia_grid_110_wrapper" style="display: block;"><div id="wistia_grid_110_above"></div><div id="wistia_grid_110_main"><div id="wistia_grid_110_behind"></div><div id="wistia_grid_110_center"><div class="w-video-wrapper w-css-reset" style="clip: rect(0px, 0px, 0px, 0px); height: 100%; position: absolute; top: 0px; width: 100%; opacity: 1; background-color: rgb(0, 0, 0);"></div><div class="w-ui-container" style="height: 100%; left: 0px; position: absolute; top: 0px; width: 100%; opacity: 1;"></div></div><div id="wistia_grid_110_front"></div><div id="wistia_grid_110_top_inside"><div id="wistia_grid_110_top"></div></div><div id="wistia_grid_110_bottom_inside"><div id="wistia_grid_110_bottom"></div></div><div id="wistia_grid_110_left_inside"><div id="wistia_grid_110_left"></div></div><div id="wistia_grid_110_right_inside"><div id="wistia_grid_110_right"></div></div></div><div id="wistia_grid_110_below"></div><style id="wistia_111_style" type="text/css" class="wistia_injected_style">#wistia_grid_110_wrapper{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;font-family:Arial,sans-serif;font-size:14px;height:100%;position:relative;text-align:left;width:100%;}
#wistia_grid_110_wrapper *{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;}
#wistia_grid_110_above{position:relative;}
#wistia_grid_110_main{display:block;height:100%;position:relative;}
#wistia_grid_110_behind{height:100%;left:0;position:absolute;top:0;width:100%;}
#wistia_grid_110_center{height:100%;overflow:hidden;position:relative;width:100%;}
#wistia_grid_110_front{display:none;height:100%;left:0;position:absolute;top:0;width:100%;}
#wistia_grid_110_top_inside{position:absolute;left:0;top:0;width:100%;}
#wistia_grid_110_top{width:100%;position:absolute;bottom:0;left:0;}
#wistia_grid_110_bottom_inside{position:absolute;left:0;bottom:0;width:100%;}
#wistia_grid_110_bottom{width:100%;position:absolute;top:0;left:0;}
#wistia_grid_110_left_inside{height:100%;position:absolute;left:0;top:0;}
#wistia_grid_110_left{height:100%;position:absolute;right:0;top:0;}
#wistia_grid_110_right_inside{height:100%;right:0;position:absolute;top:0;}
#wistia_grid_110_right{height:100%;left:0;position:absolute;top:0;}
#wistia_grid_110_below{position:relative;}</style></div></div></div></div></div>
        </div>
        <div class="front-modal-action" style="margin-top: 20px;">
            <p><strong>Enter your email address below to learn more about PyImageSearch University</strong> (including how you can download the source code to this post):</p>
            <form class="footer-cta" action="https://www.getdrip.com/forms/857913265/submissions" method="post" target="_blank" data-drip-embedded-form="857913265" id="drip-ef-857913265">
                <input type="email" name="fields[email]" class="form-control" id="email" value="" placeholder="Your email address">
                <input id="code_submit_post_title" type="hidden" name="fields[code_submit_post_title]" value="">
                <button type="submit" data-drip-attribute="sign-up-button">Learn More</button>
                <div style="display: none;" aria-hidden="true"><label for="website">Website</label><br><input type="text" id="website" name="website" tabindex="-1" autocomplete="false" value=""></div>
            </form>
        </div>
    </div>

    <div class="front-modal-top">
        <h3>What's included in PyImageSearch University?</h3>
    </div>

    <div class="front-modal-video">
        <div class="front-modal-video-desc">
            <ul class="is-style-list-checks">
                <li><strong>Easy access to the code, datasets, and pre-trained models</strong> for all 500+ tutorials on the PyImageSearch blog</li>
                <li><strong>High-quality, well documented source code</strong> with line-by-line explanations (ensuring you know exactly what the code is doing)</li>
                <li><strong>Jupyter Notebooks</strong> that are pre-configured to run in <strong>Google Colab</strong> with a <em>single click</em></li>
                <li><strong>Run all code examples in your web browser</strong> — no dev environment configuration required!</li>
            </ul>
        </div>
        <div class="front-modal-video-desc">
            <ul class="is-style-list-checks">
                <li><strong>Support for all major operating systems</strong> (Windows, macOS, Linux, and Raspbian)</li>
                <li><strong>Full access to PyImageSearch University courses</strong></li>
                <li><strong>Detailed video tutorials</strong> for every lesson</li>
                <li><strong>Certificates of Completion</strong> for all courses</li>
                <li><strong>New courses added <em>every month!</em></strong> — stay on top of state-of-the-art trends in computer vision and deep learning</li>
            </ul>
        </div>
    </div>

    <div class="front-modal-testimonial">
        <blockquote><p>PyImageSearch University is really the best Computer Visions "Masters" Degree that I wish I had when starting out. <strong>Being able to access all of Adrian's tutorials in a single indexed page and being able to start playing around with the code without going through the nightmare of setting up everything is just amazing.</strong> 10/10 would recommend.</p><cite><span class="quote-name">Sanyam Bhutani</span><span class="cite-title">Machine Learning Engineer and 2x Kaggle Master</span></cite></blockquote>
    </div>

</div>
    </div>

    <a href="https://pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/#close-modal" rel="modal:close" target="_self" class="close-modal">
        Close    </a>

</div><!-- Drip -->


<!-- facebook -->

<noscript><img height="1" width="1" style="display:none"
  src="https://www.facebook.com/tr?id=1465896023527386&ev=PageView&noscript=1"
/></noscript>

<!-- Global site tag (gtag.js) - Google Analytics -->



<!-- Start VWO Async SmartCode -->
<script type="text/javascript">
window._vwo_code = window._vwo_code || (function(){
var account_id=586234,
settings_tolerance=2000,
library_tolerance=2500,
use_existing_jquery=false,
is_spa=1,
hide_element='body',

/* DO NOT EDIT BELOW THIS LINE */
f=false,d=document,code={use_existing_jquery:function(){return use_existing_jquery;},library_tolerance:function(){return library_tolerance;},finish:function(){if(!f){f=true;var a=d.getElementById('_vis_opt_path_hides');if(a)a.parentNode.removeChild(a);}},finished:function(){return f;},load:function(a){var b=d.createElement('script');b.src=a;b.type='text/javascript';b.innerText;b.onerror=function(){_vwo_code.finish();};d.getElementsByTagName('head')[0].appendChild(b);},init:function(){
window.settings_timer=setTimeout(function () {_vwo_code.finish() },settings_tolerance);var a=d.createElement('style'),b=hide_element?hide_element+'{opacity:0 !important;filter:alpha(opacity=0) !important;background:none !important;}':'',h=d.getElementsByTagName('head')[0];a.setAttribute('id','_vis_opt_path_hides');a.setAttribute('type','text/css');if(a.styleSheet)a.styleSheet.cssText=b;else a.appendChild(d.createTextNode(b));h.appendChild(a);this.load('https://dev.visualwebsiteoptimizer.com/j.php?a='+account_id+'&u='+encodeURIComponent(d.URL)+'&f='+(+is_spa)+'&r='+Math.random());return settings_timer; }};window._vwo_settings_timer = code.init(); return code; }());
</script>
<!-- End VWO Async SmartCode --><!-- This site is converting visitors into subscribers and customers with OptinMonster - https://optinmonster.com :: Campaign Title: 2022/09/10 baseline -->

<!-- / OptinMonster --><!-- This site is converting visitors into subscribers and customers with OptinMonster - https://optinmonster.com :: Campaign Title: PyImageSearch Gurus Syllabus --><div id="om-kizfm1tpclo79dji-holder"></div><!-- / OptinMonster --><div style="position:absolute;overflow:hidden;clip:rect(0 0 0 0);height:1px;width:1px;margin:-1px;padding:0;border:0"><div class="omapi-shortcode-helper">[class^="wpforms-"]</div><div class="omapi-shortcode-parsed omapi-encoded">[class^="wpforms-"]</div></div>		
		
<script type="text/javascript" id="rocket-browser-checker-js-after">
"use strict";var _createClass=function(){function defineProperties(target,props){for(var i=0;i<props.length;i++){var descriptor=props[i];descriptor.enumerable=descriptor.enumerable||!1,descriptor.configurable=!0,"value"in descriptor&&(descriptor.writable=!0),Object.defineProperty(target,descriptor.key,descriptor)}}return function(Constructor,protoProps,staticProps){return protoProps&&defineProperties(Constructor.prototype,protoProps),staticProps&&defineProperties(Constructor,staticProps),Constructor}}();function _classCallCheck(instance,Constructor){if(!(instance instanceof Constructor))throw new TypeError("Cannot call a class as a function")}var RocketBrowserCompatibilityChecker=function(){function RocketBrowserCompatibilityChecker(options){_classCallCheck(this,RocketBrowserCompatibilityChecker),this.passiveSupported=!1,this._checkPassiveOption(this),this.options=!!this.passiveSupported&&options}return _createClass(RocketBrowserCompatibilityChecker,[{key:"_checkPassiveOption",value:function(self){try{var options={get passive(){return!(self.passiveSupported=!0)}};window.addEventListener("test",null,options),window.removeEventListener("test",null,options)}catch(err){self.passiveSupported=!1}}},{key:"initRequestIdleCallback",value:function(){!1 in window&&(window.requestIdleCallback=function(cb){var start=Date.now();return setTimeout(function(){cb({didTimeout:!1,timeRemaining:function(){return Math.max(0,50-(Date.now()-start))}})},1)}),!1 in window&&(window.cancelIdleCallback=function(id){return clearTimeout(id)})}},{key:"isDataSaverModeOn",value:function(){return"connection"in navigator&&!0===navigator.connection.saveData}},{key:"supportsLinkPrefetch",value:function(){var elem=document.createElement("link");return elem.relList&&elem.relList.supports&&elem.relList.supports("prefetch")&&window.IntersectionObserver&&"isIntersecting"in IntersectionObserverEntry.prototype}},{key:"isSlowConnection",value:function(){return"connection"in navigator&&"effectiveType"in navigator.connection&&("2g"===navigator.connection.effectiveType||"slow-2g"===navigator.connection.effectiveType)}}]),RocketBrowserCompatibilityChecker}();
</script>
<script type="text/javascript" id="rocket-preload-links-js-extra">
/* <![CDATA[ */
var RocketPreloadLinksConfig = {"excludeUris":"\/contact\/|\/(?:.+\/)?feed(?:\/(?:.+\/?)?)?$|\/(?:.+\/)?embed\/|\/(index\\.php\/)?wp\\-json(\/.*|$)|\/refer\/|\/go\/|\/recommend\/|\/recommends\/","usesTrailingSlash":"1","imageExt":"jpg|jpeg|gif|png|tiff|bmp|webp|avif|pdf|doc|docx|xls|xlsx|php","fileExt":"jpg|jpeg|gif|png|tiff|bmp|webp|avif|pdf|doc|docx|xls|xlsx|php|html|htm","siteUrl":"https:\/\/pyimagesearch.com","onHoverDelay":"100","rateThrottle":"3"};
/* ]]> */
</script>
<script type="text/javascript" id="rocket-preload-links-js-after">
(function() {
"use strict";var r="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e},e=function(){function i(e,t){for(var n=0;n<t.length;n++){var i=t[n];i.enumerable=i.enumerable||!1,i.configurable=!0,"value"in i&&(i.writable=!0),Object.defineProperty(e,i.key,i)}}return function(e,t,n){return t&&i(e.prototype,t),n&&i(e,n),e}}();function i(e,t){if(!(e instanceof t))throw new TypeError("Cannot call a class as a function")}var t=function(){function n(e,t){i(this,n),this.browser=e,this.config=t,this.options=this.browser.options,this.prefetched=new Set,this.eventTime=null,this.threshold=1111,this.numOnHover=0}return e(n,[{key:"init",value:function(){!this.browser.supportsLinkPrefetch()||this.browser.isDataSaverModeOn()||this.browser.isSlowConnection()||(this.regex={excludeUris:RegExp(this.config.excludeUris,"i"),images:RegExp(".("+this.config.imageExt+")$","i"),fileExt:RegExp(".("+this.config.fileExt+")$","i")},this._initListeners(this))}},{key:"_initListeners",value:function(e){-1<this.config.onHoverDelay&&document.addEventListener("mouseover",e.listener.bind(e),e.listenerOptions),document.addEventListener("mousedown",e.listener.bind(e),e.listenerOptions),document.addEventListener("touchstart",e.listener.bind(e),e.listenerOptions)}},{key:"listener",value:function(e){var t=e.target.closest("a"),n=this._prepareUrl(t);if(null!==n)switch(e.type){case"mousedown":case"touchstart":this._addPrefetchLink(n);break;case"mouseover":this._earlyPrefetch(t,n,"mouseout")}}},{key:"_earlyPrefetch",value:function(t,e,n){var i=this,r=setTimeout(function(){if(r=null,0===i.numOnHover)setTimeout(function(){return i.numOnHover=0},1e3);else if(i.numOnHover>i.config.rateThrottle)return;i.numOnHover++,i._addPrefetchLink(e)},this.config.onHoverDelay);t.addEventListener(n,function e(){t.removeEventListener(n,e,{passive:!0}),null!==r&&(clearTimeout(r),r=null)},{passive:!0})}},{key:"_addPrefetchLink",value:function(i){return this.prefetched.add(i.href),new Promise(function(e,t){var n=document.createElement("link");n.rel="prefetch",n.href=i.href,n.onload=e,n.onerror=t,document.head.appendChild(n)}).catch(function(){})}},{key:"_prepareUrl",value:function(e){if(null===e||"object"!==(void 0===e?"undefined":r(e))||!1 in e||-1===["http:","https:"].indexOf(e.protocol))return null;var t=e.href.substring(0,this.config.siteUrl.length),n=this._getPathname(e.href,t),i={original:e.href,protocol:e.protocol,origin:t,pathname:n,href:t+n};return this._isLinkOk(i)?i:null}},{key:"_getPathname",value:function(e,t){var n=t?e.substring(this.config.siteUrl.length):e;return n.startsWith("/")||(n="/"+n),this._shouldAddTrailingSlash(n)?n+"/":n}},{key:"_shouldAddTrailingSlash",value:function(e){return this.config.usesTrailingSlash&&!e.endsWith("/")&&!this.regex.fileExt.test(e)}},{key:"_isLinkOk",value:function(e){return null!==e&&"object"===(void 0===e?"undefined":r(e))&&(!this.prefetched.has(e.href)&&e.origin===this.config.siteUrl&&-1===e.href.indexOf("?")&&-1===e.href.indexOf("#")&&!this.regex.excludeUris.test(e.href)&&!this.regex.images.test(e.href))}}],[{key:"run",value:function(){"undefined"!=typeof RocketPreloadLinksConfig&&new n(new RocketBrowserCompatibilityChecker({capture:!0,passive:!0}),RocketPreloadLinksConfig).init()}}]),n}();t.run();
}());
</script>





<script type="text/javascript" id="gforms_recaptcha_recaptcha-js-extra">
/* <![CDATA[ */
var gforms_recaptcha_recaptcha_strings = {"site_key":"6LdUr2EfAAAAAJ6_2rW0WWD9TkARt5bIjiIJeGnJ","ajaxurl":"https:\/\/pyimagesearch.com\/wp-admin\/admin-ajax.php","nonce":"1124d2675f"};
/* ]]> */
</script>







		<script type="text/javascript">var omapi_localized = {
			ajax: 'https://pyimagesearch.com/wp-admin/admin-ajax.php?optin-monster-ajax-route=1',
			nonce: 'c89028fe77',
			slugs:
			{"vksgrjuaic5dopynajjn":{"slug":"vksgrjuaic5dopynajjn","mailpoet":false},"kizfm1tpclo79dji":{"slug":"kizfm1tpclo79dji","mailpoet":false}}		};</script>
				<script type="text/javascript">var omapi_data = {"wc_cart":[],"object_id":9061,"object_key":"post","object_type":"post","term_ids":[165,504,27,109,513,512,172,249,146,505],"wp_json":"https:\/\/pyimagesearch.com\/wp-json"};</script>
		<script>window.lazyLoadOptions=[{elements_selector:"img[data-lazy-src],.rocket-lazyload,iframe[data-lazy-src]",data_src:"lazy-src",data_srcset:"lazy-srcset",data_sizes:"lazy-sizes",class_loading:"lazyloading",class_loaded:"lazyloaded",threshold:300,callback_loaded:function(element){if(element.tagName==="IFRAME"&&element.dataset.rocketLazyload=="fitvidscompatible"){if(element.classList.contains("lazyloaded")){if(typeof window.jQuery!="undefined"){if(jQuery.fn.fitVids){jQuery(element).parent().fitVids()}}}}}},{elements_selector:".rocket-lazyload",data_src:"lazy-src",data_srcset:"lazy-srcset",data_sizes:"lazy-sizes",class_loading:"lazyloading",class_loaded:"lazyloaded",threshold:300,}];window.addEventListener('LazyLoad::Initialized',function(e){var lazyLoadInstance=e.detail.instance;if(window.MutationObserver){var observer=new MutationObserver(function(mutations){var image_count=0;var iframe_count=0;var rocketlazy_count=0;mutations.forEach(function(mutation){for(var i=0;i<mutation.addedNodes.length;i++){if(typeof mutation.addedNodes[i].getElementsByTagName!=='function'){continue}
if(typeof mutation.addedNodes[i].getElementsByClassName!=='function'){continue}
images=mutation.addedNodes[i].getElementsByTagName('img');is_image=mutation.addedNodes[i].tagName=="IMG";iframes=mutation.addedNodes[i].getElementsByTagName('iframe');is_iframe=mutation.addedNodes[i].tagName=="IFRAME";rocket_lazy=mutation.addedNodes[i].getElementsByClassName('rocket-lazyload');image_count+=images.length;iframe_count+=iframes.length;rocketlazy_count+=rocket_lazy.length;if(is_image){image_count+=1}
if(is_iframe){iframe_count+=1}}});if(image_count>0||iframe_count>0||rocketlazy_count>0){lazyLoadInstance.update()}});var b=document.getElementsByTagName("body")[0];var config={childList:!0,subtree:!0};observer.observe(b,config)}},!1)</script><script>"use strict";function wprRemoveCPCSS(){var preload_stylesheets=document.querySelectorAll('link[data-rocket-async="style"][rel="preload"]');if(preload_stylesheets&&0<preload_stylesheets.length)for(var stylesheet_index=0;stylesheet_index<preload_stylesheets.length;stylesheet_index++){var media=preload_stylesheets[stylesheet_index].getAttribute("media")||"all";if(window.matchMedia(media).matches)return void setTimeout(wprRemoveCPCSS,200)}var elem=document.getElementById("rocket-critical-css");elem&&"remove"in elem&&elem.remove()}window.addEventListener?window.addEventListener("load",wprRemoveCPCSS):window.attachEvent&&window.attachEvent("onload",wprRemoveCPCSS);</script><noscript><link data-avlabs-exclude-css="1"  rel="stylesheet" href="https://pyimagesearch.com/wp-content/cache/min/1/eef0bf32586d57e4ed24eb224ecbaf2f.css" media="all" data-minify="1" /></noscript><script>
        var avlabs_load_scripts_immediately =false ;
        var avlabs_primary_scripts = [] ;
        var avlabs_secondary_scripts = [] ;
        var avlabs_primary_scripts_to_be_loaded =[];
        var avlabs_secondary_scripts_to_be_loaded=[];
        var primary_script_timer, secondary_script_timer;
        avlabs_primary_scripts.push('https://pyimagesearch.com/wp-includes/js/jquery/jquery.js');
        avlabs_primary_scripts.push('https://pyimagesearch.com/wp-content/cache/min/1/f67da8ef1bb72583a9be2d03590e071d_avlabs_primary_script.js');
        avlabs_primary_scripts.push('https://pyimagesearch.com/wp-content/avlabs-cache/js/avlabs-mobile-menu.js?ver=6.0.3');
        avlabs_primary_scripts.push('https://pyimagesearch.com/wp-content/avlabs-cache/js/avlabs-preloader.js?ver=6.0.3');
        avlabs_primary_scripts.push('https://pyimagesearch.com/wp-content/themes/pyi/assets/js/stickykit.min.js?ver=1597079258');
        avlabs_secondary_scripts.push('https://fast.wistia.com/embed/medias/kno0cmko2z.jsonp');
        avlabs_secondary_scripts.push('https://fast.wistia.com/embed/medias/8ggk996ods.jsonp');
        avlabs_secondary_scripts.push('https://www.google.com/recaptcha/api.js?render=6LdUr2EfAAAAAJ6_2rW0WWD9TkARt5bIjiIJeGnJ&#038;ver=1.1');
        avlabs_secondary_scripts.push('https://www.googletagmanager.com/gtag/js?id=UA-46641058-1');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/plugins/enlighter/cache/enlighterjs.min.js?ver=lyvLsKN0kw3Q9Uv');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/cache/min/1/5f56163b05bae797fe59e9425270e15c.js');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/themes/genesis/lib/js/skip-links.min.js?ver=3.4.0');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/themes/pyi/assets/js/modal-min.js?ver=1597079258');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/avlabs-cache/js/avlabs-lazy-load.js?ver=6.0.3');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/themes/pyi/assets/js/jquery.flexslider.min.js?ver=1597079258');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/themes/pyi/assets/js/global-min.js?ver=1597079258');
        avlabs_secondary_scripts.push('https://pyimagesearch.com/wp-content/plugins/wp-rocket/assets/js/lazyload/17.5/lazyload.min.js');
        setTimeout(function(){
        if( document.getElementById('avlabs-lazy-load-bg') !== null )
        {
            bg_none_css = document.getElementById('avlabs-lazy-load-bg').innerHTML;
                document.getElementById('avlabs-lazy-load-bg').innerHTML = bg_none_css.replaceAll("!important",'') ;
        }},8000);
                
        function avlabs_scripts_loader( which,callback) 
        {
            if(which=='primary' )
            {
                if(avlabs_primary_scripts_to_be_loaded=='')
                {
                    return;
                }
                else
                {
                   
                    //clearInterval
                    if( typeof primary_script_timer !== "undefined" )
                    {
                        clearInterval(primary_script_timer)
                    }
                    scripts = avlabs_primary_scripts_to_be_loaded;
                }
                
            }

            if(which=='secondary' )
            {
                if(avlabs_secondary_scripts_to_be_loaded=='')
                {
                    return;
                }
                else
                {
                    //clearInterval
                    if( typeof secondary_script_timer !== "undefined" )
                    {
                        clearInterval(secondary_script_timer)
                    }
                    scripts = avlabs_secondary_scripts_to_be_loaded;
                }
                
            }    

            var count = scripts.length;
            function urlCallback(url) {
                return function () {
                    
                    console.log(url + ' was loaded (' + --count + ' more '+which+' scripts remaining).');
                    if (count < 1) {
                        //callback();
                        if(which =='primary' && avlabs_load_scripts_immediately==true)
                        {
                            avlabs_secondary_scripts_to_be_loaded = avlabs_secondary_scripts;  
                        }
                        if(document.createEvent){
                            var evt = document.createEvent("MutationEvents"); 
                            evt.initMutationEvent("DOMContentLoaded", true, true, document, "", "", "", 0); 
                            document.dispatchEvent(evt);
                        }
                        if (typeof jQuery != 'undefined') {
                            jQuery(window).trigger( 'load' ); 
                            jQuery(window).trigger( 'resize' );
                        }
                    }
                };
            }

            function loadScript(url) {
                var s = document.createElement('script');
                s.setAttribute('src', url);
                s.onload = urlCallback(url);
                s.async=false;
                document.head.appendChild(s);
            }

            for (var i = 0; i<scripts.length; i++) {
                loadScript(scripts[i]);
            }
        };
        
        if(avlabs_primary_scripts!='')
        {
            primary_time_out = setTimeout(function(){
            avlabs_primary_scripts_to_be_loaded = avlabs_primary_scripts;
            }
        ,1000);
            if( typeof primary_script_timer === "undefined" )
            {
                primary_script_timer = setInterval(function(){
                    avlabs_scripts_loader('primary', function() {
                    });
                },200);
            }
            
        }

        if(avlabs_secondary_scripts !='' )
        {
            secondary_time_out = setTimeout(function(){
                avlabs_secondary_scripts_to_be_loaded = avlabs_secondary_scripts;
            }
        ,12000);
            if( typeof secondary_script_timer === "undefined" )
            {
                secondary_script_timer = setInterval(function(){
                    avlabs_scripts_loader('secondary', function() {
                    });
                },200);
            }
        }

        function avlabs_clear_timeout_load_js_script()
        {
            if(avlabs_primary_scripts!='' )
            {
                if(avlabs_primary_scripts_to_be_loaded =='')
                {
                    avlabs_primary_scripts_to_be_loaded = avlabs_primary_scripts;
                    avlabs_load_scripts_immediately=true;
                }
                else
                {
                    avlabs_secondary_scripts_to_be_loaded = avlabs_secondary_scripts;
                }
                    
            }
            else if(avlabs_secondary_scripts!='')
            {
                avlabs_secondary_scripts_to_be_loaded = avlabs_secondary_scripts;
            }

        }

        window.addEventListener("scroll", function(){
            avlabs_clear_timeout_load_js_script();
        });

        window.addEventListener("mousemove", function(){ 
            avlabs_clear_timeout_load_js_script();
        });

        window.addEventListener("touchstart", function(){ 
            avlabs_clear_timeout_load_js_script();
        }); 
            
        </script><script>
        var avlabs_load_css_immediately =false ;
        var avlabs_primary_css = [] ;
        var avlabs_secondary_css = [] ;
        var avlabs_primary_css_to_be_loaded =[];
        var avlabs_secondary_css_to_be_loaded=[];
        var primary_css_timer, secondary_css_timer;
        avlabs_secondary_css.push('https://pyimagesearch.com/wp-content/cache/min/1/eef0bf32586d57e4ed24eb224ecbaf2f.css');

        
        function avlabs_css_loader( which,callback) 
        {
            if(which=='primary' )
            {
                if(avlabs_primary_css_to_be_loaded=='')
                {
                    return;
                }
                else
                {
                    //clearInterval
                    if( typeof primary_css_timer !== "undefined" )
                    {
                            clearInterval(primary_css_timer)
                    }
                    scripts = avlabs_primary_css_to_be_loaded;
                }
                
            }

            if(which=='secondary' )
            {
                if(avlabs_secondary_css_to_be_loaded=='')
                {
                    return;
                }
                else
                {
                    //clearInterval
                    if( typeof secondary_css_timer !== "undefined" )
                    {
                        clearInterval(secondary_css_timer)
                    }
                    scripts = avlabs_secondary_css_to_be_loaded;
                }
                
            }    

            var count = scripts.length;
            function urlCallback(url) {
                return function () {
                    
                    console.log(url + ' was loaded (' + --count + ' more '+which+' css remaining).');
                    if (count < 1) {
                        //callback();
                        if(which =='primary' && avlabs_load_css_immediately==true)
                        {
                            avlabs_secondary_css_to_be_loaded = avlabs_secondary_css;  
                        }
                        
                    }
                };
            }
            var avlabs_atfcss = document.getElementById('avlabs-rocket-critical-css');
            
            function loadScript(url) {
                var css = document.createElement("link");
                css.rel = "stylesheet";
                css.href = url;
                css.media = "all";
                css.type = "text/css";
                css.onload = urlCallback(url);
                
                //document.getElementsByTagName('head')[0].appendChild(css);
                avlabs_atfcss.parentNode.insertBefore(css,avlabs_atfcss.nextSibling);
                
            }       

            for (var i = 0; i<scripts.length; i++) {
                loadScript(scripts[i]);
            }
        };
        
        if(avlabs_primary_css!='')
        {
            setTimeout(function(){
            avlabs_primary_css_to_be_loaded = avlabs_primary_css;
            }
        ,200);
            if( typeof primary_css_timer === "undefined" )
            {
                primary_css_timer = setInterval(function(){
                    avlabs_css_loader('primary', function() {
                    });
                },200);
            }
        }

        if(avlabs_secondary_css !='' )
        {
            setTimeout(function(){
                avlabs_secondary_css_to_be_loaded = avlabs_secondary_css;
            }
        ,12000);
            if( typeof secondary_css_timer === "undefined" )
            {
                secondary_css_timer = setInterval(function(){
                    avlabs_css_loader('secondary', function() {
                    });
                },200);
            }
        }

        function avlabs_clear_timeout_load_css_script()
        {
            if(avlabs_primary_css!='' )
            {
                if(avlabs_primary_css_to_be_loaded =='')
                {
                    avlabs_primary_css_to_be_loaded = avlabs_primary_css;
                    avlabs_load_css_immediately=true;
                }
                else
                {
                    avlabs_secondary_css_to_be_loaded = avlabs_secondary_css;
                }
                    
            }
            else if(avlabs_secondary_css!='')
            {
                avlabs_secondary_css_to_be_loaded = avlabs_secondary_css;
            }

        }

        window.addEventListener("scroll", function(){
            avlabs_clear_timeout_load_css_script();
        });

        window.addEventListener("mousemove", function(){ 
            avlabs_clear_timeout_load_css_script();
        });

        window.addEventListener("touchstart", function(){ 
            avlabs_clear_timeout_load_css_script();
        }); 
            
        </script><script>
if (document.querySelector("body[class*=av-template]") !== null) {
document.querySelector("style#avlabs-rocket-critical-css").innerHTML = "";
}
</script><script> var avlabs_mobile_menu_clicked = false;
var avlabs_mobile_menu = document.getElementsByClassName('mobile-menu-toggle')[0];
if (avlabs_mobile_menu !== undefined) {
    avlabs_mobile_menu.addEventListener("click", function(){
    avlabs_mobile_menu_clicked = true;
    });
}
            </script>

<div></div><style id="wistia_22_style" type="text/css" class="wistia_injected_style">
@font-face {
font-family: 'WistiaPlayerInterNumbersSemiBold';
font-feature-settings: 'tnum' 1;
src: url(data:application/x-font-woff;charset=utf-8;base64,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);
}
</style><div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; position: fixed; visibility: hidden; display: block; transition: right 0.3s ease 0s; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" src="./Instance segmentation with OpenCV - PyImageSearch_files/anchor.html" width="256" height="60" role="presentation" name="a-rleu7lbv5xml" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;" src="./Instance segmentation with OpenCV - PyImageSearch_files/saved_resource.html"></iframe></div><div id="otherside-root"><div><div id="windows"><div><div style="all: unset;"></div></div></div><div class="css-34tvdx e1gj4xli0"></div></div></div><div id="hyperwrite-login-notification" style="display: none;"></div></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>